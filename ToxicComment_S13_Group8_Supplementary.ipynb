{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "### Import\n",
    "Several libraries are required to perform a thorough analysis of the dataset. Each of these libraries will be imported and described below:\n",
    "\n",
    "#### Basic Libraries \n",
    "Import `numpy` and `pandas`.\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2fb8d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "836013db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Datasets and Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Trying different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "176302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mn_hyper_parameter:\n",
    "    def __init__(self, class_, alpha, fit_prior):\n",
    "        self.class_ = class_\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8c247db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_hyperparameter:\n",
    "    def __init__(self, class_, c, max_iter):\n",
    "        self.class_ = class_\n",
    "        self.c = c\n",
    "        self.max_iter = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fafb6",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "61100a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    accuracy = np.sum (predictions == actual) / len (predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv(predictions, filename):\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    sample_submission ['id'] = test ['id'] \n",
    "    counter = 0\n",
    "\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "85a0a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv_multiclass (predictions, filename):\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    sample_submission ['id'] = test ['id'] \n",
    "    counter = 0\n",
    "\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98318366",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "613bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b8f9a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0ad45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c0caa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2ebad703",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [1, 12, 15],\n",
    "        'classifier__max_iter': [600, 1800, 3000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7a3f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 95.13696097661855\n",
      "TF-IDF Vectors: 92.36828747078103\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.641983819115\n",
      "TF-IDF Vectors: 98.99104473870565\n",
      "Fitting obscene...\n",
      "Count Vectors: 96.70867513520626\n",
      "TF-IDF Vectors: 95.38449968979326\n",
      "Fitting threat...\n",
      "Count Vectors: 99.55505699657206\n",
      "TF-IDF Vectors: 99.6973134216117\n",
      "Fitting insult...\n",
      "Count Vectors: 96.46301646289113\n",
      "TF-IDF Vectors: 95.35629907689994\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 98.77233331871079\n",
      "TF-IDF Vectors: 99.11074067343063\n"
     ]
    }
   ],
   "source": [
    "predictions_mnb_count = np.zeros((len(test), len(classes)))\n",
    "predictions_mnb_tfidf = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    \n",
    "    mnb.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(mnb.predict(count_train), y_train[classes[i]]))\n",
    "    predictions_mnb_count[:,i] = mnb.predict_proba(count_test)[:,1]\n",
    "    \n",
    "    mnb.fit(tfidf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(mnb.predict(tfidf_train), y_train[classes[i]]))\n",
    "    predictions_mnb_tfidf[:,i] = mnb.predict_proba(tfidf_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "838853eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_count, 'submission_mnb_count')\n",
    "to_submission_csv(predictions_mnb_tfidf, 'submission_mnb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00c9d03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mnb_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mnb_tfidf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          private   public\n",
       "submission_mnb_count.csv  0.84551  0.85581\n",
       "submission_mnb_tfidf.csv  0.82510  0.83586"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_mnb_count.csv', 'submission_mnb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1da8d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 95.13696097661855 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 97.48262528905627 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.72031885492977 {'alpha': 0.001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.42157409554368 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting obscene...\n",
      "Count Vectors: 96.70867513520626 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 98.62067668937338 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting threat...\n"
     ]
    }
   ],
   "source": [
    "predictions_mnb_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mnb_tfidf_tuned = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    \n",
    "    mnb_tuned = GridSearchCV(MultinomialNB(), parameters_mnb, scoring='f1')\n",
    "    mnb_tuned.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(mnb_tuned.predict(count_train), y_train[classes[i]]), mnb_tuned.best_params_)\n",
    "    predictions_mnb_count_tuned[:,i] = mnb_tuned.predict_proba(count_test)[:,1]\n",
    "    \n",
    "    mnb_tuned = GridSearchCV(MultinomialNB(), parameters_mnb, scoring='f1')\n",
    "    mnb_tuned.fit(tf_idf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(mnb_tuned.predict(tfidf_train), y_train[classes[i]]), mnb_tuned.best_params_)\n",
    "    predictions_mnb_tfidf_tuned[:,i] = mnb_tuned.predict_proba(tfidf_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_count_tuned, 'submission_mnb_count_tuned')\n",
    "to_submission_csv(predictions_mnb_tfidf_tuned, 'submission_mnb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "958be394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mnb_count_tuned.csv</th>\n",
       "      <td>0.75966</td>\n",
       "      <td>0.76208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mnb_tfidf_tuned.csv</th>\n",
       "      <td>0.82930</td>\n",
       "      <td>0.83952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                private   public\n",
       "submission_mnb_count_tuned.csv  0.75966  0.76208\n",
       "submission_mnb_tfidf_tuned.csv  0.82930  0.83952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.75966, 0.82930], 'public': [0.76208, 0.83952]}, \n",
    "    index=['submission_mnb_count_tuned.csv', 'submission_mnb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932fe321",
   "metadata": {},
   "source": [
    "### Ensemble Models: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39e1c1b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 90.41555169799024\n",
      "TF-IDF Vectors: 90.41555169799024\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.00044494300343\n",
      "TF-IDF Vectors: 99.00044494300343\n",
      "Fitting obscene...\n",
      "Count Vectors: 94.7051782592075\n",
      "TF-IDF Vectors: 94.7051782592075\n",
      "Fitting threat...\n",
      "Count Vectors: 99.70044682304429\n",
      "TF-IDF Vectors: 99.70170018361732\n",
      "Fitting insult...\n",
      "Count Vectors: 95.06363938309592\n",
      "TF-IDF Vectors: 95.06363938309592\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 99.11951419744189\n",
      "TF-IDF Vectors: 99.11951419744189\n"
     ]
    }
   ],
   "source": [
    "predictions_rf_count = np.zeros((len(test), len(classes)))\n",
    "predictions_rf_tfidf = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=1000, max_leaf_nodes=20, n_jobs=-1)\n",
    "    \n",
    "    rf.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(rf.predict(count_train), y_train[classes[i]]))\n",
    "    predictions_rf_count[:,i] = rf.predict_proba(count_test)[:,1]\n",
    "    \n",
    "    rf.fit(tfidf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(rf.predict(tfidf_train), y_train[classes[i]]))\n",
    "    predictions_rf_tfidf[:,i] = rf.predict_proba(tfidf_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e84cae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d970aee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_rf_count.csv</th>\n",
       "      <td>0.96735</td>\n",
       "      <td>0.96725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_rf_tfidf.csv</th>\n",
       "      <td>0.96784</td>\n",
       "      <td>0.96710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         private   public\n",
       "submission_rf_count.csv  0.96735  0.96725\n",
       "submission_rf_tfidf.csv  0.96784  0.96710"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.96735, 0.96784], 'public': [0.96725, 0.96710]}, \n",
    "    index=['submission_rf_count.csv', 'submission_rf_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c87301",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb0fee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = [{\n",
    "    'n_estimators' : [500, 1000, 1500],\n",
    "    'min_samples_split' : [2, 10, 20],\n",
    "    'max_leaf_nodes' : [15, 20, 25],\n",
    "    'min_samples_leaf' : [1, 5, 10],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09b6ba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-13287f64d78a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrf_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrf_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Count Vectors:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpredictions_rf_count_tuned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_rf_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_rf_tfidf_tuned = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    rf_tuned = GridSearchCV(RandomForestClassifier(n_jobs=-1), parameters_rf, scoring='accuracy', verbose=1)\n",
    "    \n",
    "    rf_tuned.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(rf_tuned.predict(count_train), y_train[classes[i]]))\n",
    "    predictions_rf_count_tuned[:,i] = rf_tuned.predict_proba(count_test)[:,1]\n",
    "    print(rf_tuned.best_params_, rf_tuned.best_score_)\n",
    "    \n",
    "    rf_tuned.fit(tf_idf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(rf_tuned.predict(tfidf_train), y_train[classes[i]]))\n",
    "    predictions_rf_tfidf_tuned[:,i] = rf_tuned.predict_proba(tfidf_test)[:,1]\n",
    "    print(rf_tuned.best_params_, rf_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1fa56",
   "metadata": {},
   "source": [
    "### Ensemble Models: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4706a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5865            2.41m\n",
      "         2           0.5667            2.30m\n",
      "         3           0.5524            2.20m\n",
      "         4           0.5425            2.14m\n",
      "         5           0.5329            2.10m\n",
      "         6           0.5258            2.10m\n",
      "         7           0.5180            2.10m\n",
      "         8           0.5124            2.10m\n",
      "         9           0.5050            2.10m\n",
      "        10           0.5007            2.09m\n",
      "        11           0.4942            2.06m\n",
      "        12           0.4897            2.03m\n",
      "        13           0.4840            2.02m\n",
      "        14           0.4796            2.00m\n",
      "        15           0.4761            1.99m\n",
      "        16           0.4699            1.97m\n",
      "        17           0.4667            1.93m\n",
      "        18           0.4623            1.90m\n",
      "        19           0.4596            1.87m\n",
      "        20           0.4573            1.85m\n",
      "        21           0.4547            1.83m\n",
      "        22           0.4508            1.80m\n",
      "        23           0.4489            1.77m\n",
      "        24           0.4456            1.75m\n",
      "        25           0.4434            1.72m\n",
      "        26           0.4415            1.69m\n",
      "        27           0.4370            1.67m\n",
      "        28           0.4354            1.64m\n",
      "        29           0.4328            1.62m\n",
      "        30           0.4311            1.59m\n",
      "        31           0.4290            1.57m\n",
      "        32           0.4252            1.55m\n",
      "        33           0.4236            1.52m\n",
      "        34           0.4219            1.50m\n",
      "        35           0.4203            1.47m\n",
      "        36           0.4172            1.45m\n",
      "        37           0.4155            1.43m\n",
      "        38           0.4125            1.41m\n",
      "        39           0.4112            1.39m\n",
      "        40           0.4097            1.37m\n",
      "        41           0.4082            1.35m\n",
      "        42           0.4057            1.32m\n",
      "        43           0.4046            1.30m\n",
      "        44           0.4025            1.28m\n",
      "        45           0.4014            1.25m\n",
      "        46           0.4004            1.23m\n",
      "        47           0.3985            1.20m\n",
      "        48           0.3973            1.18m\n",
      "        49           0.3963            1.16m\n",
      "        50           0.3951            1.13m\n",
      "        51           0.3929            1.11m\n",
      "        52           0.3916            1.09m\n",
      "        53           0.3902            1.06m\n",
      "        54           0.3883            1.04m\n",
      "        55           0.3872            1.02m\n",
      "        56           0.3864           59.79s\n",
      "        57           0.3849           58.48s\n",
      "        58           0.3839           57.07s\n",
      "        59           0.3831           55.72s\n",
      "        60           0.3810           54.38s\n",
      "        61           0.3802           53.08s\n",
      "        62           0.3791           51.86s\n",
      "        63           0.3784           50.51s\n",
      "        64           0.3771           49.25s\n",
      "        65           0.3761           47.99s\n",
      "        66           0.3747           46.62s\n",
      "        67           0.3738           45.33s\n",
      "        68           0.3731           44.00s\n",
      "        69           0.3723           42.73s\n",
      "        70           0.3715           41.50s\n",
      "        71           0.3698           40.36s\n",
      "        72           0.3689           39.02s\n",
      "        73           0.3681           37.66s\n",
      "        74           0.3674           36.36s\n",
      "        75           0.3656           34.99s\n",
      "        76           0.3649           33.59s\n",
      "        77           0.3641           32.20s\n",
      "        78           0.3628           30.83s\n",
      "        79           0.3620           29.40s\n",
      "        80           0.3614           27.99s\n",
      "        81           0.3607           26.59s\n",
      "        82           0.3600           25.17s\n",
      "        83           0.3589           23.78s\n",
      "        84           0.3578           22.39s\n",
      "        85           0.3567           21.01s\n",
      "        86           0.3562           19.60s\n",
      "        87           0.3555           18.20s\n",
      "        88           0.3548           16.78s\n",
      "        89           0.3533           15.38s\n",
      "        90           0.3519           13.97s\n",
      "        91           0.3514           12.57s\n",
      "        92           0.3507           11.17s\n",
      "        93           0.3501            9.77s\n",
      "        94           0.3496            8.38s\n",
      "        95           0.3491            6.98s\n",
      "        96           0.3485            5.58s\n",
      "        97           0.3480            4.19s\n",
      "        98           0.3467            2.79s\n",
      "        99           0.3461            1.40s\n",
      "       100           0.3456            0.00s\n",
      "Count Vectors: 94.33731693102129\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5862            5.50m\n",
      "         2           0.5666            5.32m\n",
      "         3           0.5519            5.17m\n",
      "         4           0.5421            5.07m\n",
      "         5           0.5320            4.98m\n",
      "         6           0.5250            4.92m\n",
      "         7           0.5170            4.89m\n",
      "         8           0.5103            4.87m\n",
      "         9           0.5027            4.82m\n",
      "        10           0.4980            4.81m\n",
      "        11           0.4937            4.77m\n",
      "        12           0.4868            4.71m\n",
      "        13           0.4824            4.65m\n",
      "        14           0.4751            4.60m\n",
      "        15           0.4720            4.53m\n",
      "        16           0.4669            4.48m\n",
      "        17           0.4639            4.45m\n",
      "        18           0.4608            4.41m\n",
      "        19           0.4553            4.37m\n",
      "        20           0.4529            4.32m\n",
      "        21           0.4505            4.27m\n",
      "        22           0.4447            4.24m\n",
      "        23           0.4405            4.21m\n",
      "        24           0.4384            4.15m\n",
      "        25           0.4364            4.09m\n",
      "        26           0.4342            4.04m\n",
      "        27           0.4317            3.99m\n",
      "        28           0.4279            3.93m\n",
      "        29           0.4260            3.87m\n",
      "        30           0.4244            3.81m\n",
      "        31           0.4210            3.75m\n",
      "        32           0.4191            3.69m\n",
      "        33           0.4174            3.63m\n",
      "        34           0.4158            3.57m\n",
      "        35           0.4141            3.51m\n",
      "        36           0.4124            3.46m\n",
      "        37           0.4100            3.40m\n",
      "        38           0.4086            3.34m\n",
      "        39           0.4068            3.28m\n",
      "        40           0.4037            3.22m\n",
      "        41           0.4026            3.17m\n",
      "        42           0.4012            3.11m\n",
      "        43           0.3997            3.06m\n",
      "        44           0.3971            3.00m\n",
      "        45           0.3953            2.94m\n",
      "        46           0.3943            2.89m\n",
      "        47           0.3932            2.83m\n",
      "        48           0.3919            2.78m\n",
      "        49           0.3908            2.73m\n",
      "        50           0.3895            2.67m\n",
      "        51           0.3883            2.62m\n",
      "        52           0.3868            2.56m\n",
      "        53           0.3842            2.51m\n",
      "        54           0.3832            2.45m\n",
      "        55           0.3822            2.40m\n",
      "        56           0.3810            2.34m\n",
      "        57           0.3799            2.29m\n",
      "        58           0.3784            2.24m\n",
      "        59           0.3773            2.18m\n",
      "        60           0.3764            2.13m\n",
      "        61           0.3748            2.07m\n",
      "        62           0.3739            2.02m\n",
      "        63           0.3729            1.97m\n",
      "        64           0.3719            1.92m\n",
      "        65           0.3710            1.86m\n",
      "        66           0.3701            1.81m\n",
      "        67           0.3694            1.76m\n",
      "        68           0.3675            1.70m\n",
      "        69           0.3667            1.65m\n",
      "        70           0.3659            1.59m\n",
      "        71           0.3645            1.54m\n",
      "        72           0.3635            1.49m\n",
      "        73           0.3626            1.43m\n",
      "        74           0.3617            1.38m\n",
      "        75           0.3602            1.33m\n",
      "        76           0.3595            1.27m\n",
      "        77           0.3588            1.22m\n",
      "        78           0.3581            1.17m\n",
      "        79           0.3574            1.11m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        80           0.3567            1.06m\n",
      "        81           0.3558            1.01m\n",
      "        82           0.3552           57.21s\n",
      "        83           0.3539           54.05s\n",
      "        84           0.3532           50.87s\n",
      "        85           0.3525           47.67s\n",
      "        86           0.3515           44.48s\n",
      "        87           0.3508           41.30s\n",
      "        88           0.3501           38.12s\n",
      "        89           0.3496           34.93s\n",
      "        90           0.3489           31.75s\n",
      "        91           0.3483           28.57s\n",
      "        92           0.3477           25.39s\n",
      "        93           0.3469           22.21s\n",
      "        94           0.3458           19.03s\n",
      "        95           0.3450           15.86s\n",
      "        96           0.3444           12.68s\n",
      "        97           0.3438            9.51s\n",
      "        98           0.3429            6.34s\n",
      "        99           0.3424            3.17s\n",
      "       100           0.3417            0.00s\n",
      "TF-IDF Vectors: 94.43382569514512\n",
      "Fitting severe_toxic...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0812            2.26m\n",
      "         2           0.0793            2.12m\n",
      "         3           0.0778            2.05m\n",
      "         4           0.0764            2.02m\n",
      "         5           0.0749            2.00m\n",
      "         6           0.0740            1.99m\n",
      "         7           0.0730            1.97m\n",
      "         8           0.0718            1.94m\n",
      "         9           0.0710            1.92m\n",
      "        10           0.0702            1.91m\n",
      "        11           0.0694            1.88m\n",
      "        12           0.0689            1.87m\n",
      "        13           0.0681            1.85m\n",
      "        14           0.0675            1.83m\n",
      "        15           0.0670            1.81m\n",
      "        16           0.0663            1.78m\n",
      "        17           0.0659            1.76m\n",
      "        18           0.0655            1.74m\n",
      "        19           0.0652            1.72m\n",
      "        20           0.0649            1.70m\n",
      "        21           0.0645            1.68m\n",
      "        22           0.0642            1.65m\n",
      "        23           0.0638            1.63m\n",
      "        24           0.0635            1.61m\n",
      "        25           0.0632            1.59m\n",
      "        26           0.0629            1.57m\n",
      "        27           0.0623            1.54m\n",
      "        28           0.0620            1.52m\n",
      "        29           0.0619            1.50m\n",
      "        30           0.0616            1.47m\n",
      "        31           0.0614            1.45m\n",
      "        32           0.0610            1.43m\n",
      "        33           0.0608            1.41m\n",
      "        34           0.0605            1.39m\n",
      "        35           0.0604            1.37m\n",
      "        36           0.0601            1.35m\n",
      "        37           0.0595            1.33m\n",
      "        38           0.0592            1.30m\n",
      "        39           0.0589            1.28m\n",
      "        40           0.0588            1.26m\n",
      "        41           0.0585            1.24m\n",
      "        42           0.0582            1.22m\n",
      "        43           0.0580            1.19m\n",
      "        44           0.0579            1.17m\n",
      "        45           0.0577            1.15m\n",
      "        46           0.0572            1.12m\n",
      "        47           0.0570            1.10m\n",
      "        48           0.0568            1.07m\n",
      "        49           0.0563            1.05m\n",
      "        50           0.0562            1.03m\n",
      "        51           0.0561            1.01m\n",
      "        52           0.0560           58.96s\n",
      "        53           0.0558           57.59s\n",
      "        54           0.0557           56.25s\n",
      "        55           0.0556           54.88s\n",
      "        56           0.0552           53.54s\n",
      "        57           0.0550           52.22s\n",
      "        58           0.0549           50.97s\n",
      "        59           0.0548           49.67s\n",
      "        60           0.0547           48.33s\n",
      "        61           0.0546           47.06s\n",
      "        62           0.0544           45.73s\n",
      "        63           0.0543           44.49s\n",
      "        64           0.0542           43.20s\n",
      "        65           0.0541           41.93s\n",
      "        66           0.0538           40.60s\n",
      "        67           0.0536           39.31s\n",
      "        68           0.0534           38.01s\n",
      "        69           0.0532           36.74s\n",
      "        70           0.0530           35.46s\n",
      "        71           0.0528           34.20s\n",
      "        72           0.0525           32.95s\n",
      "        73           0.0524           31.73s\n",
      "        74           0.0522           30.53s\n",
      "        75           0.0520           29.29s\n",
      "        76           0.0518           28.06s\n",
      "        77           0.0516           26.83s\n",
      "        78           0.0515           25.64s\n",
      "        79           0.0512           24.42s\n",
      "        80           0.0510           23.22s\n",
      "        81           0.0508           22.01s\n",
      "        82           0.0506           20.81s\n",
      "        83           0.0504           19.62s\n",
      "        84           0.0502           18.43s\n",
      "        85           0.0500           17.28s\n",
      "        86           0.0498           16.10s\n",
      "        87           0.0496           14.92s\n",
      "        88           0.0494           13.76s\n",
      "        89           0.0493           12.59s\n",
      "        90           0.0491           11.44s\n",
      "        91           0.0489           10.30s\n",
      "        92           0.0487            9.15s\n",
      "        93           0.0485            7.99s\n",
      "        94           0.0483            6.84s\n",
      "        95           0.0481            5.69s\n",
      "        96           0.0480            4.55s\n",
      "        97           0.0478            3.41s\n",
      "        98           0.0476            2.27s\n",
      "        99           0.0474            1.13s\n",
      "       100           0.0473            0.00s\n",
      "Count Vectors: 99.21414292070614\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0824            5.27m\n",
      "         2           0.0800            5.12m\n",
      "         3           0.0783            5.04m\n",
      "         4           0.0764            4.97m\n",
      "         5           0.0752            4.90m\n",
      "         6           0.0738            4.86m\n",
      "         7           0.0726            4.81m\n",
      "         8           0.0716            4.76m\n",
      "         9           0.0707            4.70m\n",
      "        10           0.0699            4.67m\n",
      "        11           0.0690            4.62m\n",
      "        12           0.0684            4.62m\n",
      "        13           0.0678            4.58m\n",
      "        14           0.0672            4.54m\n",
      "        15           0.0665            4.51m\n",
      "        16           0.0660            4.47m\n",
      "        17           0.0654            4.48m\n",
      "        18           0.0650            4.46m\n",
      "        19           0.0647            4.42m\n",
      "        20           0.0644            4.44m\n",
      "        21           0.0640            4.40m\n",
      "        22           0.0634            4.37m\n",
      "        23           0.0631            4.31m\n",
      "        24           0.0627            4.24m\n",
      "        25           0.0625            4.18m\n",
      "        26           0.0622            4.11m\n",
      "        27           0.0619            4.05m\n",
      "        28           0.0616            3.98m\n",
      "        29           0.0610            3.92m\n",
      "        30           0.0608            3.86m\n",
      "        31           0.0605            3.79m\n",
      "        32           0.0602            3.73m\n",
      "        33           0.0600            3.67m\n",
      "        34           0.0596            3.61m\n",
      "        35           0.0593            3.55m\n",
      "        36           0.0591            3.50m\n",
      "        37           0.0589            3.45m\n",
      "        38           0.0586            3.39m\n",
      "        39           0.0584            3.34m\n",
      "        40           0.0581            3.29m\n",
      "        41           0.0578            3.25m\n",
      "        42           0.0577            3.20m\n",
      "        43           0.0575            3.14m\n",
      "        44           0.0573            3.08m\n",
      "        45           0.0571            3.03m\n",
      "        46           0.0569            2.97m\n",
      "        47           0.0566            2.91m\n",
      "        48           0.0563            2.86m\n",
      "        49           0.0558            2.80m\n",
      "        50           0.0555            2.74m\n",
      "        51           0.0554            2.69m\n",
      "        52           0.0551            2.63m\n",
      "        53           0.0550            2.57m\n",
      "        54           0.0548            2.52m\n",
      "        55           0.0546            2.46m\n",
      "        56           0.0543            2.41m\n",
      "        57           0.0542            2.36m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        58           0.0540            2.30m\n",
      "        59           0.0538            2.25m\n",
      "        60           0.0536            2.19m\n",
      "        61           0.0535            2.14m\n",
      "        62           0.0532            2.08m\n",
      "        63           0.0529            2.03m\n",
      "        64           0.0527            1.97m\n",
      "        65           0.0527            1.93m\n",
      "        66           0.0525            1.87m\n",
      "        67           0.0523            1.82m\n",
      "        68           0.0522            1.76m\n",
      "        69           0.0519            1.71m\n",
      "        70           0.0519            1.65m\n",
      "        71           0.0517            1.60m\n",
      "        72           0.0517            1.54m\n",
      "        73           0.0515            1.49m\n",
      "        74           0.0514            1.43m\n",
      "        75           0.0513            1.38m\n",
      "        76           0.0510            1.32m\n",
      "        77           0.0508            1.27m\n",
      "        78           0.0506            1.21m\n",
      "        79           0.0505            1.16m\n",
      "        80           0.0504            1.10m\n",
      "        81           0.0503            1.05m\n",
      "        82           0.0502           59.42s\n",
      "        83           0.0501           56.10s\n",
      "        84           0.0500           52.77s\n",
      "        85           0.0498           49.43s\n",
      "        86           0.0497           46.12s\n",
      "        87           0.0496           42.79s\n",
      "        88           0.0496           39.47s\n",
      "        89           0.0495           36.15s\n",
      "        90           0.0495           32.83s\n",
      "        91           0.0494           29.52s\n",
      "        92           0.0493           26.22s\n",
      "        93           0.0491           22.93s\n",
      "        94           0.0489           19.64s\n",
      "        95           0.0488           16.36s\n",
      "        96           0.0487           13.07s\n",
      "        97           0.0487            9.80s\n",
      "        98           0.0485            6.53s\n",
      "        99           0.0484            3.26s\n",
      "       100           0.0482            0.00s\n",
      "TF-IDF Vectors: 99.22730320672302\n",
      "Fitting obscene...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3395            2.26m\n",
      "         2           0.3203            2.15m\n",
      "         3           0.3052            2.09m\n",
      "         4           0.2932            2.08m\n",
      "         5           0.2856            2.04m\n",
      "         6           0.2794            2.01m\n",
      "         7           0.2719            1.98m\n",
      "         8           0.2669            1.96m\n",
      "         9           0.2622            1.93m\n",
      "        10           0.2580            1.91m\n",
      "        11           0.2536            1.89m\n",
      "        12           0.2506            1.87m\n",
      "        13           0.2458            1.85m\n",
      "        14           0.2431            1.83m\n",
      "        15           0.2406            1.81m\n",
      "        16           0.2375            1.78m\n",
      "        17           0.2354            1.76m\n",
      "        18           0.2329            1.75m\n",
      "        19           0.2309            1.72m\n",
      "        20           0.2290            1.71m\n",
      "        21           0.2273            1.68m\n",
      "        22           0.2238            1.67m\n",
      "        23           0.2217            1.65m\n",
      "        24           0.2202            1.63m\n",
      "        25           0.2184            1.61m\n",
      "        26           0.2171            1.59m\n",
      "        27           0.2139            1.57m\n",
      "        28           0.2119            1.55m\n",
      "        29           0.2100            1.52m\n",
      "        30           0.2076            1.51m\n",
      "        31           0.2066            1.48m\n",
      "        32           0.2050            1.46m\n",
      "        33           0.2037            1.44m\n",
      "        34           0.2018            1.42m\n",
      "        35           0.2005            1.40m\n",
      "        36           0.1996            1.38m\n",
      "        37           0.1987            1.36m\n",
      "        38           0.1974            1.34m\n",
      "        39           0.1953            1.32m\n",
      "        40           0.1945            1.30m\n",
      "        41           0.1938            1.27m\n",
      "        42           0.1926            1.25m\n",
      "        43           0.1911            1.23m\n",
      "        44           0.1902            1.21m\n",
      "        45           0.1895            1.19m\n",
      "        46           0.1885            1.17m\n",
      "        47           0.1879            1.14m\n",
      "        48           0.1868            1.12m\n",
      "        49           0.1853            1.10m\n",
      "        50           0.1846            1.08m\n",
      "        51           0.1840            1.06m\n",
      "        52           0.1833            1.04m\n",
      "        53           0.1820            1.02m\n",
      "        54           0.1813           59.68s\n",
      "        55           0.1807           58.34s\n",
      "        56           0.1799           57.07s\n",
      "        57           0.1794           55.76s\n",
      "        58           0.1786           54.42s\n",
      "        59           0.1778           53.12s\n",
      "        60           0.1773           51.84s\n",
      "        61           0.1762           50.52s\n",
      "        62           0.1756           49.23s\n",
      "        63           0.1750           47.92s\n",
      "        64           0.1745           46.60s\n",
      "        65           0.1739           45.30s\n",
      "        66           0.1734           44.05s\n",
      "        67           0.1727           42.74s\n",
      "        68           0.1719           41.45s\n",
      "        69           0.1709           40.16s\n",
      "        70           0.1704           38.90s\n",
      "        71           0.1699           37.58s\n",
      "        72           0.1694           36.29s\n",
      "        73           0.1687           35.02s\n",
      "        74           0.1678           33.73s\n",
      "        75           0.1672           32.45s\n",
      "        76           0.1667           31.16s\n",
      "        77           0.1663           29.85s\n",
      "        78           0.1659           28.55s\n",
      "        79           0.1655           27.26s\n",
      "        80           0.1648           25.96s\n",
      "        81           0.1644           24.66s\n",
      "        82           0.1639           23.37s\n",
      "        83           0.1635           22.06s\n",
      "        84           0.1630           20.76s\n",
      "        85           0.1622           19.48s\n",
      "        86           0.1617           18.19s\n",
      "        87           0.1614           16.88s\n",
      "        88           0.1611           15.59s\n",
      "        89           0.1607           14.29s\n",
      "        90           0.1602           12.99s\n",
      "        91           0.1597           11.70s\n",
      "        92           0.1593           10.41s\n",
      "        93           0.1588            9.10s\n",
      "        94           0.1584            7.80s\n",
      "        95           0.1580            6.50s\n",
      "        96           0.1577            5.20s\n",
      "        97           0.1572            3.90s\n",
      "        98           0.1565            2.60s\n",
      "        99           0.1561            1.30s\n",
      "       100           0.1557            0.00s\n",
      "Count Vectors: 97.60106786320823\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3394            5.25m\n",
      "         2           0.3197            5.12m\n",
      "         3           0.3038            5.04m\n",
      "         4           0.2922            4.97m\n",
      "         5           0.2847            4.92m\n",
      "         6           0.2784            4.86m\n",
      "         7           0.2723            4.81m\n",
      "         8           0.2650            4.76m\n",
      "         9           0.2610            4.70m\n",
      "        10           0.2570            4.65m\n",
      "        11           0.2529            4.60m\n",
      "        12           0.2489            4.55m\n",
      "        13           0.2449            4.50m\n",
      "        14           0.2424            4.45m\n",
      "        15           0.2394            4.39m\n",
      "        16           0.2364            4.35m\n",
      "        17           0.2341            4.30m\n",
      "        18           0.2321            4.25m\n",
      "        19           0.2296            4.19m\n",
      "        20           0.2278            4.14m\n",
      "        21           0.2260            4.09m\n",
      "        22           0.2236            4.04m\n",
      "        23           0.2216            3.99m\n",
      "        24           0.2179            3.94m\n",
      "        25           0.2158            3.89m\n",
      "        26           0.2144            3.84m\n",
      "        27           0.2130            3.78m\n",
      "        28           0.2108            3.73m\n",
      "        29           0.2081            3.68m\n",
      "        30           0.2064            3.63m\n",
      "        31           0.2053            3.58m\n",
      "        32           0.2042            3.53m\n",
      "        33           0.2027            3.48m\n",
      "        34           0.2014            3.43m\n",
      "        35           0.2001            3.38m\n",
      "        36           0.1979            3.33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        37           0.1965            3.28m\n",
      "        38           0.1957            3.23m\n",
      "        39           0.1948            3.17m\n",
      "        40           0.1937            3.12m\n",
      "        41           0.1926            3.07m\n",
      "        42           0.1908            3.02m\n",
      "        43           0.1896            2.97m\n",
      "        44           0.1887            2.91m\n",
      "        45           0.1877            2.86m\n",
      "        46           0.1869            2.81m\n",
      "        47           0.1862            2.76m\n",
      "        48           0.1853            2.71m\n",
      "        49           0.1845            2.65m\n",
      "        50           0.1836            2.60m\n",
      "        51           0.1816            2.55m\n",
      "        52           0.1810            2.50m\n",
      "        53           0.1802            2.45m\n",
      "        54           0.1796            2.40m\n",
      "        55           0.1788            2.35m\n",
      "        56           0.1778            2.29m\n",
      "        57           0.1772            2.24m\n",
      "        58           0.1757            2.19m\n",
      "        59           0.1749            2.14m\n",
      "        60           0.1743            2.09m\n",
      "        61           0.1736            2.03m\n",
      "        62           0.1732            1.98m\n",
      "        63           0.1726            1.93m\n",
      "        64           0.1720            1.88m\n",
      "        65           0.1715            1.83m\n",
      "        66           0.1709            1.77m\n",
      "        67           0.1702            1.72m\n",
      "        68           0.1697            1.67m\n",
      "        69           0.1684            1.62m\n",
      "        70           0.1677            1.56m\n",
      "        71           0.1669            1.51m\n",
      "        72           0.1665            1.46m\n",
      "        73           0.1656            1.41m\n",
      "        74           0.1652            1.36m\n",
      "        75           0.1648            1.30m\n",
      "        76           0.1642            1.25m\n",
      "        77           0.1637            1.20m\n",
      "        78           0.1633            1.15m\n",
      "        79           0.1627            1.10m\n",
      "        80           0.1618            1.04m\n",
      "        81           0.1614           59.44s\n",
      "        82           0.1605           56.31s\n",
      "        83           0.1600           53.18s\n",
      "        84           0.1597           50.06s\n",
      "        85           0.1594           46.93s\n",
      "        86           0.1589           43.79s\n",
      "        87           0.1585           40.66s\n",
      "        88           0.1580           37.53s\n",
      "        89           0.1575           34.40s\n",
      "        90           0.1570           31.27s\n",
      "        91           0.1566           28.15s\n",
      "        92           0.1562           25.02s\n",
      "        93           0.1558           21.89s\n",
      "        94           0.1553           18.76s\n",
      "        95           0.1550           15.63s\n",
      "        96           0.1543           12.51s\n",
      "        97           0.1540            9.38s\n",
      "        98           0.1537            6.25s\n",
      "        99           0.1534            3.13s\n",
      "       100           0.1529            0.00s\n",
      "TF-IDF Vectors: 97.68378966102863\n",
      "Fitting threat...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0493            2.30m\n",
      "         2           0.0384            2.17m\n",
      "         3           0.0367            2.14m\n",
      "         4           0.0356            2.09m\n",
      "         5           5.6724            2.05m\n",
      "         6 325854827083698219568101057963223825814381632814998035103744.0000            2.02m\n",
      "         7 325854827083698219568101057963223825814381632814998035103744.0000            2.01m\n",
      "         8 325854827083698219568101057963223825814381632814998035103744.0000            1.98m\n",
      "         9 325854827083698219568101057963223825814381632814998035103744.0000            1.95m\n",
      "        10 325854827083698219568101057963223825814381632814998035103744.0000            1.92m\n",
      "        11 325854827083698219568101057963223825814381632814998035103744.0000            1.90m\n",
      "        12 325854827083698219568101057963223825814381632814998035103744.0000            1.87m\n",
      "        13 325854827083698219568101057963223825814381632814998035103744.0000            1.85m\n",
      "        14 325854827083698219568101057963223825814381632814998035103744.0000            1.82m\n",
      "        15 325854827083698219568101057963223825814381632814998035103744.0000            1.80m\n",
      "        16 325854827083698219568101057963223825814381632814998035103744.0000            1.78m\n",
      "        17 325854827083698219568101057963223825814381632814998035103744.0000            1.76m\n",
      "        18 325854827083698219568101057963223825814381632814998035103744.0000            1.73m\n",
      "        19 325854827083698219568101057963223825814381632814998035103744.0000            1.71m\n",
      "        20 325854827083698219568101057963223825814381632814998035103744.0000            1.69m\n",
      "        21 325854827083698219568101057963223825814381632814998035103744.0000            1.67m\n",
      "        22 325854827083698219568101057963223825814381632814998035103744.0000            1.65m\n",
      "        23 325854827083698219568101057963223825814381632814998035103744.0000            1.62m\n",
      "        24 325854827083698219568101057963223825814381632814998035103744.0000            1.60m\n",
      "        25 325854827083698219568101057963223825814381632814998035103744.0000            1.58m\n",
      "        26 325854827083698219568101057963223825814381632814998035103744.0000            1.56m\n",
      "        27 325854827083698219568101057963223825814381632814998035103744.0000            1.54m\n",
      "        28 325854827083698219568101057963223825814381632814998035103744.0000            1.52m\n",
      "        29 325854827083698219568101057963223825814381632814998035103744.0000            1.50m\n",
      "        30 325854827083698219568101057963223825814381632814998035103744.0000            1.47m\n",
      "        31 325854827083698219568101057963223825814381632814998035103744.0000            1.45m\n",
      "        32 325854827083698219568101057963223825814381632814998035103744.0000            1.43m\n",
      "        33 325854827083698219568101057963223825814381632814998035103744.0000            1.41m\n",
      "        34 325854827083698219568101057963223825814381632814998035103744.0000            1.39m\n",
      "        35 325854827083698219568101057963223825814381632814998035103744.0000            1.37m\n",
      "        36 325854827083698219568101057963223825814381632814998035103744.0000            1.35m\n",
      "        37 325854827083698219568101057963223825814381632814998035103744.0000            1.33m\n",
      "        38 325854827083698219568101057963223825814381632814998035103744.0000            1.31m\n",
      "        39 325854827083698219568101057963223825814381632814998035103744.0000            1.29m\n",
      "        40 325854827083698219568101057963223825814381632814998035103744.0000            1.26m\n",
      "        41 325854827083698219568101057963223825814381632814998035103744.0000            1.24m\n",
      "        42 325854827083698219568101057963223825814381632814998035103744.0000            1.22m\n",
      "        43 325854827083698219568101057963223825814381632814998035103744.0000            1.20m\n",
      "        44 325854827083698219568101057963223825814381632814998035103744.0000            1.18m\n",
      "        45 325854827083698219568101057963223825814381632814998035103744.0000            1.16m\n",
      "        46 325854827083698219568101057963223825814381632814998035103744.0000            1.14m\n",
      "        47 325854827083698219568101057963223825814381632814998035103744.0000            1.12m\n",
      "        48 325854827083698219568101057963223825814381632814998035103744.0000            1.10m\n",
      "        49 325854827083698219568101057963223825814381632814998035103744.0000            1.07m\n",
      "        50 325854827083698219568101057963223825814381632814998035103744.0000            1.05m\n",
      "        51 325854827083698219568101057963223825814381632814998035103744.0000            1.03m\n",
      "        52 325854827083698219568101057963223825814381632814998035103744.0000            1.01m\n",
      "        53 325854827083698219568101057963223825814381632814998035103744.0000           59.38s\n",
      "        54 325854827083698219568101057963223825814381632814998035103744.0000           58.15s\n",
      "        55 325854827083698219568101057963223825814381632814998035103744.0000           56.94s\n",
      "        56 325854827083698219568101057963223825814381632814998035103744.0000           55.56s\n",
      "        57 325854827083698219568101057963223825814381632814998035103744.0000           54.18s\n",
      "        58 325854827083698219568101057963223825814381632814998035103744.0000           52.85s\n",
      "        59 325854827083698219568101057963223825814381632814998035103744.0000           51.50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        60 325854827083698219568101057963223825814381632814998035103744.0000           50.14s\n",
      "        61 325854827083698219568101057963223825814381632814998035103744.0000           48.80s\n",
      "        62 325854827083698219568101057963223825814381632814998035103744.0000           47.47s\n",
      "        63 325854827083698219568101057963223825814381632814998035103744.0000           46.13s\n",
      "        64 325854827083698219568101057963223825814381632814998035103744.0000           44.81s\n",
      "        65 325854827083698219568101057963223825814381632814998035103744.0000           43.50s\n",
      "        66 325854827083698219568101057963223825814381632814998035103744.0000           42.21s\n",
      "        67 325854827083698219568101057963223825814381632814998035103744.0000           40.91s\n",
      "        68 325854827083698219568101057963223825814381632814998035103744.0000           39.61s\n",
      "        69 325854827083698219568101057963223825814381632814998035103744.0000           38.32s\n",
      "        70 325854827083698219568101057963223825814381632814998035103744.0000           37.03s\n",
      "        71 325854827083698219568101057963223825814381632814998035103744.0000           35.75s\n",
      "        72 325854827083698219568101057963223825814381632814998035103744.0000           34.46s\n",
      "        73 325854827083698219568101057963223825814381632814998035103744.0000           33.20s\n",
      "        74 325854827083698219568101057963223825814381632814998035103744.0000           31.93s\n",
      "        75 325854827083698219568101057963223825814381632814998035103744.0000           30.66s\n",
      "        76 325854827083698219568101057963223825814381632814998035103744.0000           29.40s\n",
      "        77 325854827083698219568101057963223825814381632814998035103744.0000           28.15s\n",
      "        78 325854827083698219568101057963223825814381632814998035103744.0000           26.90s\n",
      "        79 325854827083698219568101057963223825814381632814998035103744.0000           25.65s\n",
      "        80 325854827083698219568101057963223825814381632814998035103744.0000           24.40s\n",
      "        81 325854827083698219568101057963223825814381632814998035103744.0000           23.17s\n",
      "        82 325854827083698219568101057963223825814381632814998035103744.0000           21.94s\n",
      "        83 325854827083698219568101057963223825814381632814998035103744.0000           20.70s\n",
      "        84 325854827083698219568101057963223825814381632814998035103744.0000           19.46s\n",
      "        85 325854827083698219568101057963223825814381632814998035103744.0000           18.23s\n",
      "        86 325854827083698219568101057963223825814381632814998035103744.0000           17.00s\n",
      "        87 325854827083698219568101057963223825814381632814998035103744.0000           15.77s\n",
      "        88 325854827083698219568101057963223825814381632814998035103744.0000           14.55s\n",
      "        89 325854827083698219568101057963223825814381632814998035103744.0000           13.33s\n",
      "        90 325854827083698219568101057963223825814381632814998035103744.0000           12.10s\n",
      "        91 325854827083698219568101057963223825814381632814998035103744.0000           10.88s\n",
      "        92 325854827083698219568101057963223825814381632814998035103744.0000            9.67s\n",
      "        93 325854827083698219568101057963223825814381632814998035103744.0000            8.45s\n",
      "        94 325854827083698219568101057963223825814381632814998035103744.0000            7.24s\n",
      "        95 325854827083698219568101057963223825814381632814998035103744.0000            6.03s\n",
      "        96 325854827083698219568101057963223825814381632814998035103744.0000            4.82s\n",
      "        97 325854827083698219568101057963223825814381632814998035103744.0000            3.61s\n",
      "        98 325854827083698219568101057963223825814381632814998035103744.0000            2.41s\n",
      "        99 325854827083698219568101057963223825814381632814998035103744.0000            1.20s\n",
      "       100 325854827083698219568101057963223825814381632814998035103744.0000            0.00s\n",
      "Count Vectors: 99.74118104166797\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0457            5.45m\n",
      "         2         540.0673            5.30m\n",
      "         3    35116364.1319            5.19m\n",
      "         4    35116359.1794            5.12m\n",
      "         5    35116406.4008            5.05m\n",
      "         6    35116406.4005            4.99m\n",
      "         7    35116406.4002            4.94m\n",
      "         8    35116406.4011            4.88m\n",
      "         9    35116406.3992            4.81m\n",
      "        10    35116406.3989            4.75m\n",
      "        11    35116406.3984            4.69m\n",
      "        12    35116343.4200            4.63m\n",
      "        13    35116343.4199            4.57m\n",
      "        14    35116343.4194            4.50m\n",
      "        15    35116343.4189            4.44m\n",
      "        16    35116343.4199            4.38m\n",
      "        17    35116343.4175            4.32m\n",
      "        18    35116343.4179            4.26m\n",
      "        19    35116343.4168            4.20m\n",
      "        20    35116343.4167            4.15m\n",
      "        21    35116343.4167            4.10m\n",
      "        22    35116343.4159            4.04m\n",
      "        23    35116343.4158            3.99m\n",
      "        24    35116343.4156            3.93m\n",
      "        25    35116343.4156            3.87m\n",
      "        26    35116343.4156            3.82m\n",
      "        27    35116343.4156            3.77m\n",
      "        28    35116343.4154            3.71m\n",
      "        29    35116343.4154            3.66m\n",
      "        30    35116343.4154            3.60m\n",
      "        31    35116343.4085            3.55m\n",
      "        32    35116343.4084            3.50m\n",
      "        33    35116343.4081            3.45m\n",
      "        34    35116343.4078            3.40m\n",
      "        35    35116343.4077            3.35m\n",
      "        36    35116343.4076            3.29m\n",
      "        37    35116343.4075            3.24m\n",
      "        38    35116343.4075            3.19m\n",
      "        39    35116343.4075            3.13m\n",
      "        40    35116343.4075            3.08m\n",
      "        41    35116343.4075            3.03m\n",
      "        42    35116343.4074            2.98m\n",
      "        43    35116343.4074            2.92m\n",
      "        44    35116343.4074            2.87m\n",
      "        45    35116343.4074            2.82m\n",
      "        46    35116343.4074            2.77m\n",
      "        47    35116343.4074            2.72m\n",
      "        48    35116343.4074            2.66m\n",
      "        49    35116343.4074            2.61m\n",
      "        50    35116343.4074            2.56m\n",
      "        51    35116343.4074            2.51m\n",
      "        52    35116343.4074            2.45m\n",
      "        53    35116343.4073            2.40m\n",
      "        54    35116343.4073            2.35m\n",
      "        55    35116343.4073            2.30m\n",
      "        56    35116343.4073            2.25m\n",
      "        57    35116343.4073            2.20m\n",
      "        58    35116343.4073            2.15m\n",
      "        59    35116343.4073            2.09m\n",
      "        60    35116343.4073            2.04m\n",
      "        61    35116343.4073            1.99m\n",
      "        62    35116343.4073            1.94m\n",
      "        63    35116343.4073            1.89m\n",
      "        64    35116343.4073            1.84m\n",
      "        65    35116343.4073            1.79m\n",
      "        66    35116343.4073            1.74m\n",
      "        67    35116343.4073            1.68m\n",
      "        68    35116343.4073            1.63m\n",
      "        69    35116343.4073            1.58m\n",
      "        70    35116343.4072            1.53m\n",
      "        71    35116343.4072            1.48m\n",
      "        72    35116343.4072            1.43m\n",
      "        73    35116343.4072            1.38m\n",
      "        74    35116343.4072            1.33m\n",
      "        75    35116343.4072            1.27m\n",
      "        76    35116343.4072            1.22m\n",
      "        77    35116343.4072            1.17m\n",
      "        78    35116343.4072            1.12m\n",
      "        79    35116343.4072            1.07m\n",
      "        80    35116343.4072            1.02m\n",
      "        81    35116343.4072           58.09s\n",
      "        82    35116343.4072           55.04s\n",
      "        83    35116343.4072           51.98s\n",
      "        84    35116343.4071           48.91s\n",
      "        85    35116343.4071           45.85s\n",
      "        86    35116343.4071           42.80s\n",
      "        87    35116343.4071           39.74s\n",
      "        88    35116343.4071           36.69s\n",
      "        89    35116343.4071           33.63s\n",
      "        90    35116343.4071           30.61s\n",
      "        91    35116343.4071           27.56s\n",
      "        92    35116343.4071           24.48s\n",
      "        93    35116343.4071           21.42s\n",
      "        94    35116343.4071           18.35s\n",
      "        95    35116343.4071           15.29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        96    35116343.4071           12.23s\n",
      "        97    35116343.4071            9.17s\n",
      "        98    35116343.4071            6.11s\n",
      "        99    35116343.4071            3.06s\n",
      "       100    35116343.4071            0.00s\n",
      "TF-IDF Vectors: 99.78066189971862\n",
      "Fitting insult...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3446            2.23m\n",
      "         2           0.3304            2.12m\n",
      "         3           0.3197            2.06m\n",
      "         4           0.3116            2.01m\n",
      "         5           0.3040            2.00m\n",
      "         6           0.2994            1.97m\n",
      "         7           0.2953            1.95m\n",
      "         8           0.2903            1.92m\n",
      "         9           0.2856            1.91m\n",
      "        10           0.2830            1.89m\n",
      "        11           0.2796            1.86m\n",
      "        12           0.2771            1.84m\n",
      "        13           0.2739            1.82m\n",
      "        14           0.2715            1.79m\n",
      "        15           0.2697            1.77m\n",
      "        16           0.2675            1.75m\n",
      "        17           0.2651            1.73m\n",
      "        18           0.2619            1.71m\n",
      "        19           0.2602            1.69m\n",
      "        20           0.2584            1.67m\n",
      "        21           0.2544            1.65m\n",
      "        22           0.2529            1.63m\n",
      "        23           0.2513            1.61m\n",
      "        24           0.2501            1.59m\n",
      "        25           0.2471            1.57m\n",
      "        26           0.2457            1.55m\n",
      "        27           0.2447            1.53m\n",
      "        28           0.2434            1.51m\n",
      "        29           0.2412            1.49m\n",
      "        30           0.2400            1.47m\n",
      "        31           0.2390            1.45m\n",
      "        32           0.2379            1.43m\n",
      "        33           0.2353            1.41m\n",
      "        34           0.2342            1.39m\n",
      "        35           0.2333            1.37m\n",
      "        36           0.2325            1.35m\n",
      "        37           0.2318            1.33m\n",
      "        38           0.2308            1.31m\n",
      "        39           0.2291            1.29m\n",
      "        40           0.2283            1.27m\n",
      "        41           0.2274            1.24m\n",
      "        42           0.2266            1.22m\n",
      "        43           0.2256            1.20m\n",
      "        44           0.2249            1.18m\n",
      "        45           0.2232            1.16m\n",
      "        46           0.2226            1.14m\n",
      "        47           0.2220            1.12m\n",
      "        48           0.2213            1.10m\n",
      "        49           0.2205            1.08m\n",
      "        50           0.2188            1.06m\n",
      "        51           0.2181            1.04m\n",
      "        52           0.2176            1.02m\n",
      "        53           0.2160           59.76s\n",
      "        54           0.2153           58.52s\n",
      "        55           0.2145           57.23s\n",
      "        56           0.2140           55.98s\n",
      "        57           0.2135           54.73s\n",
      "        58           0.2125           53.47s\n",
      "        59           0.2119           52.21s\n",
      "        60           0.2113           50.98s\n",
      "        61           0.2108           49.67s\n",
      "        62           0.2104           48.41s\n",
      "        63           0.2091           47.17s\n",
      "        64           0.2086           45.89s\n",
      "        65           0.2081           44.64s\n",
      "        66           0.2070           43.36s\n",
      "        67           0.2065           42.10s\n",
      "        68           0.2060           40.81s\n",
      "        69           0.2056           39.54s\n",
      "        70           0.2052           38.28s\n",
      "        71           0.2049           36.99s\n",
      "        72           0.2045           35.72s\n",
      "        73           0.2041           34.49s\n",
      "        74           0.2037           33.21s\n",
      "        75           0.2032           31.93s\n",
      "        76           0.2024           30.64s\n",
      "        77           0.2021           29.36s\n",
      "        78           0.2017           28.09s\n",
      "        79           0.2010           26.83s\n",
      "        80           0.2006           25.55s\n",
      "        81           0.2003           24.28s\n",
      "        82           0.1999           22.99s\n",
      "        83           0.1992           21.71s\n",
      "        84           0.1989           20.42s\n",
      "        85           0.1977           19.15s\n",
      "        86           0.1971           17.88s\n",
      "        87           0.1967           16.60s\n",
      "        88           0.1963           15.32s\n",
      "        89           0.1960           14.04s\n",
      "        90           0.1957           12.77s\n",
      "        91           0.1954           11.49s\n",
      "        92           0.1951           10.22s\n",
      "        93           0.1948            8.93s\n",
      "        94           0.1938            7.66s\n",
      "        95           0.1934            6.38s\n",
      "        96           0.1931            5.11s\n",
      "        97           0.1927            3.83s\n",
      "        98           0.1924            2.55s\n",
      "        99           0.1920            1.28s\n",
      "       100           0.1912            0.00s\n",
      "Count Vectors: 96.8609584448302\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3442            5.15m\n",
      "         2           0.3299            5.01m\n",
      "         3           0.3188            4.94m\n",
      "         4           0.3104            4.88m\n",
      "         5           0.3028            4.85m\n",
      "         6           0.2982            4.79m\n",
      "         7           0.2925            4.74m\n",
      "         8           0.2876            4.68m\n",
      "         9           0.2837            4.64m\n",
      "        10           0.2805            4.59m\n",
      "        11           0.2769            4.54m\n",
      "        12           0.2746            4.48m\n",
      "        13           0.2723            4.44m\n",
      "        14           0.2701            4.38m\n",
      "        15           0.2676            4.33m\n",
      "        16           0.2655            4.28m\n",
      "        17           0.2633            4.23m\n",
      "        18           0.2609            4.18m\n",
      "        19           0.2576            4.13m\n",
      "        20           0.2559            4.08m\n",
      "        21           0.2546            4.02m\n",
      "        22           0.2529            3.98m\n",
      "        23           0.2490            3.92m\n",
      "        24           0.2476            3.87m\n",
      "        25           0.2462            3.82m\n",
      "        26           0.2430            3.77m\n",
      "        27           0.2416            3.72m\n",
      "        28           0.2405            3.67m\n",
      "        29           0.2395            3.62m\n",
      "        30           0.2385            3.57m\n",
      "        31           0.2371            3.52m\n",
      "        32           0.2341            3.46m\n",
      "        33           0.2330            3.42m\n",
      "        34           0.2320            3.36m\n",
      "        35           0.2299            3.31m\n",
      "        36           0.2291            3.26m\n",
      "        37           0.2281            3.21m\n",
      "        38           0.2271            3.16m\n",
      "        39           0.2261            3.11m\n",
      "        40           0.2239            3.06m\n",
      "        41           0.2229            3.01m\n",
      "        42           0.2215            2.96m\n",
      "        43           0.2208            2.91m\n",
      "        44           0.2201            2.86m\n",
      "        45           0.2192            2.81m\n",
      "        46           0.2185            2.76m\n",
      "        47           0.2177            2.71m\n",
      "        48           0.2170            2.66m\n",
      "        49           0.2164            2.61m\n",
      "        50           0.2147            2.56m\n",
      "        51           0.2139            2.51m\n",
      "        52           0.2132            2.45m\n",
      "        53           0.2126            2.40m\n",
      "        54           0.2121            2.35m\n",
      "        55           0.2114            2.30m\n",
      "        56           0.2108            2.25m\n",
      "        57           0.2101            2.20m\n",
      "        58           0.2092            2.15m\n",
      "        59           0.2078            2.10m\n",
      "        60           0.2072            2.04m\n",
      "        61           0.2067            1.99m\n",
      "        62           0.2060            1.94m\n",
      "        63           0.2053            1.89m\n",
      "        64           0.2048            1.84m\n",
      "        65           0.2044            1.79m\n",
      "        66           0.2033            1.74m\n",
      "        67           0.2028            1.69m\n",
      "        68           0.2024            1.64m\n",
      "        69           0.2020            1.59m\n",
      "        70           0.2016            1.53m\n",
      "        71           0.2011            1.48m\n",
      "        72           0.2007            1.43m\n",
      "        73           0.2003            1.38m\n",
      "        74           0.1999            1.33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        75           0.1994            1.28m\n",
      "        76           0.1989            1.23m\n",
      "        77           0.1979            1.18m\n",
      "        78           0.1974            1.13m\n",
      "        79           0.1970            1.07m\n",
      "        80           0.1967            1.02m\n",
      "        81           0.1964           58.33s\n",
      "        82           0.1960           55.27s\n",
      "        83           0.1957           52.19s\n",
      "        84           0.1949           49.12s\n",
      "        85           0.1945           46.05s\n",
      "        86           0.1941           42.98s\n",
      "        87           0.1937           39.90s\n",
      "        88           0.1926           36.83s\n",
      "        89           0.1922           33.76s\n",
      "        90           0.1918           30.69s\n",
      "        91           0.1915           27.62s\n",
      "        92           0.1910           24.55s\n",
      "        93           0.1901           21.48s\n",
      "        94           0.1898           18.41s\n",
      "        95           0.1894           15.35s\n",
      "        96           0.1891           12.28s\n",
      "        97           0.1888            9.21s\n",
      "        98           0.1885            6.14s\n",
      "        99           0.1877            3.07s\n",
      "       100           0.1873            0.00s\n",
      "TF-IDF Vectors: 96.96498737239223\n",
      "Fitting identity_hate...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0813            2.25m\n",
      "         2           0.0772            2.12m\n",
      "         3           0.0757            2.08m\n",
      "         4           0.0738            2.03m\n",
      "         5           0.0726            2.01m\n",
      "         6           0.0719            1.98m\n",
      "         7           0.0712            1.95m\n",
      "         8           0.0700            1.92m\n",
      "         9           0.0692            1.91m\n",
      "        10           0.0680            1.89m\n",
      "        11           0.0672            1.88m\n",
      "        12           0.0666            1.85m\n",
      "        13           0.0659            1.83m\n",
      "        14           0.0651            1.82m\n",
      "        15           0.0645            1.80m\n",
      "        16           0.0638            1.78m\n",
      "        17           0.0635            1.76m\n",
      "        18           0.0628            1.74m\n",
      "        19           0.0623            1.72m\n",
      "        20           0.0622            1.69m\n",
      "        21           0.0618            1.67m\n",
      "        22           0.0612            1.65m\n",
      "        23           0.0603            1.63m\n",
      "        24           0.0596            1.61m\n",
      "        25           0.0592            1.58m\n",
      "        26           0.0587            1.56m\n",
      "        27           0.0584            1.54m\n",
      "        28           0.0583            1.51m\n",
      "        29           0.0580            1.50m\n",
      "        30           0.0578            1.47m\n",
      "        31           0.0574            1.45m\n",
      "        32           0.0569            1.42m\n",
      "        33           0.0567            1.40m\n",
      "        34           0.0566            1.38m\n",
      "        35           0.0565            1.36m\n",
      "        36           0.0562            1.34m\n",
      "        37           0.0559            1.32m\n",
      "        38           0.0559            1.29m\n",
      "        39           0.0556            1.27m\n",
      "        40           0.0553            1.25m\n",
      "        41           0.0549            1.23m\n",
      "        42           0.0547            1.21m\n",
      "        43           0.0546            1.19m\n",
      "        44           0.0545            1.17m\n",
      "        45           0.0543            1.15m\n",
      "        46           0.0539            1.13m\n",
      "        47           0.0535            1.11m\n",
      "        48           0.0535            1.08m\n",
      "        49           0.0531            1.06m\n",
      "        50           0.0528            1.04m\n",
      "        51           0.0526            1.02m\n",
      "        52           0.0524           59.71s\n",
      "        53           0.0522           58.33s\n",
      "        54           0.0520           56.98s\n",
      "        55           0.0518           55.62s\n",
      "        56           0.0517           54.40s\n",
      "        57           0.0515           53.10s\n",
      "        58           0.0513           51.81s\n",
      "        59           0.0511           50.48s\n",
      "        60           0.0508           49.17s\n",
      "        61           0.0506           47.84s\n",
      "        62           0.0504           46.66s\n",
      "        63           0.0502           45.38s\n",
      "        64           0.0500           44.08s\n",
      "        65           0.0498           42.80s\n",
      "        66           0.0496           41.52s\n",
      "        67           0.0494           40.24s\n",
      "        68           0.0492           38.97s\n",
      "        69           0.0490           37.69s\n",
      "        70           0.0488           36.42s\n",
      "        71           0.0486           35.16s\n",
      "        72           0.0483           33.91s\n",
      "        73           0.0481           32.66s\n",
      "        74           0.0479           31.41s\n",
      "        75           0.0478           30.21s\n",
      "        76           0.0476           28.97s\n",
      "        77           0.0474           27.72s\n",
      "        78           0.0472           26.54s\n",
      "        79           0.0470           25.32s\n",
      "        80           0.0468           24.08s\n",
      "        81           0.0466           22.85s\n",
      "        82           0.0464           21.62s\n",
      "        83           0.0462           20.41s\n",
      "        84           0.0460           19.19s\n",
      "        85           0.0458           18.01s\n",
      "        86           0.0456           16.79s\n",
      "        87           0.0454           15.59s\n",
      "        88           0.0452           14.37s\n",
      "        89           0.0450           13.16s\n",
      "        90           0.0448           11.96s\n",
      "        91           0.0446           10.76s\n",
      "        92           0.0444            9.55s\n",
      "        93           0.0443            8.35s\n",
      "        94           0.0442            7.15s\n",
      "        95           0.0440            5.94s\n",
      "        96           0.0438            4.75s\n",
      "        97           0.0436            3.56s\n",
      "        98           0.0435            2.37s\n",
      "        99           0.0433            1.18s\n",
      "       100           0.0431            0.00s\n",
      "Count Vectors: 99.41781401382457\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0813            5.28m\n",
      "         2           0.0764            5.09m\n",
      "         3           0.0734            5.01m\n",
      "         4           0.0716            4.92m\n",
      "         5           0.0700            4.86m\n",
      "         6           0.0684            4.81m\n",
      "         7           0.0673            4.75m\n",
      "         8           0.0666            4.69m\n",
      "         9           0.0658            4.64m\n",
      "        10           0.0648            4.59m\n",
      "        11           0.0638            4.53m\n",
      "        12           0.0628            4.49m\n",
      "        13           0.0624            4.44m\n",
      "        14           0.0617            4.38m\n",
      "        15           0.0610            4.33m\n",
      "        16           0.0602            4.27m\n",
      "        17           0.0600            4.23m\n",
      "        18           0.0594            4.17m\n",
      "        19           0.0591            4.12m\n",
      "        20           0.0586            4.08m\n",
      "        21           0.0584            4.02m\n",
      "        22           0.0578            3.97m\n",
      "        23           0.0576            3.92m\n",
      "        24           0.0568            3.87m\n",
      "        25           0.0565            3.82m\n",
      "        26           0.0560            3.76m\n",
      "        27           0.0557            3.71m\n",
      "        28           0.0555            3.66m\n",
      "        29           0.0552            3.60m\n",
      "        30           0.0550            3.55m\n",
      "        31           0.0546            3.50m\n",
      "        32           0.0544            3.45m\n",
      "        33           0.0542            3.40m\n",
      "        34           0.0539            3.35m\n",
      "        35           0.0536            3.30m\n",
      "        36           0.0534            3.24m\n",
      "        37           0.0531            3.19m\n",
      "        38           0.0526            3.14m\n",
      "        39           0.0525            3.10m\n",
      "        40           0.0523            3.04m\n",
      "        41           0.0519            2.99m\n",
      "        42           0.0516            2.94m\n",
      "        43           0.0514            2.89m\n",
      "        44           0.0513            2.84m\n",
      "        45           0.0511            2.79m\n",
      "        46           0.0508            2.74m\n",
      "        47           0.0505            2.69m\n",
      "        48           0.0505            2.64m\n",
      "        49           0.0503            2.58m\n",
      "        50           0.0498            2.53m\n",
      "        51           0.0498            2.48m\n",
      "        52           0.0494            2.43m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        53           0.0492            2.38m\n",
      "        54           0.0491            2.33m\n",
      "        55           0.0490            2.28m\n",
      "        56           0.0486            2.23m\n",
      "        57           0.0484            2.18m\n",
      "        58           0.0481            2.13m\n",
      "        59           0.0479            2.08m\n",
      "        60           0.0474            2.03m\n",
      "        61           0.0473            1.98m\n",
      "        62           0.0473            1.92m\n",
      "        63           0.0470            1.87m\n",
      "        64           0.0465            1.82m\n",
      "        65           0.0462            1.77m\n",
      "        66           0.0460            1.72m\n",
      "        67           0.0458            1.67m\n",
      "        68           0.0456            1.62m\n",
      "        69           0.0454            1.57m\n",
      "        70           0.0452            1.51m\n",
      "        71           0.0449            1.46m\n",
      "        72           0.0447            1.41m\n",
      "        73           0.0445            1.36m\n",
      "        74           0.0444            1.31m\n",
      "        75           0.0442            1.26m\n",
      "        76           0.0439            1.21m\n",
      "        77           0.0437            1.16m\n",
      "        78           0.0435            1.11m\n",
      "        79           0.0433            1.06m\n",
      "        80           0.0430            1.01m\n",
      "        81           0.0430           57.35s\n",
      "        82           0.0429           54.34s\n",
      "        83           0.0426           51.29s\n",
      "        84           0.0424           48.26s\n",
      "        85           0.0422           45.22s\n",
      "        86           0.0420           42.19s\n",
      "        87           0.0417           39.16s\n",
      "        88           0.0415           36.13s\n",
      "        89           0.0413           33.11s\n",
      "        90           0.0411           30.08s\n",
      "        91           0.0410           27.08s\n",
      "        92           0.0409           24.08s\n",
      "        93           0.0406           21.06s\n",
      "        94           0.0404           18.04s\n",
      "        95           0.0402           15.03s\n",
      "        96           0.0400           12.02s\n",
      "        97           0.0397            9.01s\n",
      "        98           0.0395            6.01s\n",
      "        99           0.0394            3.00s\n",
      "       100           0.0393            0.00s\n",
      "TF-IDF Vectors: 99.5149494582349\n"
     ]
    }
   ],
   "source": [
    "predictions_gbc_count = np.zeros((len(test), len(classes)))\n",
    "predictions_gbc_tfidf = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(verbose=2)\n",
    "    \n",
    "    gbc.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(gbc.predict(count_train), y_train[classes[i]]))\n",
    "    predictions_gbc_count[:,i] = gbc.predict_proba(count_test)[:,1]\n",
    "    \n",
    "    gbc.fit(tfidf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(gbc.predict(tfidf_train), y_train[classes[i]]))\n",
    "    predictions_gbc_tfidf[:,i] = gbc.predict_proba(tfidf_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "729bf683",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1e584c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_gbc_count.csv</th>\n",
       "      <td>0.90663</td>\n",
       "      <td>0.92024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_gbc_tfidf.csv</th>\n",
       "      <td>0.92569</td>\n",
       "      <td>0.93239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          private   public\n",
       "submission_gbc_count.csv  0.90663  0.92024\n",
       "submission_gbc_tfidf.csv  0.92569  0.93239"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.90663, 0.92569], 'public': [0.92024, 0.93239]}, \n",
    "    index=['submission_gbc_count.csv', 'submission_gbc_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ffd6a",
   "metadata": {},
   "source": [
    "### Ensemble Models: AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9254e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 94.5434947452858\n",
      "TF-IDF Vectors: 94.8054471050504\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.9615907652393\n",
      "TF-IDF Vectors: 98.99981826271691\n",
      "Fitting obscene...\n",
      "Count Vectors: 97.11977740316223\n",
      "TF-IDF Vectors: 97.49139881306755\n",
      "Fitting threat...\n",
      "Count Vectors: 99.69480670046562\n",
      "TF-IDF Vectors: 99.69606006103866\n",
      "Fitting insult...\n",
      "Count Vectors: 96.59211260191388\n",
      "TF-IDF Vectors: 96.79327697388624\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 99.15084821176781\n",
      "TF-IDF Vectors: 99.17278202179594\n"
     ]
    }
   ],
   "source": [
    "predictions_adb_count = np.zeros((len(test), len(classes)))\n",
    "predictions_adb_tfidf = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    \n",
    "    adb = AdaBoostClassifier()\n",
    "    \n",
    "    adb.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(adb.predict(count_train), y_train[classes[i]]))\n",
    "    predictions_adb_count[:,i] = adb.predict_proba(count_test)[:,1]\n",
    "    \n",
    "    adb.fit(tfidf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(adb.predict(tfidf_train), y_train[classes[i]]))\n",
    "    predictions_adb_tfidf[:,i] = adb.predict_proba(tfidf_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77a9267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54ec5673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_adb_count.csv</th>\n",
       "      <td>0.93539</td>\n",
       "      <td>0.94218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_adb_tfidf.csv</th>\n",
       "      <td>0.93830</td>\n",
       "      <td>0.94145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          private   public\n",
       "submission_adb_count.csv  0.93539  0.94218\n",
       "submission_adb_tfidf.csv  0.93830  0.94145"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRestClassifier Classifier: Logistic Regression using Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "lr_oc = OneVsRestClassifier(LogisticRegression(max_iter = 3000))\n",
    "lr_oc.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83944f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oc.predict(count_train)\n",
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00520a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oc.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac23fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_oc_lr_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a9a1f",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160feff",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "41b713eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           0             0        0       0       0              0\n",
       "4           0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      0             0        0       0       0              0\n",
       "159567      0             0        0       0       0              0\n",
       "159568      0             0        0       0       0              0\n",
       "159569      0             0        0       0       0              0\n",
       "159570      0             0        0       0       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e768790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7564c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_tf = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_tf.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ededd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf.predict(tf_idf_train)\n",
    "print('TF-IDF Vectors: ' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = lr_mo_count.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d96e87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_mo_tf = lr_mo_tf.predict_proba(tf_idf_test)\n",
    "predictions_lr_mo_count = lr_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c7ff4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_lr_mo_tf, 'submission_mo_lr_tf')\n",
    "to_submission_csv_multiclass(predictions_lr_mo_count, 'submission_mo_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c4518fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_lr_count.csv  0.94036  0.94400\n",
       "submission_mo_lr_tf.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97063], 'public': [0.94400, 0.97183]}, \n",
    "    index=['submission_mo_lr_count.csv', 'submission_mo_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5096",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f7107bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [\n",
    "    {\n",
    "        'estimator__C': [1, 12, 15],\n",
    "        'estimator__max_iter': [600, 1800, 3000],\n",
    "        'estimator__class_weight' : ['balanced', None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7c83146",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8bafa6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(LogisticRegression ())\n",
    "lr_mo_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_tuned.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2d001476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tuned.predict(tf_idf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), lr_mo_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "31b6e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_mo_tuned.predict_proba(tf_idf_test)\n",
    "to_submission_csv_multiclass(predictions_lr_tfidf_tuned, 'submission_mo_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d297b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "10449db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            97.936342\n",
      "severe_toxic     98.640730\n",
      "obscene          98.735359\n",
      "threat           99.741808\n",
      "insult           97.858633\n",
      "identity_hate    98.945924\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), lr_mo_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "221b93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_mo_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_lr_count_tuned, 'submission_mo_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d17e95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count_tuned.csv</th>\n",
       "      <td>0.93996</td>\n",
       "      <td>0.94410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf_tuned.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_lr_count_tuned.csv  0.93996  0.94410\n",
       "submission_mo_lr_tf_tuned.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97063], 'public': [0.94410, 0.97183]}, \n",
    "    index=['submission_mo_lr_count_tuned.csv', 'submission_mo_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c8000",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes using Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559daa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_mo = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9795f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_mo.predict(count_train)\n",
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_mo.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99061ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_mo_mn_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 10000)\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc = ClassifierChain(\n",
    "    classifier = MultinomialNB(alpha = 1.0, fit_prior = True),\n",
    ")\n",
    "\n",
    "mn_cc.fit(count_train, y_train)\n",
    "\n",
    "predictions = mn_cc.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_count_mn_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tuned = RandomizedSearchCV(ClassifierChain(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_cc_tuned.fit(count_train, y_train)\n",
    "print (mn_cc_tuned.best_params_, mn_cc_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a93384",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ab6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_count_mn_cc_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46353cfd",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade5aa6",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbcabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7371a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mn_cc = ClassifierChain(\n",
    "    classifier = MultinomialNB(alpha = 1.0, fit_prior = True),\n",
    ")\n",
    "\n",
    "mn_cc.fit(tf_idf_train, y_train)\n",
    "\n",
    "predictions = mn_cc.predict(tf_idf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ee1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc.predict(tf_idf_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_tfidf_mn_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a8c8e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ef089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9e5b2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c1539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f016da",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acab8b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf417a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c918d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lr = BinaryRelevance(classifier = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lr.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_lr.predict(count_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = binary_lr.predict(count_test)\n",
    "predictions = predictions.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_lr_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921bad",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9214d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_lr, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66df22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lr_br_tuned.fit(count_train, y_train)\n",
    "print (lr_br_tuned.best_params_, lr_br_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8676eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_br_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb442d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_br_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_lr_count_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633710",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b35262",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46acf7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb884fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn = BinaryRelevance(classifier = MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd28cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_mn.predict(tf_idf_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b995c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = binary_mn.predict(tf_idf_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv('results/submission_binary_mn_tfidf.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e32a6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_br_tuned.fit(tf_idf_train, y_train)\n",
    "print (mn_br_tuned.best_params_, v.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247114a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tuned.predict(tf_idf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886182ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_br_tuned.predict(tf_idf_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_mn_tfidf_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c3b8",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0528ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167d94bf",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4cd9",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features = 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f05119",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn = BinaryRelevance(classifier = MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_mn.predict(count_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id']\n",
    "counter = 0\n",
    "\n",
    "predictions = binary_mn.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv('results/submission_binary_mn_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89804b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ff4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_br_tuned.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mn_br_tuned.best_params_, mn_br_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45700c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_br_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_mn_count_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe9a75",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf324509",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc574c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tfidf_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a8714",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cdd89",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d69379",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2508e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab42516",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24309156",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ea51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(count_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(count_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "sample_submission.to_csv(f'results/submission_count_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6d970",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70786f3",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269a8fd",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036227",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4d6e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  toxic\n",
      "96.23615819917153\n",
      "Class:  severe_toxic\n",
      "99.12578100030707\n",
      "Class:  obscene\n",
      "97.95514222509102\n",
      "Class:  threat\n",
      "99.73366087822976\n",
      "Class:  insult\n",
      "97.39551672923025\n",
      "Class:  identity_hate\n",
      "99.24109017302642\n"
     ]
    }
   ],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression (n_jobs=-1)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55109e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'results/submission_logreg_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d99897aee007>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msample_submission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'results/submission_logreg_1.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'results/submission_logreg_1.csv'"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict_proba(tf_idf_test)[:,1]\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_logreg_1.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba88dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'C' : [1, 12, 15],\n",
    "    'max_iter' :[600, 1800, 3000, 4200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d8f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ec8a5",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7246",
   "metadata": {},
   "source": [
    "### Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cba4",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408644e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c943f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'C' : [1, 12, 15],\n",
    "    'max_iter' :[600, 1800, 3000, 4200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05384cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87ee1a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f612c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg_tuned.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
