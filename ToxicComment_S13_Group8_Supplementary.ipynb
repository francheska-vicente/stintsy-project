{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "#### Basic Libraries \n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations\n",
    "- `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features \n",
    "- `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries\n",
    "The following code block can be used to install **scikit-multilearn** without restarting Jupyter Notebook. The `sys` module is used to access the *executable* function of the interpreter, which would run the installation of scikit-multilearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "850d2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a154c",
   "metadata": {},
   "source": [
    "The following libraries are multi-label classification modules that would allow the usage of one model that can classify one instance as more than one class.\n",
    "- `ClassifierChain` chains binary classifiers in a way that its predictions are dependent on the earlier classes\n",
    "- `BinaryRelevance` uses binary classifiers to classify the classes independently\n",
    "- `MultiOutputClassifier` fits one classifier per target class \n",
    "- `OneVsRestClassifier` fits one class against the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ea567ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7f3",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "- `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees\n",
    "- `GradientBoostingClassifier` is a class under the ensemble module that optimizes arbitrary differentiable loss functions\n",
    "- `AdaBoostClassifier` is a class under the ensemble module that implements AdaBoost-SAMME\n",
    "- `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "- `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "- `SGDClassifier` is a class under the linear models module that implements regularized linear models with stochastic gradient descent (SGD) learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "836013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e6642",
   "metadata": {},
   "source": [
    "Meanwhile, the following classes are used for hyperparameter tuning.\n",
    "- `ParameterGrid` is a class that allows the iteration over different combinations of parameter values \n",
    "- `GridSearchCV` is a cross-validation class that allows the exhaustive search over all possible combinations of hyperparameter values\n",
    "- `RandomizedSearchCV` is a cross-validation class that allows a random search over some possible combinations of hyperparameter values\n",
    "- `train_test_split` divides the dataset into two subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "54f9c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688e12a",
   "metadata": {},
   "source": [
    "And lastly, these classes computes different scores about how well a model works.\n",
    "- `log_loss` computes the Logistic loss given the true values and the predicted values\n",
    "- `f1_score` computes the balanced F-score by comparing the actual classes and the predicted classes\n",
    "- `accuracy_score` computes the accuracy by determining how many classes were correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2710dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878a641",
   "metadata": {},
   "source": [
    "The warnings module is used to ignore any ConvergenceWarnings that might appear when doing hyperparameter tuning. As these models will not be chosen due to low accuracy scores, the warnings would only clutter the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "23c3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Load Files\n",
    "The csv files to be loaded here contains the datasets that have already gone through the data cleaning and preprocessing techniques discussed in the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130512f",
   "metadata": {},
   "source": [
    "## Initialize Datasets\n",
    "Before using these datasets, we would need to convert the values in the `comment_text` column into either \"str, unicode or file objects\", according to the documentation of TF-IDF vectorizer and Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7c6cd",
   "metadata": {},
   "source": [
    "Then, we would be declaring our **X_train**, **y_train**, and **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed343812",
   "metadata": {},
   "source": [
    "Afterwards, we would be declaring the different classes that our model would need to predict. This can be found in the **train** data's column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "## Vectorizing Data\n",
    "As explained in the **Feature Engineering** part of the main notebook, two types of vectorizers would be used: (1) Count Vectorizer, and (2) TF-IDF Vectorizer.\n",
    "\n",
    "Two types of each vectorizer were made in consideration of the more complex estimators: one with no **max_features** parameter, and one with a **max_features** parameter that is equal to 5000. Limiting the number of max features would lessen the time and space complexity from training the estimators; this would lessen the burden on our machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae61874",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e44339",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()                     # creating the Vectorizer with no max features\n",
    "count_train = count_vectorizer.fit_transform(X_train)    # fitting the vectorizer according to the train data, and then\n",
    "                                                         # returning the transformed train data\n",
    "count_test = count_vectorizer.transform(X_test)          # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_5000 = CountVectorizer(max_features = 5000)     # creating the Vectorizer with max features = 5000\n",
    "count_train_5000 = count_vectorizer_5000.fit_transform(X_train)  # fitting the vectorizer according to the train data, and then\n",
    "                                                                 # returning the transformed train data\n",
    "count_test_5000 = count_vectorizer_5000.transform(X_test)        # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1bbb9f",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f758d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()                    # creating the Vectorizer with no max features\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)   # fitting the vectorizer according to the train data, and then\n",
    "                                                        # returning the transformed train data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)         # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_5000 = TfidfVectorizer(max_features = 5000)    # creating the Vectorizer with max features = 5000\n",
    "tfidf_train_5000 = tfidf_vectorizer_5000.fit_transform(X_train) # fitting the vectorizer according to the train data, and then\n",
    "                                                                # returning the transformed train data\n",
    "tfidf_test_5000 = tfidf_vectorizer_5000.transform(X_test)       # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679953d",
   "metadata": {},
   "source": [
    "#### Average Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6de054c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    t = TweetTokenizer()\n",
    "\n",
    "    tokens_list = []\n",
    "    for text in data:\n",
    "        tokens_list += [t.tokenize(text)]\n",
    "    return tokens_list\n",
    "\n",
    "def vectorize_word2vec(model, tokens_list):\n",
    "    vectors = []\n",
    "    for tokens in tokens_list:\n",
    "        feat = np.zeros(100)\n",
    "        count = 0 + 1e-5\n",
    "        for token in tokens:\n",
    "            if token in model.wv.index_to_key:\n",
    "                feat += model.wv[token]\n",
    "                count +=1\n",
    "        if(count!=0):\n",
    "            feat /= count\n",
    "        vectors.append(feat)\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d422bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(tokenize(X_train), epochs=30, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_train = vectorize_word2vec(word2vec_model, tokenize(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122630c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_test = vectorize_word2vec(word2vec_model, tokenize(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Declaring Functions\n",
    "Helper functions that would be repeatedly used throughout the notebook, will be declared and discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e723496",
   "metadata": {},
   "source": [
    "The following `to_submission_csv` functions are used to create CSV files with the correct submission template. The first function is used by almost all models, while a modified version is used for the MultiOutput Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id']\n",
    "\n",
    "def to_submission_csv(predictions, filename):\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) \n",
    "    \n",
    "def to_submission_csv_multiclass(predictions, filename):\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d3af4",
   "metadata": {},
   "source": [
    "As the task requires us to give predictions for six classes, the `train_models` function would train multiple classifiers that will give predictions for a given class. The function would fit each classifier using data vectorized using both the Count Vectorizer and the TF-IDF Vectorizer as discussed below, and would then display their respective training accuracies. \n",
    "\n",
    "The function will return the trained models and their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7784784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model):\n",
    "    \"\"\"Trains six models using both count vectorized data and TF-IDF vectorized data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models_count\n",
    "        a list of estimator objects fitted with count vectorized data\n",
    "    models_tfidf\n",
    "        a list of estimator objects fitted with TF-IDF vectorized data\n",
    "    predictions_count\n",
    "        a list of prediction probabilities made for the count vectorized test data\n",
    "    predictions_tfidf\n",
    "        a list of prediction probabilities made for the TF-IDF vectorized test data\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions_count = np.zeros((len(test), len(classes)))       # initialize empty list for count predictions\n",
    "    predictions_tfidf = np.zeros((len(test), len(classes)))       # initialize empty list for tf-idf predictions\n",
    "    predictions_wrd2v = np.zeros((len(test), len(classes)))       # initialize empty list for tf-idf predictions    \n",
    "    models_count = []                                             # initialize empty list for count models\n",
    "    models_tfidf = []                                             # initialize empty list for tf-idf models\n",
    "    models_wrd2v = []                                             # initialize empty list for tf-idf models\n",
    "\n",
    "    for i in range(6):                                            # loop for each of six classes\n",
    "        print('Fitting', classes[i] + '...')\n",
    "\n",
    "        mdl = model                                                     # initialize the model\n",
    "        mdl.fit(count_train, y_train[classes[i]])                       # fit the model\n",
    "        predictions = mdl.predict(count_train)                          # predict using train data\n",
    "        accuracy = accuracy_score(predictions, y_train[classes[i]])     # get training accuracy \n",
    "        print('Count Vectors:', accuracy)\n",
    "        predictions_count[:,i] = mdl.predict_proba(count_test)[:,1]     # predict using test data\n",
    "        models_count += [mdl]\n",
    "        \n",
    "        mdl = model                                                     # initialize the model\n",
    "        mdl.fit(tfidf_train, y_train[classes[i]])                       # fit the model\n",
    "        predictions = mdl.predict(tfidf_train)                          # predict using train data\n",
    "        accuracy = accuracy_score(predictions, y_train[classes[i]])     # get training accuracy \n",
    "        print('TF-IDF Vectors:', accuracy)\n",
    "        predictions_tfidf[:,i] = mdl.predict_proba(tfidf_test)[:,1]     # predict using test data\n",
    "        models_tfidf += [mdl]\n",
    "        \n",
    "        mdl = model                                                     # initialize the model\n",
    "        mdl.fit(word2vec_train, y_train[classes[i]])                       # fit the model\n",
    "        predictions = mdl.predict(word2vec_train)                          # predict using train data\n",
    "        accuracy = accuracy_score(predictions, y_train[classes[i]])     # get training accuracy \n",
    "        print('Word2Vec Vectors:', accuracy)\n",
    "        predictions_wrd2v[:,i] = mdl.predict_proba(word2vec_test)[:,1]     # predict using test data\n",
    "        models_wrd2v += [mdl]\n",
    "    \n",
    "    return models_count, models_tfidf, models_wrd2v, predictions_count, predictions_tfidf, predictions_wrd2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034bab2",
   "metadata": {},
   "source": [
    "Similarly, the `tune_and_train_models` will train multiple classifiers, however, this function will include hyperparameter tuning to achieve a better training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1ec21a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "def tune_and_train_models(model_cv):\n",
    "    \"\"\"Tunes six models using both count vectorized data and TF-IDF vectorized data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_cv : GridSearchCV or RandomizedSearchCV object\n",
    "        a cross validation object with the estimator and hyperparameters to be fitted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models_count_tuned\n",
    "        a list of tuned estimator objects fitted with count vectorized data\n",
    "    models_tfidf_tuned\n",
    "        a list of tuned estimator objects fitted with TF-IDF vectorized data\n",
    "    predictions_count_tuned\n",
    "        a list of prediction probabilities made for the count vectorized test data\n",
    "    predictions_tfidf_tuned\n",
    "        a list of prediction probabilities made for the TF-IDF vectorized test data\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions_count_tuned = np.zeros((len(test), len(classes)))       # initialize empty list for count predictions\n",
    "    predictions_tfidf_tuned = np.zeros((len(test), len(classes)))       # initialize empty list for tf-idf predictions\n",
    "    models_count_tuned = []                                             # initialize empty list for count models\n",
    "    models_tfidf_tuned = []                                             # initialize empty list for tf-idf models\n",
    "\n",
    "    for i in range(6):                                                  # loop for each of six classes\n",
    "        print('Fitting', classes[i] + '...')\n",
    "\n",
    "        mdl_tuned = model_cv                                                     # initialize the cross validation model\n",
    "        mdl_tuned.fit(count_train, y_train[classes[i]])                          # fit the model\n",
    "        print('Best parameters:', mdl_tuned.best_params_)                        # print best parameters found \n",
    "        predictions = mdl_tuned.predict(count_train)                             # predict using train data\n",
    "        accuracy = accuracy_score(predictions, y_train[classes[i]])              # get training accuracy \n",
    "        print('Count Vectors:', accuracy)                                        # print training accuracy\n",
    "        predictions_count_tuned[:,i] = mdl_tuned.predict_proba(count_test)[:,1]  # predict using test data\n",
    "        models_count_tuned += [mdl_tuned]                                        # add model to list\n",
    "\n",
    "        mdl_tuned = model_cv                                                     # initialize the cross validation model\n",
    "        mdl_tuned.fit(tfidf_train, y_train[classes[i]])                          # fit the model\n",
    "        print('Best parameters:', mdl_tuned.best_params_)                        # print best parameters found \n",
    "        predictions = mdl_tuned.predict(tfidf_train)                             # predict using train data\n",
    "        accuracy = accuracy_score(predictions, y_train[classes[i]])              # get training accuracy \n",
    "        print('TF-IDF Vectors:', accuracy)                                       # print training accuracy\n",
    "        predictions_tfidf_tuned[:,i] = mdl_tuned.predict_proba(tfidf_test)[:,1]  # predict using test data\n",
    "        models_tfidf_tuned += [mdl_tuned]\n",
    "    \n",
    "    return models_count_tuned, models_tfidf_tuned, predictions_count_tuned, predictions_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b337ec4",
   "metadata": {},
   "source": [
    "To exhaust all options, we have opted to train different types of multi-label classifiers that are available from sckit-learn.\n",
    "As such, the `train_model` and `tune_and_train_model` functions will forgo the loop and proceed to train and/or tune the model using the whole **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "962c73b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "def train_model(model):\n",
    "    \"\"\"Trains a model using both count vectorized data and TF-IDF vectorized data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of multi-label estimator to be trained \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_count\n",
    "        a multi-label estimator object fitted with count vectorized data\n",
    "    model_tfidf\n",
    "        a multi-label estimator object fitted with TF-IDF vectorized data\n",
    "    predictions_count\n",
    "        a list of prediction probabilities made for the count vectorized test data\n",
    "    predictions_tfidf\n",
    "        a list of prediction probabilities made for the TF-IDF vectorized test data\n",
    "    \"\"\"\n",
    "\n",
    "    model_count = model                                           # initialize the model\n",
    "    model_count.fit(count_train, y_train)                                 # fit the model\n",
    "    predictions = model_count.predict(count_train)                        # predict using train data\n",
    "    accuracy = accuracy_score(predictions, y_train)               # get training accuracy \n",
    "    print('Count Vectors:', accuracy)                             # print training accuracy\n",
    "    predictions_count = model_count.predict_proba(count_test)             # predict using test data\n",
    "        \n",
    "    model_tfidf = model                                           # initialize the model\n",
    "    model_tfidf.fit(tfidf_train, y_train[classes[i]])                     # fit the model\n",
    "    predictions = model_tfidf.predict(tfidf_train)                        # predict using train data\n",
    "    accuracy = accuracy_score(predictions, y_train)               # get training accuracy \n",
    "    print('TF-IDF Vectors:', accuracy)                            # print training accuracy\n",
    "    predictions_tfidf = model_tfidf.predict_proba(tfidf_test)             # predict using test data\n",
    "    \n",
    "    return model_count, model_tfidf, predictions_count, predictions_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1c33d",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "49db740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "def tune_and_train_model(model_cv):\n",
    "    \"\"\"Tunes a model using both count vectorized data and TF-IDF vectorized data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_cv : GridSearchCV or RandomizedSearchCV object\n",
    "        a cross validation object with the estimator and hyperparameters to be fitted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_count\n",
    "        a multi-label estimator object fitted with count vectorized data\n",
    "    model_tfidf\n",
    "        a multi-label estimator object fitted with TF-IDF vectorized data\n",
    "    predictions_count\n",
    "        a list of prediction probabilities made for the count vectorized test data\n",
    "    predictions_tfidf\n",
    "        a list of prediction probabilities made for the TF-IDF vectorized test data\n",
    "    \"\"\"\n",
    "\n",
    "    model_count_tuned = model_cv                                             # initialize the cross validation model\n",
    "    model_count_tuned.fit(count_train, y_train)                              # fit the model\n",
    "    print('Best parameters:', model_count_tuned.best_params_)                # print best parameters found \n",
    "    predictions = model_count_tuned.predict(count_train)                     # predict using train data\n",
    "    accuracy = accuracy_score(predictions, y_train)                          # get training accuracy \n",
    "    print('Count Vectors:', accuracy)                                        # print training accuracy\n",
    "    predictions_count_tuned = model_count_tuned.predict_proba(count_test)    # predict using test data\n",
    "\n",
    "    model_tfidf_tuned = model_cv                                             # initialize the cross validation model\n",
    "    model_tfidf_tuned.fit(tfidf_train, y_train)                              # fit the model\n",
    "    print('Best parameters:', model_tfidf_tuned.best_params_)                # print best parameters found \n",
    "    predictions = model_tfidf_tuned.predict(tfidf_train)                     # predict using train data\n",
    "    accuracy = accuracy_score(predictions, y_train)                          # get training accuracy \n",
    "    print('TF-IDF Vectors:', accuracy)                                       # print training accuracy  \n",
    "    predictions_tfidf_tuned = model_tfidf_tuned.predict_proba(tfidf_test)    # predict using test data\n",
    "    \n",
    "    return model_count_tuned, model_tfidf_tuned, predictions_count_tuned, predictions_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": [
    "## Declaring Hyperparameter Values\n",
    "As hyperparameters for each base estimator will remain constant, these will be declared here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17596dc2",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"param_lr\"></a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c75638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "parameters_lr = [{\n",
    "    'C' : [0.01, 0.1, 1, 10],\n",
    "    'max_iter' : [300, 600, 900, 1200], \n",
    "    'class_weight' : ['balanced', None]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ef0af",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"param_mn\"></a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee4b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "parameters_mnb = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298152f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"param_rf\"></a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "865abbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "parameters_rf = [{\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 20, 30],\n",
    "    'min_samples_split' : [2, 4, 6, 10, 15, 20],\n",
    "    'max_leaf_nodes' : [3, 5, 10, 20, 50, 100],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b154c6f",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fd5bd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "parameters_gbc = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7e04e",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1eb7ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "parameters_xgb = [{\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37176e56",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "11f2fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost Classifier\n",
    "parameters_adb = {\n",
    "    'n_estimators' : [10, 25, 50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0035ae",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "663ee2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDClassifier\n",
    "parameters_sgd = [{\n",
    "    'loss' : ['log', 'modified_huber'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc2603",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "153902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneVsRest Classifier and MultiOutput Classifier: Logistic Regression\n",
    "parameters_lr_mo = [{\n",
    "    'estimator__C': [0.01, 0.1, 1, 10],            # [1, 12, 15]\n",
    "    'estimator__max_iter': [300, 600, 900, 1200],  # [600, 1800, 3000],\n",
    "    'estimator__class_weight' : ['balanced', None]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d2cfb",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneVsRest Classifier and MultiOutput Classifier: Multinomial Naive Bayes\n",
    "parameters_mn_mo = [{\n",
    "    'estimator__alpha': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],   # [0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "    'estimator__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f84ec4",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Relevance: Logistic Regression\n",
    "parameters_lr_multi = [{\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],            # [1, 12, 15]\n",
    "    'classifier__max_iter': [300, 600, 900, 1200]   # [600, 1800, 3000],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9041c",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Chain and Binary Relevance: Multinomial Naive Bayes\n",
    "parameters_mn_multi = [{\n",
    "    'classifier': [MultinomialNB()],\n",
    "    'classifier__alpha': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],   # [0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "    'classifier__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc9dd9",
   "metadata": {},
   "source": [
    "## Training and Tuning Different Models <a class=\"anchor\" id=\"toc\"></a>\n",
    "TODO: i ken fly\n",
    "\n",
    "\n",
    "### Six Single-Label Classifiers\n",
    "* [**Logistic Regression**](#lr)\n",
    "* [**Multinomial Naive Bayes**](#mn)\n",
    "* [**Random Forest Classifier**](#rf)\n",
    "* [**Gradient Boosting Classifier**](#gbc)\n",
    "* [**eXtreme Gradient Boosting Classifier**](#xgb)\n",
    "* [**AdaBoostClassifier Boosting Classifier**](#adb)\n",
    "* [**Stochastic Gradient Descent Classifier**](#sgd)\n",
    "\n",
    "### Multi-Label Classifiers\n",
    "* [**OneVsRest Classifier: Logistic Regression**](#oc_lr)\n",
    "* [**OneVsRest Classifier: Multinomial Naive Bayes**](#oc_mn)\n",
    "* [**MultiOutput Classifier: Logistic Regression**](#mo_lr)\n",
    "* [**MultiOutput Classifier: Multinomial Naive Bayes**](#mo_mn)\n",
    "* [**Binary Relevance: Logistic Regression**](#br_lr)\n",
    "* [**Binary Relevance: Multinomial Naive Bayes**](#br_mn)\n",
    "* [**Classifier Chain: Multinomial Naive Bayes**](#cc_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d6f2",
   "metadata": {},
   "source": [
    "### Logistic Regression <a class=\"anchor\" id=\"lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "# TODO: i ken fly, tell me why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e8718",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `LogisticRegression()` object is initialized with default estimator parameters before it is passed to the `train_models()` function. This model will be used as a base to train one classifier for each of the six classes for each vectorizer for a total of 12 models.\n",
    "\n",
    "Additionally, the `n_jobs` parameter is used for parallel processing which would help lessen the training time of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_count, lr_models_tfidf, lr_models_wrd2v, \\\n",
    "    predictions_lr_count, predictions_lr_tfidf, predictions_lr_wrd2v = train_models(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f778b",
   "metadata": {},
   "source": [
    "# TODO: nagbago results\n",
    "From the output shown above, it should be noted that the Logistic Regression models fitted with count vectorized data produced higher training accuracy scores for all six classes.\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ca9c3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count, 'submission_lr_count')\n",
    "to_submission_csv(predictions_lr_tfidf, 'submission_lr_tfidf')\n",
    "to_submission_csv(predictions_lr_wrd2v, 'submission_lr_wrd2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a78059d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr_wrd2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad01fcc",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TF-IDF vectors yielded a higher test accuracy rate than count vectors, which is contrary to the results shown earlier.\n",
    "\n",
    "# TODO: mataas naman ish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c974dc",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count</td>\n",
    "    <td class=\"tg-baqh\">0.93926</td>\n",
    "    <td class=\"tg-baqh\">0.94248</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97391</td>\n",
    "    <td class=\"tg-baqh\">0.97376</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebed0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "In tuning the Logistic Regression models, a `GridSearchCV()` was used for a more comprehensive search that would result in a higher accuracy score. A `LogisticRegression()` object with default parameters will serve as the base estimator, while the [`parameters_lr`](#param_lr) hyperparameters will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "40056ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Best parameters: {'C': 1, 'max_iter': 300}\n",
      "Count Vectors: 0.9770572347105677\n",
      "Best parameters: {'C': 10, 'max_iter': 600}\n",
      "TF-IDF Vectors: 0.9798710291970345\n",
      "Fitting severe_toxic...\n",
      "Best parameters: {'C': 1, 'max_iter': 900}\n",
      "Count Vectors: 0.9865953086713751\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "TF-IDF Vectors: 0.989340168326325\n",
      "Fitting obscene...\n",
      "Best parameters: {'C': 1, 'max_iter': 600}\n",
      "Count Vectors: 0.9879802721045804\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "TF-IDF Vectors: 0.9901423190930683\n",
      "Fitting threat...\n",
      "Best parameters: {'C': 1, 'max_iter': 300}\n",
      "Count Vectors: 0.9973930100080842\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "TF-IDF Vectors: 0.998145026351906\n",
      "Fitting insult...\n",
      "Best parameters: {'C': 1, 'max_iter': 1200}\n",
      "Count Vectors: 0.9787743386956277\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "TF-IDF Vectors: 0.9829981638267605\n",
      "Fitting identity_hate...\n",
      "Best parameters: {'C': 1, 'max_iter': 900}\n",
      "Count Vectors: 0.9894717711864938\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "TF-IDF Vectors: 0.9930062480024566\n"
     ]
    }
   ],
   "source": [
    "lr_tuned = GridSearchCV(LogisticRegression(n_jobs=-1, class_weight='balanced'), parameters_lr, scoring='f1', cv=2)\n",
    "lr_models_count_tuned, lr_models_tfidf_tuned, \\\n",
    "    predictions_lr_count_tuned, predictions_lr_tfidf_tuned = tune_and_train_models(lr_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7e87e",
   "metadata": {},
   "source": [
    "It can be seen above that count vectors had higher training accuracy scores for **toxic**, **severe_toxic**, **obscene**, **threat**, and **identity_hate**, while \n",
    "# TODO: kasi irurun ulet to\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18e86238",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count_tuned, 'submission_lr_count_tuned')\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27931ea2",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "\n",
    "# TODO: bumaba bakit ganun hala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448f00b",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94016</td>\n",
    "    <td class=\"tg-baqh\">0.94392</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.97135</td>\n",
    "    <td class=\"tg-baqh\">0.97227</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5546",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes <a class=\"anchor\" id=\"mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ea456",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `MultinomialNB()` object with default parameters is initialized before it is passed to the `train_models()` function. A classifier for each of the six classes for each vectorizer will be trained using this object as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c93a26cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 0.9513696097661856\n",
      "TF-IDF Vectors: 0.9236828747078103\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 0.98641983819115\n",
      "TF-IDF Vectors: 0.9899104473870566\n",
      "Fitting obscene...\n",
      "Count Vectors: 0.9670867513520627\n",
      "TF-IDF Vectors: 0.9538449968979326\n",
      "Fitting threat...\n",
      "Count Vectors: 0.9955505699657206\n",
      "TF-IDF Vectors: 0.996973134216117\n",
      "Fitting insult...\n",
      "Count Vectors: 0.9646301646289113\n",
      "TF-IDF Vectors: 0.9535629907689994\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 0.9877233331871079\n",
      "TF-IDF Vectors: 0.9911074067343063\n"
     ]
    }
   ],
   "source": [
    "mn = MultinomialNB()\n",
    "mn_models_count, mn_models_tfidf, predictions_mn_count, predictions_mn_tfidf = train_models(mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429d5ed",
   "metadata": {},
   "source": [
    "As seen from the output above, the models trained with count vectorized data performed better when predicting **toxic**, **obscene**, and **insult** classes, while TF-IDF vectorized data performed better for **severe_toxic**, **threat**, and **identity_hate** classes.\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8eee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_count, 'submission_mn_count')\n",
    "to_submission_csv(predictions_mn_tfidf, 'submission_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d273fe",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, \n",
    "\n",
    "# TODO: yuck ang baba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaedef",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count</td>\n",
    "    <td class=\"tg-baqh\">0.84551</td>\n",
    "    <td class=\"tg-baqh\">0.85581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.82510</td>\n",
    "    <td class=\"tg-baqh\">0.83586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad09288",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "In tuning the Multinomial Naive Bayes models, a `GridSearchCV()` was used for a more comprehensive search as tuning this model is relatively inexpensive timewise. A `MultinomialNB()` object with default parameters will serve as the base estimator, while the [`parameters_mnb`](#param_mn) hyperparameters will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ecf109d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Best parameters: {'alpha': 0.1, 'fit_prior': True}\n",
      "Count Vectors: 0.95461581365035\n",
      "Best parameters: {'alpha': 0.001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 0.9748262528905628\n",
      "Fitting severe_toxic...\n",
      "Best parameters: {'alpha': 0.001, 'fit_prior': True}\n",
      "Count Vectors: 0.9872031885492978\n",
      "Best parameters: {'alpha': 0.0001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 0.9945980159302129\n",
      "Fitting obscene...\n",
      "Best parameters: {'alpha': 0.1, 'fit_prior': True}\n",
      "Count Vectors: 0.966065262485038\n",
      "Best parameters: {'alpha': 0.001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 0.9862067668937339\n",
      "Fitting threat...\n",
      "Best parameters: {'alpha': 0.001, 'fit_prior': True}\n",
      "Count Vectors: 0.9916275513721164\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "TF-IDF Vectors: 0.9987403726240983\n",
      "Fitting insult...\n",
      "Best parameters: {'alpha': 0.1, 'fit_prior': True}\n",
      "Count Vectors: 0.9630258630954246\n",
      "Best parameters: {'alpha': 0.001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 0.9840384531023808\n",
      "Fitting identity_hate...\n",
      "Best parameters: {'alpha': 0.001, 'fit_prior': True}\n",
      "Count Vectors: 0.9851038095894618\n",
      "Best parameters: {'alpha': 0.0001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 0.9957949752774627\n"
     ]
    }
   ],
   "source": [
    "mn_tuned = GridSearchCV(MultinomialNB(), parameters_mnb, scoring='f1', cv=2)\n",
    "mn_models_count_tuned, mn_models_tfidf_tuned, \\\n",
    "    predictions_mn_count_tuned, predictions_mn_tfidf_tuned = tune_and_train_models(mn_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e9017ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_count_tuned, 'submission_mn_count_tuned')\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3ce89",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90205</td>\n",
    "    <td class=\"tg-baqh\">0.90411</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90610</td>\n",
    "    <td class=\"tg-baqh\">0.90995</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b957",
   "metadata": {},
   "source": [
    "### RandomForestClassifier <a class=\"anchor\" id=\"rf\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31757d9e",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `RandomForestClassifier()` object with default parameters is initialized before it is passed to the `train_models()` function. A classifier for each of the six classes for each vectorizer will be trained using this object as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25c706c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 0.9997869287025838\n",
      "TF-IDF Vectors: 0.9997493278853927\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 0.9998245295197749\n",
      "TF-IDF Vectors: 0.9997054602653365\n",
      "Fitting obscene...\n",
      "Count Vectors: 0.9998245295197749\n",
      "TF-IDF Vectors: 0.9997681282939882\n",
      "Fitting threat...\n",
      "Count Vectors: 0.9999435987742133\n",
      "TF-IDF Vectors: 0.9999373319713482\n",
      "Fitting insult...\n",
      "Count Vectors: 0.9996866598567409\n",
      "TF-IDF Vectors: 0.9995989246166284\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 0.9998997311541571\n",
      "TF-IDF Vectors: 0.9998809307455615\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced')\n",
    "rf_models_count, rf_models_tfidf, predictions_rf_count, predictions_rf_tfidf = train_models(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0aa6ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4391b",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count</td>\n",
    "    <td class=\"tg-baqh\">0.94071</td>\n",
    "    <td class=\"tg-baqh\">0.94602</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.93731</td>\n",
    "    <td class=\"tg-baqh\">0.93999</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd252b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d81585ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Count Vectors: 0.7163018342931986\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "TF-IDF Vectors: 0.721058337667872\n",
      "Fitting severe_toxic...\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Count Vectors: 0.7858633460967218\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "TF-IDF Vectors: 0.7954578212833159\n",
      "Fitting obscene...\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Count Vectors: 0.7358041248096459\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "TF-IDF Vectors: 0.7487764067405731\n",
      "Fitting threat...\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Count Vectors: 0.8735985862092737\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "TF-IDF Vectors: 0.9027705535466971\n",
      "Fitting insult...\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Count Vectors: 0.7397710110233062\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "TF-IDF Vectors: 0.7466080929492201\n",
      "Fitting identity_hate...\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Count Vectors: 0.7627325767213341\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "TF-IDF Vectors: 0.8048266915667633\n"
     ]
    }
   ],
   "source": [
    "rf_tuned = RandomizedSearchCV(RandomForestClassifier(n_jobs=-1, class_weight='balanced'), parameters_rf, scoring='f1', random_state=8, cv=2)\n",
    "rf_models_count_tuned, rf_models_tfidf_tuned, \\\n",
    "    predictions_rf_count_tuned, predictions_rf_tfidf_tuned = tune_and_train_models(rf_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dabb22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6a8aa",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.96232</td>\n",
    "    <td class=\"tg-baqh\">0.96285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.95937</td>\n",
    "    <td class=\"tg-baqh\">0.95826</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6d61c",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier <a class=\"anchor\" id=\"gbc\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761be0e",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "36ca0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 0.943373169310213\n",
      "TF-IDF Vectors: 0.9443382569514511\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 0.9916902194007683\n",
      "TF-IDF Vectors: 0.9923106328844213\n",
      "Fitting obscene...\n",
      "Count Vectors: 0.9760106786320822\n",
      "TF-IDF Vectors: 0.9768378966102863\n",
      "Fitting threat...\n",
      "Count Vectors: 0.9974118104166797\n",
      "TF-IDF Vectors: 0.9978191526029165\n",
      "Fitting insult...\n",
      "Count Vectors: 0.968609584448302\n",
      "TF-IDF Vectors: 0.9696498737239223\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 0.9942094741525715\n",
      "TF-IDF Vectors: 0.9950366921307756\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_count, gbc_models_tfidf, predictions_gbc_count, predictions_gbc_tfidf = train_models(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83bea7",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ba158bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-a0d8fd842cd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgbc_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_gbc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgbc_models_count_tuned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbc_models_tfidf_tuned\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredictions_gbc_count_tuned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_gbc_tfidf_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtune_and_train_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbc_tuned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-79446f7a7da3>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model_cv)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mmdl_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cv\u001b[0m                                                     \u001b[1;31m# initialize the cross validation model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m                        \u001b[1;31m# print best parameters found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1619\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1621\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbc_tuned = RandomizedSearchCV(GradientBoostingClassifier(), parameters_gbc, scoring='accuracy', random_state=8, cv=2)\n",
    "gbc_models_count_tuned, gbc_models_tfidf_tuned, \\\n",
    "    predictions_gbc_count_tuned, predictions_gbc_tfidf_tuned = tune_and_train_models(gbc_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count_tuned, 'submission_gbc_count_tuned')\n",
    "to_submission_csv(predictions_gbc_tfidf_tuned, 'submission_gbc_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f4fd",
   "metadata": {},
   "source": [
    "### XGBClassifier <a class=\"anchor\" id=\"xgb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433ad06",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1ba086e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 0.9643732257114388\n",
      "TF-IDF Vectors: 0.9667358103916125\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 0.9943536106184708\n",
      "TF-IDF Vectors: 0.9954127003026866\n",
      "Fitting obscene...\n",
      "Count Vectors: 0.9863947709796893\n",
      "TF-IDF Vectors: 0.9876167975383998\n",
      "Fitting threat...\n",
      "Count Vectors: 0.9989910447387057\n",
      "TF-IDF Vectors: 0.9993482525020211\n",
      "Fitting insult...\n",
      "Count Vectors: 0.9798772959998997\n",
      "TF-IDF Vectors: 0.9813186606588916\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 0.9955568367685858\n",
      "TF-IDF Vectors: 0.9959391117433619\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_count, xgb_models_tfidf, predictions_xgb_count, predictions_xgb_tfidf = train_models(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count, 'submission_xgb_count')\n",
    "to_submission_csv(predictions_xgb_tfidf, 'submission_xgb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d70014",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>private</th>\n",
    "    <th>public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>submission_xgb_count</td>\n",
    "    <td>0.96468</td>\n",
    "    <td>0.96783</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>submission_xgb_tfidf</td>\n",
    "    <td>0.96502</td>\n",
    "    <td>0.96803</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879062a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7020eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_tuned = GridSearchCV(estimator, parameters_xgb, scoring='f1', cv=2)\n",
    "xgb_models_count_tuned, xgb_models_tfidf_tuned, \\\n",
    "    predictions_xgb_count_tuned, predictions_xgb_tfidf_tuned = tune_and_train_models(xgb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d462d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea054",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier <a class=\"anchor\" id=\"adb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ca85f",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb786de",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_count, adb_models_tfidf, predictions_adb_count, predictions_adb_tfidf = train_models(adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a51c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b4c5c",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_tuned = GridSearchCV(AdaBoostClassifier(random_state=8), parameters_adb, scoring='accuracy', cv=2)\n",
    "adb_models_count_tuned, adb_models_tfidf_tuned, \\\n",
    "    predictions_adb_count_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8040d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803b2a5",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier <a class=\"anchor\" id=\"sgd\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1d781",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30717932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 0.9740930369553364\n",
      "TF-IDF Vectors: 0.9546032800446196\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 0.9773141736280402\n",
      "TF-IDF Vectors: 0.9773705748538268\n",
      "Fitting obscene...\n",
      "Count Vectors: 0.9366551566387377\n",
      "TF-IDF Vectors: 0.9798020943655176\n",
      "Fitting threat...\n",
      "Count Vectors: 0.9831673675041204\n",
      "TF-IDF Vectors: 0.9951808285966748\n",
      "Fitting insult...\n",
      "Count Vectors: 0.8818895663999098\n",
      "TF-IDF Vectors: 0.9667295435887473\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 0.961321292716095\n",
      "TF-IDF Vectors: 0.9792819497277074\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count, sgd_models_tfidf, predictions_sgd_count, predictions_sgd_tfidf = train_models(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7309b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count, 'submission_sgd_count')\n",
    "to_submission_csv(predictions_sgd_tfidf, 'submission_sgd_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfacf6",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count</td>\n",
    "    <td class=\"tg-baqh\">0.68992</td>\n",
    "    <td class=\"tg-baqh\">0.70589</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97214</td>\n",
    "    <td class=\"tg-baqh\">0.97625</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd2aa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tuned = GridSearchCV(SGDClassifier(n_jobs=-1, class_weight='balanced', random_state=8), parameters_sgd, scoring='f1', cv=2)\n",
    "sgd_models_count_tuned, sgd_models_tfidf_tuned, \\\n",
    "    predictions_sgd_count_tuned, predictions_sgd_tfidf_tuned = tune_and_train_models(sgd_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a60caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count_tuned, 'submission_sgd_count_tuned')\n",
    "to_submission_csv(predictions_sgd_tfidf_tuned, 'submission_sgd_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da19a36",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.81387</td>\n",
    "    <td class=\"tg-baqh\">0.81848</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94660</td>\n",
    "    <td class=\"tg-baqh\">0.95230</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Logistic Regression <a class=\"anchor\" id=\"oc_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571180e0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a000217",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_lr = OneVsRestClassifier(LogisticRegression(max_iter=3000))\n",
    "oc_lr_model_count, oc_lr_model_tfidf, predictions_oc_lr_count, predictions_oc_lr_tfidf = train_model(oc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d074db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_lr_count, 'submission_oc_lr_count')\n",
    "to_submission_csv_multiclass(predictions_oc_lr_tfidf, 'submission_oc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b45081",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(LogisticRegression())\n",
    "oc_lr_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs=-1, scoring='f1', cv=1)\n",
    "oc_lr_model_count_tuned, oc_lr_model_tfidf_tuned, \\\n",
    "    predictions_oc_lr_count_tuned, predictions_oc_lr_tfidf_tuned = tune_and_train_model(oc_lr_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_lr_count_tuned, 'submission_oc_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_oc_lr_tfidf_tuned, 'submission_oc_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5d60c",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"oc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad359a7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_mn = OneVsRestClassifier(MultinomialNB())\n",
    "oc_mn_model_count, oc_mn_model_tfidf, predictions_oc_mn_count, predictions_oc_mn_tfidf = train_model(oc_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_mn_count, 'submission_oc_mn_count')\n",
    "to_submission_csv_multiclass(predictions_oc_mn_tfidf, 'submission_oc_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14695b5e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3566eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(MultinomialNB())\n",
    "oc_mn_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs=-1, scoring='f1', cv=1)\n",
    "oc_mn_model_count_tuned, oc_lr_model_tfidf_tuned, \\\n",
    "    predictions_oc_mn_count_tuned, predictions_oc_mn_tfidf_tuned = tune_and_train_model(oc_mn_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45685f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_mn_count_tuned, 'submission_oc_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_oc_mn_tfidf_tuned, 'submission_oc_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87b1da",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression <a class=\"anchor\" id=\"mo_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00c7f5",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lr = MultiOutputClassifier(LogisticRegression(max_iter=3000))\n",
    "mo_lr_model_count, mo_lr_model_tfidf, predictions_mo_lr_count, predictions_mo_lr_tfidf = train_model(mo_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c99e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2839b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MultiOutputClassifier(LogisticRegression())\n",
    "mo_lr_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs=-1, scoring='f1', cv=1)\n",
    "mo_lr_model_count_tuned, mo_lr_model_tfidf_tuned, \\\n",
    "    predictions_mo_lr_count_tuned, predictions_mo_lr_tfidf_tuned = tune_and_train_model(mo_lr_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72172ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count_tuned, 'submission_mo_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf_tuned, 'submission_mo_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8307385",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"mo_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5f984",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a90a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_mn = MultiOutputClassifier(MultinomialNB())\n",
    "mo_mn_model_count, mo_mn_model_tfidf, predictions_mo_mn_count, predictions_mo_mn_tfidf = train_model(mo_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff636c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e02268",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc146ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MultiOutputClassifier(MultinomialNB())\n",
    "mo_mn_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs=-1, scoring='f1', cv=1)\n",
    "mo_mn_model_count_tuned, mo_mn_model_tfidf_tuned, \\\n",
    "    predictions_mo_mn_count_tuned, predictions_mo_mn_tfidf_tuned = tune_and_train_model(mo_mn_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90825b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_mn_count_tuned, 'submission_mo_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_mo_mn_tfidf_tuned, 'submission_mo_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4341f5e",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression <a class=\"anchor\" id=\"br_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362818be",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d76a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr = BinaryRelevance(LogisticRegression())\n",
    "br_lr_model_count, br_lr_model_tfidf, predictions_br_lr_count, predictions_br_lr_tfidf = train_model(br_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4029658",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc450f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BinaryRelevance(LogisticRegression())\n",
    "br_lr_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs=-1, scoring='f1', cv=1)\n",
    "br_lr_model_count_tuned, mo_lr_model_tfidf_tuned, \\\n",
    "    predictions_br_lr_count_tuned, predictions_br_lr_tfidf_tuned = tune_and_train_model(br_lr_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f468b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count_tuned, 'submission_br_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf_tuned, 'submission_br_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88c227",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes <a class=\"anchor\" id=\"br_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f489cc",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_mn = MultiOutputClassifier(MultinomialNB())\n",
    "br_mn_model_count, br_mn_model_tfidf, predictions_br_mn_count, predictions_br_mn_tfidf = train_model(br_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93172647",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78f101",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffed44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MultiOutputClassifier(MultinomialNB())\n",
    "br_mn_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs=-1, scoring='f1', cv=1)\n",
    "br_mn_model_count_tuned, br_mn_model_tfidf_tuned, \\\n",
    "    predictions_br_mn_count_tuned, predictions_br_mn_tfidf_tuned = tune_and_train_model(br_mn_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_mn_count_tuned, 'submission_br_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_br_mn_tfidf_tuned, 'submission_br_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c25c04",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes <a class=\"anchor\" id=\"cc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4b5cf",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mn = ClassifierChain(MultinomialNB())\n",
    "cc_mn_model_count, cc_mn_model_tfidf, predictions_br_mn_count, predictions_br_mn_tfidf = train_model(br_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_cc_lr_count, 'submission_cc_lr_count')\n",
    "to_submission_csv_multiclass(predictions_cc_lr_tfidf, 'submission_cc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ce4f1",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ClassifierChain(MultinomialNB())\n",
    "cc_mn_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs=-1, scoring='f1', cv=1)\n",
    "cc_mn_model_count_tuned, cc_mn_model_tfidf_tuned, \\\n",
    "    predictions_cc_mn_count_tuned, predictions_cc_mn_tfidf_tuned = tune_and_train_model(cc_mn_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a48716",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_cc_mn_count_tuned, 'submission_cc_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_cc_mn_tfidf_tuned, 'submission_cc_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f7ac7",
   "metadata": {},
   "source": [
    "# old stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf32cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 max_iter=3000))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_count = OneVsRestClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_oc_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37058cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 max_iter=3000))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_tf = OneVsRestClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_oc_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4795ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            95.739201\n",
      "severe_toxic     97.941355\n",
      "obscene          98.078598\n",
      "threat           99.375200\n",
      "insult           96.812077\n",
      "identity_hate    98.102412\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ' , accuracy_score(predictions, y_train))\n",
    "\n",
    "predictions = lr_oc_count.predict(count_train)\n",
    "print('Count Vectors: ', accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef14df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_oc_tf = lr_oc_tf.predict_proba(tfidf_test)\n",
    "predictions_lr_oc_count = lr_oc_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ac23fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_oc_tf, 'submission_oc_lr_tf')\n",
    "to_submission_csv(predictions_lr_oc_count, 'submission_oc_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e68800ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_lr_tf.csv</th>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.97621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_oc_lr_count.csv  0.94036  0.94400\n",
       "submission_oc_lr_tf.csv     0.97558  0.97621"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97558], 'public': [0.94400, 0.97621]}, \n",
    "    index=['submission_oc_lr_count.csv', 'submission_oc_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414831b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5198b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a84f7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(LogisticRegression ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d557e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_tf_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_oc_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58ae1c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            98.477167\n",
      "severe_toxic     99.529363\n",
      "obscene          99.205369\n",
      "threat           99.895344\n",
      "insult           98.869469\n",
      "identity_hate    99.662219\n",
      "dtype: float64 {'estimator__C': 12, 'estimator__class_weight': None, 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', accuracy_score(predictions, y_train), lr_oc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86997d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_oc_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_oc_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647d7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "lr_oc_count_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_oc_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oc_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', accuracy_score(predictions, y_train), lr_oc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_oc_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv(predictions_lr_count_tuned, 'submission_oc_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0206f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97558], 'public': [0.94410, 0.97621]}, \n",
    "    index=['submission_oc_lr_count_tuned.csv', 'submission_oc_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dffb0b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf7e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_count = OneVsRestClassifier(MultinomialNB())\n",
    "mn_oc_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfda2b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_tf = OneVsRestClassifier(MultinomialNB())\n",
    "mn_oc_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c466f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n' , accuracy_score(predictions, y_train))\n",
    "\n",
    "predictions = mn_oc_count.predict(count_train)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26cad537",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_oc_tf = mn_oc_tf.predict_proba(tfidf_test)\n",
    "predictions_mn_oc_count = mn_oc_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_oc_tf, 'submission_oc_mn_tf')\n",
    "to_submission_csv(predictions_mn_oc_count, 'submission_oc_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e241161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_tf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_oc_mn_count.csv  0.84551  0.85581\n",
       "submission_oc_mn_tf.csv     0.82510  0.83586"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_oc_mn_count.csv', 'submission_oc_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113669a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2efd1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff8b5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(MultinomialNB ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a077218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_tf_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'accuracy')\n",
    "mn_oc_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "230d91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            93.609114\n",
      "severe_toxic     98.989791\n",
      "obscene          96.043141\n",
      "threat           99.691673\n",
      "insult           95.876444\n",
      "identity_hate    99.106354\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', accuracy_score(predictions, y_train), mn_oc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2903154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_oc_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_oc_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f2e1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_count_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'accuracy')\n",
    "mn_oc_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c226e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64 {'estimator__alpha': 1.0, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', accuracy_score(predictions, y_train), mn_oc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "909b082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_oc_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv(predictions_mn_count_tuned, 'submission_oc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c88e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_count_tuned.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_tf_tuned.csv</th>\n",
       "      <td>0.85045</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_oc_mn_count_tuned.csv  0.84551  0.85581\n",
       "submission_oc_mn_tf_tuned.csv     0.85045  0.86105"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.85045], 'public': [0.85581, 0.86105]}, \n",
    "    index=['submission_oc_mn_count_tuned.csv', 'submission_oc_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a9a1f",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160feff",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "41b713eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           0             0        0       0       0              0\n",
       "4           0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      0             0        0       0       0              0\n",
       "159567      0             0        0       0       0              0\n",
       "159568      0             0        0       0       0              0\n",
       "159569      0             0        0       0       0              0\n",
       "159570      0             0        0       0       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e768790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7564c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_tf = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ededd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ' , accuracy_score(predictions, y_train))\n",
    "\n",
    "predictions = lr_mo_count.predict(count_train)\n",
    "print('Count Vectors: ', accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d96e87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_mo_tf = lr_mo_tf.predict_proba(tfidf_test)\n",
    "predictions_lr_mo_count = lr_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c7ff4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_lr_mo_tf, 'submission_mo_lr_tf')\n",
    "to_submission_csv_multiclass(predictions_lr_mo_count, 'submission_mo_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c4518fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_lr_count.csv  0.94036  0.94400\n",
       "submission_mo_lr_tf.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97063], 'public': [0.94400, 0.97183]}, \n",
    "    index=['submission_mo_lr_count.csv', 'submission_mo_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5096",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7c83146",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8bafa6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(LogisticRegression ())\n",
    "lr_mo_tf_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2d001476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', accuracy_score(predictions, y_train), lr_mo_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "31b6e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_mo_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_lr_tfidf_tuned, 'submission_mo_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d297b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "10449db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            97.936342\n",
      "severe_toxic     98.640730\n",
      "obscene          98.735359\n",
      "threat           99.741808\n",
      "insult           97.858633\n",
      "identity_hate    98.945924\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', accuracy_score(predictions, y_train), lr_mo_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "221b93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_mo_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_lr_count_tuned, 'submission_mo_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d17e95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count_tuned.csv</th>\n",
       "      <td>0.93996</td>\n",
       "      <td>0.94410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf_tuned.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_lr_count_tuned.csv  0.93996  0.94410\n",
       "submission_mo_lr_tf_tuned.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97063], 'public': [0.94410, 0.97183]}, \n",
    "    index=['submission_mo_lr_count_tuned.csv', 'submission_mo_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c8000",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51860474",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "559daa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_count = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6f95889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_tf = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a9795f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n' , accuracy_score(predictions, y_train))\n",
    "\n",
    "predictions = mn_mo_count.predict(count_train)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c1a6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mnb_mo_tf = mn_mo_tf.predict_proba(tfidf_test)\n",
    "predictions_mnb_mo_count = mn_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e99061ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mnb_mo_tf, 'submission_mo_mn_tf')\n",
    "to_submission_csv_multiclass(predictions_mnb_mo_count, 'submission_mo_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bddaaa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_tf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_mn_count.csv  0.84551  0.85581\n",
       "submission_mo_mn_tf.csv     0.82510  0.83586"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_mo_mn_count.csv', 'submission_mo_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d7b5b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1717b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ea0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(MultinomialNB ())\n",
    "mn_mo_tf_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_mo_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b36dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            93.609114\n",
      "severe_toxic     98.989791\n",
      "obscene          96.043141\n",
      "threat           99.691673\n",
      "insult           95.876444\n",
      "identity_hate    99.106354\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n', accuracy_score(predictions, y_train), mn_mo_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe5702db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_mo_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mn_tfidf_tuned, 'submission_mo_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19a946ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_count_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_mo_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58c687c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            95.165162\n",
      "severe_toxic     98.426406\n",
      "obscene          96.575192\n",
      "threat           99.472335\n",
      "insult           96.317627\n",
      "identity_hate    98.473407\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_count_tuned.predict(count_train)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions, y_train), mn_mo_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33e6339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_mo_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_mn_count_tuned, 'submission_mo_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed6b150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_count_tuned.csv</th>\n",
       "      <td>0.87456</td>\n",
       "      <td>0.88221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_tf_tuned.csv</th>\n",
       "      <td>0.85045</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_mn_count_tuned.csv  0.87456  0.88221\n",
       "submission_mo_mn_tf_tuned.csv     0.85045  0.86105"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.87456, 0.85045], 'public': [0.88221, 0.86105]}, \n",
    "    index=['submission_mo_mn_count_tuned.csv', 'submission_mo_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6b9bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tf = ClassifierChain(classifier = MultinomialNB(alpha = 1.0, fit_prior = True))\n",
    "mn_cc_count = ClassifierChain(classifier = MultinomialNB(alpha = 1.0, fit_prior = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ee28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_cc_tf.fit(tfidf_train_5000, y_train)\n",
    "mn_cc_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d20afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            95.029799\n",
      "severe_toxic     98.715932\n",
      "obscene          97.173672\n",
      "threat           99.046819\n",
      "insult           96.766330\n",
      "identity_hate    95.881457\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            94.139913\n",
      "severe_toxic     97.492025\n",
      "obscene          94.467666\n",
      "threat           95.961672\n",
      "insult           94.012070\n",
      "identity_hate    93.246893\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions_mn_cc_tf = mn_cc_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , accuracy_score(predictions_mn_cc_tf.todense(), y_train))\n",
    "\n",
    "predictions_mn_cc_count = mn_cc_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions_mn_cc_count.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ec577f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_cc_tf = mn_cc_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_mn_cc_count = mn_cc_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_cc_tf.todense(), 'submission_tfidf_mn_cc')\n",
    "to_submission_csv(predictions_mn_cc_count.todense(), 'submission_count_mn_cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa47c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_count_mn_cc.csv</th>\n",
       "      <td>0.92866</td>\n",
       "      <td>0.92896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_tfidf_mn_cc.csv</th>\n",
       "      <td>0.94711</td>\n",
       "      <td>0.94614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_count_mn_cc.csv  0.92866  0.92896\n",
       "submission_tfidf_mn_cc.csv  0.94711  0.94614"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.92866, 0.94711], 'public': [0.92896, 0.94614]}, \n",
    "    index=['submission_count_mn_cc.csv', 'submission_tfidf_mn_cc.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b3cf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "estimator = ClassifierChain(MultinomialNB ())\n",
    "mn_cc_tf_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_cc_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', accuracy_score(predictions.todense(), y_train), mn_cc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_cc_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned.todense(), 'submission_cc_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_count_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_cc_count_tuned.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions.todense(), y_train), mn_cc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_cc_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_mn_count_tuned.todense(), 'submission_cc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_cc_mn_count_tuned.csv', 'submission_cc_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f016da",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acab8b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4437362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr_tf = BinaryRelevance(classifier = LogisticRegression())\n",
    "br_lr_count = BinaryRelevance(classifier = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721df04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "br_lr_tf.fit(tfidf_train_5000, y_train)\n",
    "br_lr_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_br_lr_tf = br_lr_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , accuracy_score(predictions_br_lr_tf.todense(), y_train))\n",
    "\n",
    "predictions_br_lr_count = br_lr_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions_br_lr_count.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_br_lr_tf = br_lr_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_br_lr_count = br_lr_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6451a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_br_lr_tf.todense(), 'submission_tfidf_lr_br')\n",
    "to_submission_csv(predictions_br_lr_count.todense(), 'submission_count_lr_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_count_lr_br.csv', 'submission_tfidf_lr_br.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921bad",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22772ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BinaryRelevance(LogisticRegression ())\n",
    "lr_cc_tf_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_cc_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_cc_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', accuracy_score(predictions.todense(), y_train), lr_cc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_cc_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned.todense(), 'submission_lr_cc_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea099b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_br_count_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_br_count_tuned.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_br_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions.todense(), y_train), lr_br_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ede017",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_br_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_lr_count_tuned.todense(), 'submission_lr_cc_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db979687",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_count_lr_br.csv', 'submission_tfidf_lr_br.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633710",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b35262",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46acf7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbd5abc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_br_count = BinaryRelevance(MultinomialNB())\n",
    "mn_br_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "233d93db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_br_tf = BinaryRelevance(MultinomialNB())\n",
    "mn_br_tf.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87de363b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            95.029799\n",
      "severe_toxic     99.088180\n",
      "obscene          97.347889\n",
      "threat           99.702327\n",
      "insult           96.954960\n",
      "identity_hate    99.159622\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            94.139913\n",
      "severe_toxic     98.111186\n",
      "obscene          96.105182\n",
      "threat           98.551115\n",
      "insult           95.760508\n",
      "identity_hate    97.667496\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_br_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , accuracy_score(predictions.todense(), y_train))\n",
    "\n",
    "predictions = mn_br_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55c5e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mnb_br_tf = mn_br_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_mnb_br_count = mn_br_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3351f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_br_tf.todense(), 'submission_br_mn_tf')\n",
    "to_submission_csv(predictions_mnb_br_count.todense(), 'submission_br_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_br_mn_count.csv', 'submission_br_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e32a6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a624d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BinaryRelevance(MultinomialNB())\n",
    "mn_br_tf_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_br_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7526d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', accuracy_score(predictions.todense(), y_train), mn_br_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_br_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned.todense(), 'submission_br_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_count_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_br_count_tuned.fit(count_train_5000, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac99605",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', accuracy_score(predictions.todense(), y_train), mn_br_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_br_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_mn_count_tuned.todense(), 'submission_br_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97146af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_br_mn_count_tuned.csv', 'submission_br_mn_tf_tuned.csv']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
