{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "### Import\n",
    "Several libraries are required to perform a thorough analysis of the dataset. Each of these libraries will be imported and described below:\n",
    "\n",
    "#### Basic Libraries \n",
    "Import `numpy` and `pandas`.\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb8d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Datasets and Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Trying different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mn_hyper_parameter:\n",
    "    def __init__(self, class_, alpha, fit_prior):\n",
    "        self.class_ = class_\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c247db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_hyperparameter:\n",
    "    def __init__(self, class_, c, max_iter):\n",
    "        self.class_ = class_\n",
    "        self.c = c\n",
    "        self.max_iter = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fafb6",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61100a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    accuracy = np.sum (predictions == actual) / len (predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv(predictions, filename):\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    sample_submission ['id'] = test ['id'] \n",
    "    counter = 0\n",
    "\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a0a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv_multiclass (predictions, filename):\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    sample_submission ['id'] = test ['id'] \n",
    "    counter = 0\n",
    "\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec21a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model):\n",
    "    predictions_count = np.zeros((len(test), len(classes)))\n",
    "    predictions_tfidf = np.zeros((len(test), len(classes)))\n",
    "    models = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        print('Fitting', classes[i] + '...')\n",
    "\n",
    "        mdl = model\n",
    "        mdl.fit(count_train, y_train[classes[i]])\n",
    "        print('Count Vectors:', compute_accuracy(mdl.predict(count_train), y_train[classes[i]]))\n",
    "        predictions_count[:,i] = mdl.predict_proba(count_test)[:,1]\n",
    "\n",
    "        mdl = model\n",
    "        mdl.fit(tfidf_train, y_train[classes[i]])\n",
    "        print('TF-IDF Vectors:', compute_accuracy(mdl.predict(tfidf_train), y_train[classes[i]]))\n",
    "        predictions_tfidf[:,i] = mdl.predict_proba(tfidf_test)[:,1]\n",
    "    \n",
    "    return models, predictions_count, predictions_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beed1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_models(model):\n",
    "    predictions_count_tuned = np.zeros((len(test), len(classes)))\n",
    "    predictions_tfidf_tuned = np.zeros((len(test), len(classes)))\n",
    "\n",
    "    for i in range(6):\n",
    "        print('Fitting', classes[i] + '...')\n",
    "\n",
    "        mdl_tuned = model\n",
    "        mdl_tuned.fit(count_train, y_train[classes[i]])\n",
    "        print('Count Vectors:', compute_accuracy(mdl_tuned.predict(count_train), y_train[classes[i]]), mdl_tuned.best_params_)\n",
    "        predictions_count_tuned[:,i] = mdl_tuned.predict_proba(count_test)[:,1]\n",
    "\n",
    "        mdl_tuned = model\n",
    "        mdl_tuned.fit(tfidf_train, y_train[classes[i]])\n",
    "        print('TF-IDF Vectors:', compute_accuracy(mdl_tuned.predict(tfidf_train), y_train[classes[i]]), mdl_tuned.best_params_)\n",
    "        predictions_tfidf_tuned[:,i] = mdl_tuned.predict_proba(tfidf_test)[:,1]\n",
    "    \n",
    "    return predictions_count_tuned, predictions_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98318366",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f9a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0085708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_5000 = TfidfVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff713513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_5000 = tfidf_vectorizer_5000.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "758c0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_5000 = tfidf_vectorizer_5000.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0ad45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0caa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ebad703",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "327ed991",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_5000 = CountVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d460312",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train_5000 = count_vectorizer_5000.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "433d031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tes_5000t = count_vectorizer_5000.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_multi = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_multi = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [1, 12, 15],\n",
    "        'classifier__max_iter': [600, 1800, 3000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_mo = [\n",
    "    {\n",
    "        'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'estimator__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "153902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [\n",
    "    {\n",
    "        'estimator__C': [1, 12, 15],\n",
    "        'estimator__max_iter': [600, 1800, 3000],\n",
    "        'estimator__class_weight' : ['balanced', None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee4b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [\n",
    "    {\n",
    "        'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "        'fit_prior' : [False, True]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c75638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [\n",
    "    {\n",
    "        'C' : [1, 12, 15],\n",
    "        'max_iter' :[600, 1800, 3000, 4200]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "865abbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = [\n",
    "    {\n",
    "        'n_estimators' : [500, 1000, 1500],\n",
    "        'min_samples_split' : [2, 10, 20],\n",
    "        'max_leaf_nodes' : [15, 20, 25],\n",
    "        'min_samples_leaf' : [1, 5, 10],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d6f2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bda0dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 97.1943523572579\n",
      "TF-IDF Vectors: 96.23553151888501\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.19596919239711\n",
      "TF-IDF Vectors: 99.12578100030707\n",
      "Fitting obscene...\n",
      "Count Vectors: 98.13750618846782\n",
      "TF-IDF Vectors: 97.95514222509102\n",
      "Fitting threat...\n",
      "Count Vectors: 99.79632890688158\n",
      "TF-IDF Vectors: 99.73366087822976\n",
      "Fitting insult...\n",
      "Count Vectors: 97.40241021238195\n",
      "TF-IDF Vectors: 97.39551672923025\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 99.27681094935797\n",
      "TF-IDF Vectors: 99.24109017302642\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_models, predictions_lr_count, predictions_lr_tfidf = train_models(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca9c3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count, 'submission_lr_count')\n",
    "to_submission_csv(predictions_lr_tfidf, 'submission_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c974dc",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count</td>\n",
    "    <td class=\"tg-baqh\">0.93926</td>\n",
    "    <td class=\"tg-baqh\">0.94248</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97391</td>\n",
    "    <td class=\"tg-baqh\">0.97376</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebed0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40056ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tuned = GridSearchCV(LogisticRegression(n_jobs=-1), parameters_lr, scoring='f1', verbose=2)\n",
    "lr_models_tuned, predictions_lr_count_tuned, predictions_lr_tfidf_tuned = tune_and_train_models(lr_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448f00b",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5546",
   "metadata": {},
   "source": [
    "### Naive Bayes: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16aa7cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 95.13696097661855\n",
      "TF-IDF Vectors: 92.36828747078103\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.641983819115\n",
      "TF-IDF Vectors: 98.99104473870565\n",
      "Fitting obscene...\n",
      "Count Vectors: 96.70867513520626\n",
      "TF-IDF Vectors: 95.38449968979326\n",
      "Fitting threat...\n",
      "Count Vectors: 99.55505699657206\n",
      "TF-IDF Vectors: 99.6973134216117\n",
      "Fitting insult...\n",
      "Count Vectors: 96.46301646289113\n",
      "TF-IDF Vectors: 95.35629907689994\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 98.77233331871079\n",
      "TF-IDF Vectors: 99.11074067343063\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb_models, predictions_mnb_count, predictions_mnb_tfidf = train_models(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8eee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_count, 'submission_mnb_count')\n",
    "to_submission_csv(predictions_mnb_tfidf, 'submission_mnb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaedef",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count</td>\n",
    "    <td class=\"tg-baqh\">0.84551</td>\n",
    "    <td class=\"tg-baqh\">0.85581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.82510</td>\n",
    "    <td class=\"tg-baqh\">0.83586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e45539",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c0eefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecf109d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 95.13696097661855 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 97.48262528905627 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.72031885492977 {'alpha': 0.001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.42157409554368 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting obscene...\n",
      "Count Vectors: 96.70867513520626 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 98.62067668937338 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting threat...\n",
      "Count Vectors: 99.31315840597603 {'alpha': 0.0001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.87403726240983 {'alpha': 1e-05, 'fit_prior': True}\n",
      "Fitting insult...\n",
      "Count Vectors: 96.46301646289113 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 98.40384531023808 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 98.69337160260949 {'alpha': 0.0001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.56759060230243 {'alpha': 0.001, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "mnb_tuned = GridSearchCV(MultinomialNB(), parameters_mnb, scoring='f1')\n",
    "mnb_tuned_models, predictions_mnb_count_tuned, predictions_mnb_tfidf_tuned = tune_and_train_models(mnb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9017ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_count_tuned, 'submission_mnb_count_tuned')\n",
    "to_submission_csv(predictions_mnb_tfidf_tuned, 'submission_mnb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3ce89",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.88069</td>\n",
    "    <td class=\"tg-baqh\">0.88388</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.91455</td>\n",
    "    <td class=\"tg-baqh\">0.91739</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b957",
   "metadata": {},
   "source": [
    "### Ensemble Models: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25c706c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 99.97869287025839\n",
      "TF-IDF Vectors: 99.97743950968534\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.98558635341008\n",
      "TF-IDF Vectors: 99.97493278853928\n",
      "Fitting obscene...\n",
      "Count Vectors: 99.98370631255052\n",
      "TF-IDF Vectors: 99.9793195505449\n",
      "Fitting threat...\n",
      "Count Vectors: 99.99435987742133\n",
      "TF-IDF Vectors: 99.99373319713482\n",
      "Fitting insult...\n",
      "Count Vectors: 99.96991934624712\n",
      "TF-IDF Vectors: 99.9655325842415\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 99.9931065168483\n",
      "TF-IDF Vectors: 99.98934643512919\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf_models, predictions_rf_count, predictions_rf_tfidf = train_models(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aa6ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058de190",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.96735, 0.96784], 'public': [0.96725, 0.96710]}, \n",
    "    index=['submission_rf_count.csv', 'submission_rf_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd252b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1223467",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 20, 30],\n",
    "    'min_samples_split' : [2, 4, 6, 10, 15, 20],\n",
    "    'max_leaf_nodes' : [3, 5, 10, 20, 50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d81585ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 90.41680505856327 {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 90.4180584191363 {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Fitting severe_toxic...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 99.00044494300343 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 99.00044494300343 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting obscene...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 94.70580493949402 {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 94.7051782592075 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting threat...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 99.70170018361732 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 99.70044682304429 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting insult...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 95.06363938309592 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 95.06363938309592 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting identity_hate...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 99.11951419744189 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 99.11951419744189 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "rf_tuned = RandomizedSearchCV(RandomForestClassifier(n_jobs=-1), parameters_rf, scoring='f1', random_state=8, verbose=1)\n",
    "rf_tuned_models, predictions_rf_count_tuned, predictions_rf_tfidf_tuned = tune_and_train_models(rf_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dabb22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6a8aa",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.96232</td>\n",
    "    <td class=\"tg-baqh\">0.96285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.95937</td>\n",
    "    <td class=\"tg-baqh\">0.95826</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6d61c",
   "metadata": {},
   "source": [
    "### Ensemble Models: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc_models, predictions_gbc_count, predictions_gbc_tfidf = train_models(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.90663, 0.92569], 'public': [0.92024, 0.93239]}, \n",
    "    index=['submission_gbc_count.csv', 'submission_gbc_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83bea7",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gbc = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_tuned = RandomizedSearchCV(GradientBoostingClassifier(), parameters_gbc, scoring='accuracy', random_state=8, verbose=2)\n",
    "gbc_tuned_models, predictions_gbc_count_tuned, predictions_gbc_tfidf_tuned = tune_and_train_models(gbc_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count_tuned, 'submission_gbc_count_tuned')\n",
    "to_submission_csv(predictions_gbc_tfidf_tuned, 'submission_gbc_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f4fd",
   "metadata": {},
   "source": [
    "### Ensemble Models: XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba086e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(eval_metric='logloss', verbosity=0, use_label_encoder=False)\n",
    "xgb_models, predictions_xgb_count, predictions_xgb_tfidf = train_models(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count, 'submission_xgb_count')\n",
    "to_submission_csv(predictions_xgb_tfidf, 'submission_xgb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgb = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc921ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb_tuned = GridSearchCV(xgboost.XGBClassifier(eval_metric='logloss', verbosity=0, use_label_encoder=False), parameters_xgb, scoring='f1')\n",
    "xgb_tuned_models, predictions_xgb_count_tuned, predictions_xgb_tfidf_tuned = tune_and_train_models(xgb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea054",
   "metadata": {},
   "source": [
    "### Ensemble Models: AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ad694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier()\n",
    "adb_models, predictions_adb_count, predictions_adb_tfidf = train_models(adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a51c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d417eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_adb = {\n",
    "    'n_estimators' : [10, 25, 50, 100, 250],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_tuned = GridSearchCV(AdaBoostClassifier(), parameters_adb, scoring='accuracy')\n",
    "adb_tuned_models, predictions_adb_count_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803b2a5",
   "metadata": {},
   "source": [
    "### Support Vector Machines: SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30717932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='log', n_jobs=-1)\n",
    "sgd_models, predictions_sgd_count, predictions_sgd_tfidf = train_models(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count, 'submission_sgd_count')\n",
    "to_submission_csv(predictions_sgd_tfidf, 'submission_sgd_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9417b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.92026, 0.95112], 'public': [0.92912, 0.95232]}, \n",
    "    index=['submission_sgd_count.csv', 'submission_sgd_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd2aa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86d719b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sgd = [{\n",
    "    'loss' : ['log', 'modified_huber'],\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e5e602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 97.49139881306755 {'alpha': 1e-05, 'loss': 'log'}\n",
      "TF-IDF Vectors: 98.16570680136115 {'alpha': 1e-05, 'loss': 'modified_huber'}\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.08003333939124 {'alpha': 0.01, 'loss': 'log'}\n",
      "TF-IDF Vectors: 99.10760727199805 {'alpha': 1e-05, 'loss': 'log'}\n",
      "Fitting obscene...\n",
      "Count Vectors: 97.64681552412405 {'alpha': 1e-05, 'loss': 'log'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6a19d5243bca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msgd_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_sgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions_sgd_count_tuned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_sgd_tfidf_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtune_and_train_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_tuned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-ddbb18bf0bbc>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmdl_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TF-IDF Vectors:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredictions_tfidf_tuned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         \"\"\"\n\u001b[1;32m--> 729\u001b[1;33m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[0;32m    730\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[0m\u001b[0;32m    570\u001b[0m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                  max_iter=max_iter)\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             self._fit_binary(X, y, alpha=alpha, C=C,\n\u001b[0m\u001b[0;32m    527\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    581\u001b[0m                     learning_rate, max_iter):\n\u001b[0;32m    582\u001b[0m         \u001b[1;34m\"\"\"Fit a binary classifier on X and y. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         coef, intercept, n_iter_ = fit_binary(self, 1, X, y, alpha, C,\n\u001b[0m\u001b[0;32m    584\u001b[0m                                               \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m     coef, intercept, average_coef, average_intercept, n_iter_ = _plain_sgd(\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mpenalty_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgd_tuned = GridSearchCV(SGDClassifier(n_jobs=-1), parameters_sgd, scoring='accuracy')\n",
    "predictions_sgd_count_tuned, predictions_sgd_tfidf_tuned = tune_and_train_models(sgd_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571180e0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf32cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 max_iter=3000))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_count = OneVsRestClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_oc_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37058cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 max_iter=3000))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_tf = OneVsRestClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_oc_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4795ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            95.739201\n",
      "severe_toxic     97.941355\n",
      "obscene          98.078598\n",
      "threat           99.375200\n",
      "insult           96.812077\n",
      "identity_hate    98.102412\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = lr_oc_count.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef14df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_oc_tf = lr_oc_tf.predict_proba(tfidf_test)\n",
    "predictions_lr_oc_count = lr_oc_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ac23fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_oc_tf, 'submission_oc_lr_tf')\n",
    "to_submission_csv(predictions_lr_oc_count, 'submission_oc_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e68800ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_lr_tf.csv</th>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.97621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_oc_lr_count.csv  0.94036  0.94400\n",
       "submission_oc_lr_tf.csv     0.97558  0.97621"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97558], 'public': [0.94400, 0.97621]}, \n",
    "    index=['submission_oc_lr_count.csv', 'submission_oc_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414831b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5198b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a84f7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(LogisticRegression ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d557e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_tf_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_oc_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58ae1c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            98.477167\n",
      "severe_toxic     99.529363\n",
      "obscene          99.205369\n",
      "threat           99.895344\n",
      "insult           98.869469\n",
      "identity_hate    99.662219\n",
      "dtype: float64 {'estimator__C': 12, 'estimator__class_weight': None, 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), lr_oc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86997d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_oc_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_oc_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647d7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "lr_oc_count_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_oc_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oc_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), lr_oc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_oc_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv(predictions_lr_count_tuned, 'submission_oc_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0206f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97558], 'public': [0.94410, 0.97621]}, \n",
    "    index=['submission_oc_lr_count_tuned.csv', 'submission_oc_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ea0d0",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dffb0b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf7e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_count = OneVsRestClassifier(MultinomialNB())\n",
    "mn_oc_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfda2b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_tf = OneVsRestClassifier(MultinomialNB())\n",
    "mn_oc_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c466f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = mn_oc_count.predict(count_train)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26cad537",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_oc_tf = mn_oc_tf.predict_proba(tfidf_test)\n",
    "predictions_mn_oc_count = mn_oc_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_oc_tf, 'submission_oc_mn_tf')\n",
    "to_submission_csv(predictions_mn_oc_count, 'submission_oc_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e241161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_tf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_oc_mn_count.csv  0.84551  0.85581\n",
       "submission_oc_mn_tf.csv     0.82510  0.83586"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_oc_mn_count.csv', 'submission_oc_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113669a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2efd1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff8b5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(MultinomialNB ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a077218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_tf_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'accuracy')\n",
    "mn_oc_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "230d91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            93.609114\n",
      "severe_toxic     98.989791\n",
      "obscene          96.043141\n",
      "threat           99.691673\n",
      "insult           95.876444\n",
      "identity_hate    99.106354\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), mn_oc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2903154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_oc_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_oc_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f2e1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_count_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'accuracy')\n",
    "mn_oc_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c226e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64 {'estimator__alpha': 1.0, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), mn_oc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "909b082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_oc_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv(predictions_mn_count_tuned, 'submission_oc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c88e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_count_tuned.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_tf_tuned.csv</th>\n",
       "      <td>0.85045</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_oc_mn_count_tuned.csv  0.84551  0.85581\n",
       "submission_oc_mn_tf_tuned.csv     0.85045  0.86105"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.85045], 'public': [0.85581, 0.86105]}, \n",
    "    index=['submission_oc_mn_count_tuned.csv', 'submission_oc_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a9a1f",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160feff",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "41b713eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           0             0        0       0       0              0\n",
       "4           0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      0             0        0       0       0              0\n",
       "159567      0             0        0       0       0              0\n",
       "159568      0             0        0       0       0              0\n",
       "159569      0             0        0       0       0              0\n",
       "159570      0             0        0       0       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e768790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7564c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_tf = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ededd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = lr_mo_count.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d96e87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_mo_tf = lr_mo_tf.predict_proba(tfidf_test)\n",
    "predictions_lr_mo_count = lr_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c7ff4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_lr_mo_tf, 'submission_mo_lr_tf')\n",
    "to_submission_csv_multiclass(predictions_lr_mo_count, 'submission_mo_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c4518fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_lr_count.csv  0.94036  0.94400\n",
       "submission_mo_lr_tf.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97063], 'public': [0.94400, 0.97183]}, \n",
    "    index=['submission_mo_lr_count.csv', 'submission_mo_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5096",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7c83146",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8bafa6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(LogisticRegression ())\n",
    "lr_mo_tf_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2d001476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), lr_mo_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "31b6e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_mo_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_lr_tfidf_tuned, 'submission_mo_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d297b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "10449db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            97.936342\n",
      "severe_toxic     98.640730\n",
      "obscene          98.735359\n",
      "threat           99.741808\n",
      "insult           97.858633\n",
      "identity_hate    98.945924\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), lr_mo_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "221b93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_mo_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_lr_count_tuned, 'submission_mo_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d17e95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count_tuned.csv</th>\n",
       "      <td>0.93996</td>\n",
       "      <td>0.94410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf_tuned.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_lr_count_tuned.csv  0.93996  0.94410\n",
       "submission_mo_lr_tf_tuned.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97063], 'public': [0.94410, 0.97183]}, \n",
    "    index=['submission_mo_lr_count_tuned.csv', 'submission_mo_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c8000",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51860474",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "559daa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_count = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6f95889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_tf = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a9795f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = mn_mo_count.predict(count_train)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c1a6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mnb_mo_tf = mn_mo_tf.predict_proba(tfidf_test)\n",
    "predictions_mnb_mo_count = mn_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e99061ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mnb_mo_tf, 'submission_mo_mn_tf')\n",
    "to_submission_csv_multiclass(predictions_mnb_mo_count, 'submission_mo_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bddaaa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_tf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_mn_count.csv  0.84551  0.85581\n",
       "submission_mo_mn_tf.csv     0.82510  0.83586"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_mo_mn_count.csv', 'submission_mo_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d7b5b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1717b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ea0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(MultinomialNB ())\n",
    "mn_mo_tf_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_mo_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b36dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            93.609114\n",
      "severe_toxic     98.989791\n",
      "obscene          96.043141\n",
      "threat           99.691673\n",
      "insult           95.876444\n",
      "identity_hate    99.106354\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions, y_train), mn_mo_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe5702db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_mo_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mn_tfidf_tuned, 'submission_mo_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19a946ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_count_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_mo_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58c687c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            95.165162\n",
      "severe_toxic     98.426406\n",
      "obscene          96.575192\n",
      "threat           99.472335\n",
      "insult           96.317627\n",
      "identity_hate    98.473407\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_count_tuned.predict(count_train)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions, y_train), mn_mo_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33e6339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_mo_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_mn_count_tuned, 'submission_mo_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed6b150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_count_tuned.csv</th>\n",
       "      <td>0.87456</td>\n",
       "      <td>0.88221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_tf_tuned.csv</th>\n",
       "      <td>0.85045</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_mn_count_tuned.csv  0.87456  0.88221\n",
       "submission_mo_mn_tf_tuned.csv     0.85045  0.86105"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.87456, 0.85045], 'public': [0.88221, 0.86105]}, \n",
    "    index=['submission_mo_mn_count_tuned.csv', 'submission_mo_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6b9bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tf = ClassifierChain(classifier = MultinomialNB(alpha = 1.0, fit_prior = True))\n",
    "mn_cc_count = ClassifierChain(classifier = MultinomialNB(alpha = 1.0, fit_prior = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26ee28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_cc_tf.fit(tfidf_train_5000, y_train)\n",
    "mn_cc_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d20afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            95.029799\n",
      "severe_toxic     98.715932\n",
      "obscene          97.173672\n",
      "threat           99.046819\n",
      "insult           96.766330\n",
      "identity_hate    95.881457\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            94.139913\n",
      "severe_toxic     97.492025\n",
      "obscene          94.467666\n",
      "threat           95.961672\n",
      "insult           94.012070\n",
      "identity_hate    93.246893\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions_mn_cc_tf = mn_cc_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions_mn_cc_tf.todense(), y_train))\n",
    "\n",
    "predictions_mn_cc_count = mn_cc_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions_mn_cc_count.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ec577f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_cc_tf = mn_cc_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_mn_cc_count = mn_cc_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_cc_tf.todense(), 'submission_tfidf_mn_cc')\n",
    "to_submission_csv(predictions_mn_cc_count.todense(), 'submission_count_mn_cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaa47c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_count_mn_cc.csv</th>\n",
       "      <td>0.92866</td>\n",
       "      <td>0.92896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_tfidf_mn_cc.csv</th>\n",
       "      <td>0.94711</td>\n",
       "      <td>0.94614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_count_mn_cc.csv  0.92866  0.92896\n",
       "submission_tfidf_mn_cc.csv  0.94711  0.94614"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.92866, 0.94711], 'public': [0.92896, 0.94614]}, \n",
    "    index=['submission_count_mn_cc.csv', 'submission_tfidf_mn_cc.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b3cf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "estimator = ClassifierChain(MultinomialNB ())\n",
    "mn_cc_tf_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_cc_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_cc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_cc_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned.todense(), 'submission_cc_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_count_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_cc_count_tuned.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_cc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_cc_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_mn_count_tuned.todense(), 'submission_cc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_cc_mn_count_tuned.csv', 'submission_cc_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f016da",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acab8b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4437362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr_tf = BinaryRelevance(classifier = LogisticRegression())\n",
    "br_lr_count = BinaryRelevance(classifier = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721df04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "br_lr_tf.fit(tfidf_train_5000, y_train)\n",
    "br_lr_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_br_lr_tf = br_lr_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions_br_lr_tf.todense(), y_train))\n",
    "\n",
    "predictions_br_lr_count = br_lr_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions_br_lr_count.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_br_lr_tf = br_lr_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_br_lr_count = br_lr_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6451a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_br_lr_tf.todense(), 'submission_tfidf_lr_br')\n",
    "to_submission_csv(predictions_br_lr_count.todense(), 'submission_count_lr_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_count_lr_br.csv', 'submission_tfidf_lr_br.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921bad",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22772ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BinaryRelevance(LogisticRegression ())\n",
    "lr_cc_tf_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_cc_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_cc_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions.todense(), y_train), lr_cc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_cc_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned.todense(), 'submission_lr_cc_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea099b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_br_count_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_br_count_tuned.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_br_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train), lr_br_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ede017",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_br_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_lr_count_tuned.todense(), 'submission_lr_cc_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db979687",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_count_lr_br.csv', 'submission_tfidf_lr_br.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633710",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b35262",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46acf7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_count = MultiOutputClassifier(MultinomialNB())\n",
    "mn_br_count.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tf = MultiOutputClassifier(MultinomialNB())\n",
    "mn_br_tf.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions.todense(), y_train))\n",
    "\n",
    "predictions = mn_br_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mnb_br_tf = mn_br_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_mnb_br_count = mn_br_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3351f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_br_tf.todense(), 'submission_br_mn_tf')\n",
    "to_submission_csv(predictions_mnb_br_count.todense(), 'submission_br_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_br_mn_count.csv', 'submission_br_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e32a6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ClassifierChain(MultinomialNB ())\n",
    "mn_br_tf_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_br_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7526d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_br_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_br_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned.todense(), 'submission_br_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_count_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_br_count_tuned.fit(count_train_5000, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac99605",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_br_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_br_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_mn_count_tuned.todense(), 'submission_br_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97146af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_br_mn_count_tuned.csv', 'submission_br_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c3b8",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0528ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf324509",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(tfidf_train, y_train)\n",
    "    predictions = model.predict(tfidf_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc574c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tfidf_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a8714",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_mnb):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cdd89",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d69379",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2508e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab42516",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24309156",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ea51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(count_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(count_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "sample_submission.to_csv(f'results/submission_count_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6d970",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_mnb):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70786f3",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269a8fd",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036227",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression (n_jobs=-1)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict_proba(tf_idf_test)[:,1]\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_logreg_1.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba88dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d8f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_lr):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ec8a5",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7246",
   "metadata": {},
   "source": [
    "### Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cba4",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408644e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05384cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_lr):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87ee1a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f612c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg_tuned.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
