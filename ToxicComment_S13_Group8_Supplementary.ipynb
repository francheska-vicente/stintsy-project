{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "#### Basic Libraries \n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations\n",
    "- `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features \n",
    "- `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce303532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries\n",
    "The following code block can be used to install **scikit-multilearn** without restarting Jupyter Notebook. The `sys` module is used to access the *executable* function of the interpreter, which would run the installation of scikit-multilearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850d2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a154c",
   "metadata": {},
   "source": [
    "The following libraries are multi-label classification modules that would allow the usage of one model that can classify one instance as more than one class.\n",
    "- `ClassifierChain` chains binary classifiers in a way that its predictions are dependent on the earlier classes\n",
    "- `BinaryRelevance` uses binary classifiers to classify the classes independently\n",
    "- `MultiOutputClassifier` fits one classifier per target class \n",
    "- `OneVsRestClassifier` fits one class against the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea567ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7f3",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "- `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees\n",
    "- `GradientBoostingClassifier` is a class under the ensemble module that optimizes arbitrary differentiable loss functions\n",
    "- `AdaBoostClassifier` is a class under the ensemble module that implements AdaBoost-SAMME\n",
    "- `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "- `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "- `SGDClassifier` is a class under the linear models module that implements regularized linear models with stochastic gradient descent (SGD) learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e6642",
   "metadata": {},
   "source": [
    "Meanwhile, the following classes are used for hyperparameter tuning.\n",
    "- `ParameterGrid` is a class that allows the iteration over different combinations of parameter values \n",
    "- `GridSearchCV` is a cross-validation class that allows the exhaustive search over all possible combinations of hyperparameter values\n",
    "- `RandomizedSearchCV` is a cross-validation class that allows a random search over some possible combinations of hyperparameter values\n",
    "- `train_test_split` divides the dataset into two subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f9c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688e12a",
   "metadata": {},
   "source": [
    "And lastly, these classes computes different scores about how well a model works.\n",
    "- `log_loss` computes the Logistic loss given the true values and the predicted values\n",
    "- `f1_score` computes the balanced F-score by comparing the actual classes and the predicted classes\n",
    "- `accuracy_score` computes the accuracy by determining how many classes were correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2710dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878a641",
   "metadata": {},
   "source": [
    "The warnings module is used to ignore any ConvergenceWarnings that might appear when doing hyperparameter tuning. As these models will not be chosen due to low accuracy scores, the warnings would only clutter the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Load Files\n",
    "The csv files to be loaded here contains the datasets that have already gone through the data cleaning and preprocessing techniques discussed in the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe1ca0f",
   "metadata": {},
   "source": [
    "## Initialize Datasets\n",
    "Before using these datasets, we would need to convert the values in the `comment_text` column into either \"str, unicode or file objects\", according to the documentation of TF-IDF vectorizer and Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7c6cd",
   "metadata": {},
   "source": [
    "Then, we would be declaring our **X_train**, **y_train**, and **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed343812",
   "metadata": {},
   "source": [
    "Afterwards, we would be declaring the different classes that our model would need to predict. This can be found in the **train** data's column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "## Vectorizing Data\n",
    "As explained in the **Feature Engineering** part of the main notebook, three types of vectorizers would be used: (1) Count Vectorizer, (2) TF-IDF Vectorizer, and (3) Average Word2Vec Vectors.\n",
    "\n",
    "Two types of CountVectorizer and TF-IDF Vectorizers were made in consideration of the more complex estimators: one with no **max_features** parameter, and one with a **max_features** parameter that is equal to 5000. Limiting the number of max features would lessen the time and space complexity from training the estimators; this would lessen the burden on our machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18f9b5",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6d1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()                     # creating the Vectorizer with no max features\n",
    "count_train = count_vectorizer.fit_transform(X_train)    # fitting the vectorizer according to the train data, and then\n",
    "                                                         # returning the transformed train data\n",
    "count_test = count_vectorizer.transform(X_test)          # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_5000 = CountVectorizer(max_features = 5000)     # creating the Vectorizer with max features = 5000\n",
    "count_train_5000 = count_vectorizer_5000.fit_transform(X_train)  # fitting the vectorizer according to the train data, and then\n",
    "                                                                 # returning the transformed train data\n",
    "count_test_5000 = count_vectorizer_5000.transform(X_test)        # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec4160",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60850d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()                    # creating the Vectorizer with no max features\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)   # fitting the vectorizer according to the train data, and then\n",
    "                                                        # returning the transformed train data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)         # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_5000 = TfidfVectorizer(max_features = 5000)    # creating the Vectorizer with max features = 5000\n",
    "tfidf_train_5000 = tfidf_vectorizer_5000.fit_transform(X_train) # fitting the vectorizer according to the train data, and then\n",
    "                                                                # returning the transformed train data\n",
    "tfidf_test_5000 = tfidf_vectorizer_5000.transform(X_test)       # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c4764",
   "metadata": {},
   "source": [
    "#### Average Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b109c",
   "metadata": {},
   "source": [
    "Before building a Word2Vec model, the data must be tokenized to produce a list of lists of tokens as indicated in Gensim's documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff7141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    t = TweetTokenizer()\n",
    "\n",
    "    tokens_list = []\n",
    "    for text in data:\n",
    "        tokens_list += [t.tokenize(text)]\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1f560",
   "metadata": {},
   "source": [
    "The train set is tokenized using NLTK's `TweetTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa9d937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenize(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26d183",
   "metadata": {},
   "source": [
    "The Word2Vec model is trained using this tokenized list, which would transform these words into word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6dbd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd2v_model = Word2Vec(tokens_train, epochs=30, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24797b6a",
   "metadata": {},
   "source": [
    "To transform the word vectors into usable features, these vectors are averaged for all words in the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fe9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_word2vec(model, tokens_list):\n",
    "    vectors = []\n",
    "    \n",
    "    for tokens in tokens_list:                    # iterate through each sentence\n",
    "        feat = np.zeros(100)                      # initializes a list that will hold the vectors\n",
    "        count = 0                                 # initializes the word count for a sentence\n",
    "        \n",
    "        for token in tokens:                      # iterate through each word in the sentence\n",
    "            if token in model.wv.index_to_key:    # if the word is in the model's vocabulary...\n",
    "                feat += model.wv[token]           # ...add word vectors to list and...\n",
    "                count += 1                        # ...update the word count\n",
    "        \n",
    "        if count > 1:                             # if sentence contains more than 1 word in the model...\n",
    "            feat /= count                         # ...divide word vectors by word count to get the average\n",
    "            \n",
    "        vectors.append(feat)                      # add the averaged vectors to the list\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfed1a7",
   "metadata": {},
   "source": [
    "Using the defined function, the train data can be vectorized using the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d6de79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrd2v_train = vectorize_word2vec(word2vec_model, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234fc22",
   "metadata": {},
   "source": [
    "The test data is also vectorized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = tokenize(X_test)\n",
    "wrd2v_test = vectorize_word2vec(word2vec_model, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac6bbd",
   "metadata": {},
   "source": [
    "## Training and Tuning Different Models <a class=\"anchor\" id=\"toc\"></a>\n",
    "TODO: i ken fly\n",
    "\n",
    "#### Variable and Function Declarations\n",
    "* [**Helper Functions**](#functs)\n",
    "* [**Hyperparameters**](#params)\n",
    "\n",
    "### Six Single-Label Classifiers\n",
    "* [**Logistic Regression**](#lr)\n",
    "* [**Multinomial Naive Bayes**](#mn)\n",
    "* [**Random Forest Classifier**](#rf)\n",
    "* [**Gradient Boosting Classifier**](#gbc)\n",
    "* [**eXtreme Gradient Boosting Classifier**](#xgb)\n",
    "* [**AdaBoostClassifier Boosting Classifier**](#adb)\n",
    "* [**Stochastic Gradient Descent Classifier**](#sgd)\n",
    "\n",
    "### Multi-Label Classifiers\n",
    "* [**OneVsRest Classifier: Logistic Regression**](#oc_lr)\n",
    "* [**OneVsRest Classifier: Multinomial Naive Bayes**](#oc_mn)\n",
    "* [**MultiOutput Classifier: Logistic Regression**](#mo_lr)\n",
    "* [**MultiOutput Classifier: Multinomial Naive Bayes**](#mo_mn)\n",
    "* [**Binary Relevance: Logistic Regression**](#br_lr)\n",
    "* [**Binary Relevance: Multinomial Naive Bayes**](#br_mn)\n",
    "* [**Classifier Chain: Multinomial Naive Bayes**](#cc_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "### Declaring Helper Functions <a class=\"anchor\" id=\"functs\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "Helper functions that would be repeatedly used throughout the notebook, will be declared and discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef25ee5",
   "metadata": {},
   "source": [
    "#### Submission Template Functions\n",
    "The following `to_submission_csv` functions are used to create CSV files with the correct submission template. The first function is used by almost all models, while a modified version is used for the MultiOutput Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv(predictions, filename):\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv_multiclass(predictions, filename):\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0ecfe",
   "metadata": {},
   "source": [
    "#### Training and Tuning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65432a0a",
   "metadata": {},
   "source": [
    "As the task requires us to give predictions for six classes, the `train_models` function would train multiple classifiers that will give predictions for a given class. The function would fit each classifier using the passed train set, compute for the training accuracies for each class, then predict the classes of the passed test set.\n",
    "\n",
    "The function will return the trained models and their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecee997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model, X_train, X_test):\n",
    "    \"\"\"Trains six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    test_predictions = np.zeros((len(test), len(classes)))                  # initialize empty list for predictions\n",
    "    models = []                                                             # initialize empty list for models\n",
    "    \n",
    "    print('Fitting', str(model) + '...')\n",
    "    \n",
    "    for i in range(6):                                                      # loop for each of six classes\n",
    "        model.fit(X_train, y_train[classes[i]])                             # fit the model\n",
    "        \n",
    "        train_predictions = model.predict(X_train)                          # predict using train data\n",
    "        accuracy = accuracy_score(train_predictions, y_train[classes[i]])   # get training accuracy \n",
    "        print(classes[i] + ':', accuracy)\n",
    "        \n",
    "        test_predictions[:,i] = model.predict_proba(X_test)[:,1]            # predict using test data\n",
    "        \n",
    "        models += [model]\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54662d22",
   "metadata": {},
   "source": [
    "Similarly, the `tune_and_train_models` function will train multiple classifiers with the addition of hyperparameter tuning to achieve a better training accuracy. Hyperparameter tuning will be manually done using a `ParameterGrid` as using other model selection techniques such as `GridSearchCV` and `RandomizedCV` will be more time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec21a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_models(model, hyperparameters, X_train, X_test, scoring='accuracy'):\n",
    "    \"\"\"Tunes six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    hyperparameters : estimator object\n",
    "        the hyperparameters used for tuning the model  \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    scoring : \n",
    "        the metric for deciding the best combination of parameters, either 'accuracy' or 'f1'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    test_predictions = np.zeros((len(test), len(classes)))                  # initialize empty list for predictions\n",
    "    models = []                                                             # initialize empty list for models\n",
    "    \n",
    "    print('Tuning', str(model) + '...')\n",
    "    \n",
    "    for i in range(6):                                                          # loop for each of six classes\n",
    "        best_score = 0                                                          # initialize best score per class\n",
    "\n",
    "        for g in ParameterGrid(hyperparameters):                                # loop for each combination of hyperparameters\n",
    "            model.set_params(**g)\n",
    "            model.fit(X_train, y_train[classes[i]])                             # fit the model\n",
    "            train_predictions = model.predict(X_train)                          # predict using train data\n",
    "            \n",
    "            if scoring == 'accuracy':                                           # compute the model's score using\n",
    "                score = accuracy_score(train_predictions, y_train[classes[i]])  # accuracy or...\n",
    "            else: \n",
    "                score = f1_score(train_predictions, y_train[classes[i]])        # ...f1 score\n",
    "            \n",
    "            if score > best_score:                                              # if the current model has the highest score,\n",
    "                best_score = score                                              # update the best score,\n",
    "                best_grid = g                                                   # update the best parameter combination, and\n",
    "                best_model = model                                              # save the best fitted model\n",
    "        \n",
    "        print(classes[i] + ':', best_score)\n",
    "        print('Best parameters:', best_grid)\n",
    "        \n",
    "        test_predictions[:,i] = best_model.predict_proba(X_test)[:,1]           # predict with the best model using test data\n",
    "        \n",
    "        models += [best_model]\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a521b",
   "metadata": {},
   "source": [
    "Multi-label classifiers would follow the same pipeline of training the model, getting the training predictions, and predicting the classes of the test data. As such, the `train_model` and `tune_and_train_model` functions will forgo the loop and proceed to train and/or tune the model using the whole **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, X_test, dense=False):\n",
    "    \"\"\"Trains a model using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    dense : \n",
    "        a boolean value indicating if the predictions need to be converted to dense\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        a fitted estimator object\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Fitting', str(model) + '...')\n",
    "    \n",
    "    model.fit(X_train, y_train)                                               # fit the model\n",
    "    train_predictions = model.predict(X_train)                                # predict using train data\n",
    "    \n",
    "    if dense:                                           \n",
    "        train_predictions = train_predictions.to_dense()                      # convert predictions to dense\n",
    "        \n",
    "    accuracy = np.sum(train_predictions==y_train) / len(train_predictions)    # get training accuracy \n",
    "    print(accuracy)                                                        \n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)                            # predict using test data\n",
    "    \n",
    "    return model, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea53f9",
   "metadata": {},
   "source": [
    "As with the previous functions, the `tune_and_train_model` function will tune a single multi-label classifier using a `ParameterGrid` to increase the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677549cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_model(model, hyperparameters, X_train, X_test, scoring='accuracy', dense=False):\n",
    "    \"\"\"Tunes six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    hyperparameters : estimator object\n",
    "        the hyperparameters used for tuning the model  \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    scoring : \n",
    "        the metric for deciding the best combination of parameters, either 'accuracy' or 'f1'\n",
    "    dense : \n",
    "        a boolean value indicating if the predictions need to be converted to dense\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Tuning', str(model) + '...')\n",
    "    \n",
    "    best_score = 0\n",
    "\n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "        model.set_params(**g)\n",
    "        model.fit(X_train, y_train)                                         # fit the model\n",
    "        train_predictions = model.predict(X_train)                          # predict using train data\n",
    "\n",
    "        if dense:\n",
    "            train_predictions = train_predictions.to_dense()                # convert predictions to dense\n",
    "        \n",
    "        if scoring == 'accuracy':                                           # compute the model's score using\n",
    "            score = accuracy_score(train_predictions, y_train)              # accuracy or...\n",
    "        else: \n",
    "            score = f1_score(train_predictions, y_train)                    # ...f1 score\n",
    "\n",
    "        if score > best_score:                                              # if the current model has the highest score,\n",
    "            best_score = score                                              # update the best score,\n",
    "            best_grid = g                                                   # update the best parameter combination, and\n",
    "            best_model = model                                              # save the best fitted model\n",
    "\n",
    "    print(best_score)\n",
    "    print('Best parameters:', best_grid)\n",
    "    test_predictions = best_model.predict_proba(X_test)                     # predict using test data\n",
    "\n",
    "    return model, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": [
    "### Declaring Hyperparameter Values <a class=\"anchor\" id=\"params\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "As hyperparameters for each base estimator will remain constant, these will be declared here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e83d3",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameters <a class=\"anchor\" id=\"param_lr\"></a>\n",
    "Tuning Logistic Regression models mostly involve altering the C, which controls the regularization strength, and the maximum number of iterations. \n",
    "\n",
    "For the C value, different powers of the default value (1) were tested to see if a stronger or weaker regularization strength can affect the results.\n",
    "\n",
    "During earlier testing stages, it was determined that the default number of max iterations (100) resulted in a ConvergenceWarning. With this, higher values were considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [{\n",
    "    'C' : [0.01, 0.1, 1, 10],\n",
    "    'max_iter' : [300, 600, 900, 1200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce74e5",
   "metadata": {},
   "source": [
    "As the OneVsRest Classifier and MultiOutput Classifier require a slightly altered format, this was declared as a different variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [{\n",
    "    'estimator__C': [0.01, 0.1, 1, 10],            # [1, 12, 15]\n",
    "    'estimator__max_iter': [300, 600, 900, 1200],  # [600, 1800, 3000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf27334",
   "metadata": {},
   "source": [
    "The Binary Relevance classifier also requires its own separate format, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_multi = [{\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],            # [1, 12, 15]\n",
    "    'classifier__max_iter': [300, 600, 900, 1200]   # [600, 1800, 3000],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95e23d",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Hyperparameters <a class=\"anchor\" id=\"param_mnb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f4323",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_mo = [{\n",
    "    'estimator__alpha': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],   # [0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "    'estimator__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e10be",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_multi = [{\n",
    "    'classifier': [MultinomialNB()],\n",
    "    'classifier__alpha': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],   # [0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "    'classifier__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf8952",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Hyperparameters <a class=\"anchor\" id=\"param_rf\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865abbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = [{\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 20, 30],\n",
    "    'min_samples_split' : [2, 4, 6, 10, 15, 20],\n",
    "    'max_leaf_nodes' : [3, 5, 10, 20, 50, 100],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7f119",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier Hyperparameters <a class=\"anchor\" id=\"param_gbc\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gbc = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7abec",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier Hyperparameters <a class=\"anchor\" id=\"param_xgb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgb = [{\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3753a8",
   "metadata": {},
   "source": [
    "#### Adaboost Classifier Hyperparameters <a class=\"anchor\" id=\"param_adb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_adb = {\n",
    "    'n_estimators' : [10, 25, 50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fcd8d",
   "metadata": {},
   "source": [
    "#### SGDClassifier Hyperparameters <a class=\"anchor\" id=\"param_sgd\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d29c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sgd = [{\n",
    "    'loss' : ['log', 'modified_huber'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8fd80",
   "metadata": {},
   "source": [
    "## Model Experimentation\n",
    "It should be noted that all models used below will have these constant values for parameters, if applicable:\n",
    "* `n_jobs = -1`, which would ensure that all CPU cores will be used for faster processing,\n",
    "* `class_weight='balanced'`, which would <TODO>, and\n",
    "* `random_state=8`, which would ensure that the output can be reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d6f2",
   "metadata": {},
   "source": [
    "### Logistic Regression <a class=\"anchor\" id=\"lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: baket ito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db2b05",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `LogisticRegression()` object is first initialized to be used as the base classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51162851",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50fb32",
   "metadata": {},
   "source": [
    "The model is then trained using the count vectorized train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aad487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_models_count, predictions_lr_count = train_models(lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b4983",
   "metadata": {},
   "source": [
    "TODO: comments on ^^\n",
    "\n",
    "Next, the model will be trained using the TF-IDF vectorized data as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d587df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_models_tfidf, predictions_lr_tfidf = train_models(lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb2a8f",
   "metadata": {},
   "source": [
    "TODO: comments on ^^\n",
    "\n",
    "Lastly, the Word2Vec vectorized data will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ece5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_models_wrd2v, predictions_lr_wrd2v = train_models(lr, wrd2v_train, wrd2v_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848172e5",
   "metadata": {},
   "source": [
    "From the three outputs shown above, it should be noted that TODO.\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count, 'submission_lr_count')\n",
    "to_submission_csv(predictions_lr_tfidf, 'submission_lr_tfidf')\n",
    "to_submission_csv(predictions_lr_wrd2v, 'submission_lr_wrd2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085e4eb",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c974dc",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count</td>\n",
    "    <td class=\"tg-baqh\">0.93926</td>\n",
    "    <td class=\"tg-baqh\">0.94248</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97391</td>\n",
    "    <td class=\"tg-baqh\">0.97376</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebed0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "A `LogisticRegression()` object with default parameters will serve as the base estimator, which will be tuned using the [`parameters_lr`](#param_lr) hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_count_tuned, predictions_lr_count_tuned = tune_and_train_models(lr, parameters_lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_tfidf_tuned, predictions_lr_tfidf_tuned = tune_and_train_models(lr, parameters_lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_wrd2v_tuned, predictions_lr_wrd2v_tuned = tune_and_train_models(lr, parameters_lr, wrd2v_train, wrd2v_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd15659",
   "metadata": {},
   "source": [
    "It can be seen above that count vectors had higher training accuracy scores for **toxic**, **severe_toxic**, **obscene**, **threat**, and **identity_hate**, while TODO: kasi irurun ulet to\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b88577",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count_tuned, 'submission_lr_count_tuned')\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79b557",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448f00b",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94016</td>\n",
    "    <td class=\"tg-baqh\">0.94392</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.97135</td>\n",
    "    <td class=\"tg-baqh\">0.97227</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5546",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes <a class=\"anchor\" id=\"mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9afeb",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `MultinomialNB()` object with default parameters is initialized to serve as the base classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda10b24",
   "metadata": {},
   "source": [
    "The model will first be trained using the count vectorized train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mn_models_count, predictions_mn_count = train_models(mn, count_train, count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0823d",
   "metadata": {},
   "source": [
    "TODO: comments on ^^\n",
    "\n",
    "Then, the model will be trained using the TF-IDF vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mn_models_tfidf, predictions_mn_tfidf = train_models(mn, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13685eb4",
   "metadata": {},
   "source": [
    "As seen from the output above, the models trained with count vectorized data performed better when predicting **toxic**, **obscene**, and **insult** classes, while TF-IDF vectorized data performed better for **severe_toxic**, **threat**, and **identity_hate** classes.\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_count, 'submission_mn_count')\n",
    "to_submission_csv(predictions_mn_tfidf, 'submission_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b7679",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, \n",
    "\n",
    "# TODO: yuck ang baba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaedef",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count</td>\n",
    "    <td class=\"tg-baqh\">0.84551</td>\n",
    "    <td class=\"tg-baqh\">0.85581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.82510</td>\n",
    "    <td class=\"tg-baqh\">0.83586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdb55a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "A `MultinomialNB()` object with default parameters is declared for use as the base estimator, to be tuned by the defined [`parameters_mnb`](#param_mn) hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "2ee76844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MultinomialNB()...\n",
      "toxic: 0.9661968653452069\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "severe_toxic: 0.9901736531073942\n",
      "Best parameters: {'alpha': 10, 'fit_prior': True}\n",
      "obscene: 0.9771512367535454\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "threat: 0.9970044682304429\n",
      "Best parameters: {'alpha': 1000, 'fit_prior': True}\n",
      "insult: 0.9749202549335405\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "identity_hate: 0.9912515432002056\n",
      "Best parameters: {'alpha': 100, 'fit_prior': True}\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn = MultinomialNB()\n",
    "mn_models_count_tuned, predictions_mn_count_tuned = tune_and_train_models(mn, parameters_mnb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ecf109d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MultinomialNB()...\n",
      "toxic: 0.975828941348992\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "severe_toxic: 0.9947421523961121\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "obscene: 0.9867457119401395\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "threat: 0.9987403726240983\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "insult: 0.9846651333888989\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "identity_hate: 0.9958889773204405\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn = MultinomialNB()\n",
    "mn_models_tfidf_tuned, predictions_mn_tfidf_tuned = tune_and_train_models(mn, parameters_mnb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e9017ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_count_tuned, 'submission_mn_count_tuned')\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3ce89",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90205</td>\n",
    "    <td class=\"tg-baqh\">0.90411</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90610</td>\n",
    "    <td class=\"tg-baqh\">0.90995</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b957",
   "metadata": {},
   "source": [
    "### RandomForestClassifier <a class=\"anchor\" id=\"rf\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f95b7",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `RandomForestClassifier()` object with default parameters is initialized before it is passed to the `train_models()` function. A classifier for each of the six classes for each vectorizer will be trained using this object as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ca166526",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "109a6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n",
      "toxic: 0.999793195505449\n",
      "severe_toxic: 0.9998245295197749\n",
      "obscene: 0.99983079632264\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-273-88db98ea23ed>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# get training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mtest_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m     \u001b[1;31m# predict using test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mmodels\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    681\u001b[0m                      for j in np.atleast_1d(self.n_classes_)]\n\u001b[0;32m    682\u001b[0m         \u001b[0mlock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         Parallel(n_jobs=n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    684\u001b[0m                  \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequire\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sharedmem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_count, predictions_rf_count = train_models(rf, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a44162ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-273-88db98ea23ed>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fitting'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                            \u001b[1;31m# loop for each of six classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                       \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# get training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_tfidf, predictions_rf_tfidf = train_models(rf, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "9bc8682b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrd2v_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wrd2v_train' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_wrd2v, predictions_rf_wrd2v = train_models(rf, wrd2v_train, wrd2v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0aa6ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')\n",
    "to_submission_csv(predictions_rf_wrd2v, 'submission_rf_wrd2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adbfa9",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count</td>\n",
    "    <td class=\"tg-baqh\">0.94071</td>\n",
    "    <td class=\"tg-baqh\">0.94602</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.93731</td>\n",
    "    <td class=\"tg-baqh\">0.93999</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd252b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f77194",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)\n",
    "rf_models_count_tuned, predictions_rf_count_tuned = tune_and_train_models(rf, parameters_rf, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)\n",
    "rf_models_tfidf_tuned, predictions_rf_tfidf_tuned = tune_and_train_models(rf, parameters_rf, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dabb22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6a8aa",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.96232</td>\n",
    "    <td class=\"tg-baqh\">0.96285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.95937</td>\n",
    "    <td class=\"tg-baqh\">0.95826</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6d61c",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier <a class=\"anchor\" id=\"gbc\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1686af7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b74c9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ffc659fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GradientBoostingClassifier(random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-273-88db98ea23ed>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fitting'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                            \u001b[1;31m# loop for each of six classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                       \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# get training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbc_models_count, predictions_gbc_count = train_models(gbc, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "36ca0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GradientBoostingClassifier(random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-273-88db98ea23ed>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fitting'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                            \u001b[1;31m# loop for each of six classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                       \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# get training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.TreeBuilder._check_input\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mtocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         csr_tocsc(self.shape[0], self.shape[1],\n\u001b[0m\u001b[0;32m    183\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbc_models_tfidf, predictions_gbc_tfidf = train_models(gbc, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83bea7",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ade6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_count_tuned, predictions_gbc_count_tuned = tune_and_train_models(gbc, parameters_gbc, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_tfidf_tuned, predictions_gbc_tfidf_tuned = tune_and_train_models(gbc, parameters_gbc, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count_tuned, 'submission_gbc_count_tuned')\n",
    "to_submission_csv(predictions_gbc_tfidf_tuned, 'submission_gbc_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f4fd",
   "metadata": {},
   "source": [
    "### XGBClassifier <a class=\"anchor\" id=\"xgb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250de73",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_models_count, predictions_xgb_count = train_models(xgb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2260e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_models_tfidf, predictions_xgb_tfidf = train_models(xgb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count, 'submission_xgb_count')\n",
    "to_submission_csv(predictions_xgb_tfidf, 'submission_xgb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfec96",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>private</th>\n",
    "    <th>public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>submission_xgb_count</td>\n",
    "    <td>0.96468</td>\n",
    "    <td>0.96783</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>submission_xgb_tfidf</td>\n",
    "    <td>0.96502</td>\n",
    "    <td>0.96803</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfee743",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_count_tuned, predictions_xgb_count_tuned = tune_and_train_models(xgb, parameters_xgb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_tfidf_tuned, predictions_xgb_tfidf_tuned = tune_and_train_models(xgb, parameters_xgb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ad09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea054",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier <a class=\"anchor\" id=\"adb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db3139",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0253f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb_models_count, predictions_adb_count = train_models(adb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb_models_tfidf, predictions_adb_tfidf = train_models(adb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85403f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_count_tuned, predictions_adb_count_tuned = tune_and_train_models(adb, parameters_adb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a51c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba60206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_tfidf_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb, parameters_adb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_tuned = GridSearchCV(AdaBoostClassifier(random_state=8), parameters_adb, scoring='accuracy', cv=cv)\n",
    "adb_models_count_tuned, adb_models_tfidf_tuned, \\\n",
    "    predictions_adb_count_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803b2a5",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier <a class=\"anchor\" id=\"sgd\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9981549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b3421",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_models_count, predictions_sgd_count = train_models(sgd, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf693ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_models_tfidf, predictions_sgd_tfidf = train_models(sgd, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7309b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count, 'submission_sgd_count')\n",
    "to_submission_csv(predictions_sgd_tfidf, 'submission_sgd_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30717932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 0.9740930369553364\n",
      "TF-IDF Vectors: 0.9546032800446196\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 0.9773141736280402\n",
      "TF-IDF Vectors: 0.9773705748538268\n",
      "Fitting obscene...\n",
      "Count Vectors: 0.9366551566387377\n",
      "TF-IDF Vectors: 0.9798020943655176\n",
      "Fitting threat...\n",
      "Count Vectors: 0.9831673675041204\n",
      "TF-IDF Vectors: 0.9951808285966748\n",
      "Fitting insult...\n",
      "Count Vectors: 0.8818895663999098\n",
      "TF-IDF Vectors: 0.9667295435887473\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 0.961321292716095\n",
      "TF-IDF Vectors: 0.9792819497277074\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count, sgd_models_tfidf, predictions_sgd_count, predictions_sgd_tfidf = train_models(sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10cdff",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count</td>\n",
    "    <td class=\"tg-baqh\">0.68992</td>\n",
    "    <td class=\"tg-baqh\">0.70589</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97214</td>\n",
    "    <td class=\"tg-baqh\">0.97625</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd2aa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count_tuned, predictions_sgd_count_tuned = tune_and_train_models(sgd, parameters_sgd, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f763d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_tfidf_tuned, predictions_sgd_tfidf_tuned = tune_and_train_models(sgd, parameters_sgd, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count_tuned, 'submission_sgd_count_tuned')\n",
    "to_submission_csv(predictions_sgd_tfidf_tuned, 'submission_sgd_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b66f8",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.81387</td>\n",
    "    <td class=\"tg-baqh\">0.81848</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94660</td>\n",
    "    <td class=\"tg-baqh\">0.95230</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Logistic Regression <a class=\"anchor\" id=\"oc_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571180e0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "1792e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_lr = OneVsRestClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "512f4a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
      "                                                 n_jobs=-1),\n",
      "                    n_jobs=-1)...\n",
      "toxic            96.168477\n",
      "severe_toxic     97.565347\n",
      "obscene          97.446278\n",
      "threat           99.629632\n",
      "insult           96.154690\n",
      "identity_hate    97.698203\n",
      "dtype: float64\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_lr_model_count, predictions_oc_lr_count = train_model(oc_lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c374406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
      "                                                 n_jobs=-1),\n",
      "                    n_jobs=-1)...\n",
      "toxic            95.742334\n",
      "severe_toxic     97.942609\n",
      "obscene          98.074211\n",
      "threat           99.375200\n",
      "insult           96.810197\n",
      "identity_hate    98.102412\n",
      "dtype: float64\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_lr_model_tfidf, predictions_oc_lr_tfidf = train_model(oc_lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_lr_count, 'submission_oc_lr_count')\n",
    "to_submission_csv_multiclass(predictions_oc_lr_tfidf, 'submission_oc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a00c0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "50f1cd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
      "                                                 n_jobs=-1))...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-326-61e18f2d1f7b>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model, hyperparameters, X_train, X_test, scoring)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[0;32m    282\u001b[0m             self.estimator, X, column, classes=[\n\u001b[0;32m    283\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1407\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_lr = OneVsRestClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "oc_lr_model_count_tuned, predictions_oc_lr_count_tuned = tune_and_train_models(oc_lr, parameters_lr_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "859bb689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
      "                                                 n_jobs=-1))...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-326-61e18f2d1f7b>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model, hyperparameters, X_train, X_test, scoring)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[0;32m    282\u001b[0m             self.estimator, X, column, classes=[\n\u001b[0;32m    283\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1407\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1062\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickle_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;31m# calls, but cleanup the temporary resources that the Parallel call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;31m# created. This 'hack' requires a private, low-level operation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m             self._workers._temp_folder_manager._unlink_temporary_resources(\n\u001b[0m\u001b[0;32m    552\u001b[0m                 \u001b[0mcontext_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m_unlink_temporary_resources\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    625\u001b[0m                         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m                     )\n\u001b[1;32m--> 627\u001b[1;33m                 self._try_delete_folder(\n\u001b[0m\u001b[0;32m    628\u001b[0m                     \u001b[0mallow_non_empty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m_try_delete_folder\u001b[1;34m(self, allow_non_empty, context_id)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[0mtemp_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_temp_folders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m                 delete_folder(\n\u001b[0m\u001b[0;32m    655\u001b[0m                     \u001b[0mtemp_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_non_empty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_non_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\disk.py\u001b[0m in \u001b[0;36mdelete_folder\u001b[1;34m(folder_path, onerror, allow_non_empty)\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[1;31m# yet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRM_SUBDIRS_RETRY_TIME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_lr = OneVsRestClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "oc_lr_model_tfidf_tuned, predictions_oc_lr_tfidf_tuned = tune_and_train_models(oc_lr, parameters_lr_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_lr_count_tuned, 'submission_oc_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_oc_lr_tfidf_tuned, 'submission_oc_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7f230",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"oc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ac935",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "48168411",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_mn = OneVsRestClassifier(MultinomialNB(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "11375a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OneVsRestClassifier(estimator=MultinomialNB(), n_jobs=-1)...\n",
      "toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_mn_model_count, predictions_oc_mn_count = train_model(oc_mn, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "4c26be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OneVsRestClassifier(estimator=MultinomialNB(), n_jobs=-1)...\n",
      "toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_mn_model_tfidf, predictions_oc_mn_tfidf = train_model(oc_mn, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_mn_count, 'submission_oc_mn_count')\n",
    "to_submission_csv_multiclass(predictions_oc_mn_tfidf, 'submission_oc_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de286172",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn = OneVsRestClassifier(MultinomialNB(), n_jobs=-1)\n",
    "oc_mn_model_count_tuned, predictions_oc_mn_count_tuned = tune_and_train_models(oc_mn, parameters_mn_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn = OneVsRestClassifier(MultinomialNB(), n_jobs=-1)\n",
    "oc_mn_model_tfidf_tuned, predictions_oc_mn_tfidf_tuned = tune_and_train_models(oc_mn, parameters_mn_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592607c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_oc_mn_count_tuned, 'submission_oc_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_oc_mn_tfidf_tuned, 'submission_oc_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec9910",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression <a class=\"anchor\" id=\"mo_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ea998",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f42e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr_model_count, predictions_mo_lr_count = train_model(mo_lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr_model_tfidf, predictions_mo_lr_tfidf = train_model(mo_lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab55861",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6871d",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "mo_lr_model_count_tuned, predictions_mo_lr_count_tuned = tune_and_train_models(mo_lr, parameters_lr_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b478ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "mo_lr_model_tfidf_tuned, predictions_mo_lr_tfidf_tuned = tune_and_train_models(mo_lr, parameters_lr_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count_tuned, 'submission_mo_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf_tuned, 'submission_mo_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b03d3a",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"mo_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4b87",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e23e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn_model_count, predictions_mo_mn_count = train_model(mo_mn, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b299333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn_model_tfidf, predictions_mo_mn_tfidf = train_model(mo_mn, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353eeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fd6d2",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)\n",
    "mo_mn_model_count_tuned, predictions_mo_mn_count_tuned = tune_and_train_models(mo_mn, parameters_mn_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39801076",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)\n",
    "mo_mn_model_tfidf_tuned, predictions_mo_mn_tfidf_tuned = tune_and_train_models(mo_mn, parameters_mn_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60da467",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_mn_count_tuned, 'submission_mo_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_mo_mn_tfidf_tuned, 'submission_mo_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263f499",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression <a class=\"anchor\" id=\"br_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd6c45",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5afdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr = BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr_model_count, predictions_br_lr_count = train_model(br_lr, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr_model_tfidf, predictions_br_lr_tfidf = train_model(br_lr, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cbbec",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d563842",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr br_mn= BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "br_lr_model_count_tuned, predictions_br_lr_count_tuned = \\\n",
    "    tune_and_train_models(br_lr, parameters_lr_multi, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405131e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr = BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "br_lr_model_tfidf_tuned, predictions_br_lr_tfidf_tuned = \\\n",
    "    tune_and_train_models(br_lr, parameters_lr_multi, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80960d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count_tuned, 'submission_br_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf_tuned, 'submission_br_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839855c4",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes <a class=\"anchor\" id=\"br_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a0e79",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_mn = BinaryRelevance(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f24fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn_model_count, predictions_br_mn_count = train_model(br_mn, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn_model_tfidf, predictions_br_mn_tfidf = train_model(br_mn, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e95ce6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn = BinaryRelevance(MultinomialNB())\n",
    "br_mn_model_count_tuned, predictions_br_mn_count_tuned = \\\n",
    "    tune_and_train_models(br_mn, parameters_mn_multi, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn = BinaryRelevance(MultinomialNB())\n",
    "br_mn_model_tfidf_tuned, predictions_br_mn_tfidf_tuned = \\\n",
    "    tune_and_train_models(br_mn, parameters_mn_multi, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565699ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_mn_count_tuned, 'submission_br_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_br_mn_tfidf_tuned, 'submission_br_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cece5e",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes <a class=\"anchor\" id=\"cc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc05d4a",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mn = ClassifierChain(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9bbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn_model_count, predictions_cc_mn_count = train_model(cc_mn, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn_model_tfidf, predictions_cc_mn_tfidf = train_model(cc_mn, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd707690",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_cc_lr_count, 'submission_cc_lr_count')\n",
    "to_submission_csv_multiclass(predictions_cc_lr_tfidf, 'submission_cc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1806f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313895bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn = ClassifierChain(MultinomialNB(), random_state=8)\n",
    "cc_mn_model_count_tuned, predictions_cc_mn_count_tuned = \\\n",
    "    tune_and_train_models(cc_mn, parameters_mn_multi, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd02f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn = ClassifierChain(MultinomialNB(), random_state=8)\n",
    "cc_mn_model_tfidf_tuned, predictions_cc_mn_tfidf_tuned = \\\n",
    "    tune_and_train_models(cc_mn, parameters_mn_multi, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66083052",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_cc_mn_count_tuned, 'submission_cc_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_cc_mn_tfidf_tuned, 'submission_cc_mn_tfidf_tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
