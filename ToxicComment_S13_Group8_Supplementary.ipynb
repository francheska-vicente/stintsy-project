{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "#### Basic Libraries \n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations\n",
    "- `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features \n",
    "- `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce303532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries\n",
    "The following code block can be used to install **scikit-multilearn** without restarting Jupyter Notebook. The `sys` module is used to access the *executable* function of the interpreter, which would run the installation of scikit-multilearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850d2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a154c",
   "metadata": {},
   "source": [
    "The following libraries are multi-label classification modules that would allow the usage of one model that can classify one instance as more than one class.\n",
    "- `ClassifierChain` chains binary classifiers in a way that its predictions are dependent on the earlier classes\n",
    "- `BinaryRelevance` uses binary classifiers to classify the classes independently\n",
    "- `MultiOutputClassifier` fits one classifier per target class \n",
    "- `OneVsRestClassifier` fits one class against the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea567ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7f3",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "- `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees\n",
    "- `GradientBoostingClassifier` is a class under the ensemble module that optimizes arbitrary differentiable loss functions\n",
    "- `AdaBoostClassifier` is a class under the ensemble module that implements AdaBoost-SAMME\n",
    "- `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "- `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "- `SGDClassifier` is a class under the linear models module that implements regularized linear models with stochastic gradient descent (SGD) learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e6642",
   "metadata": {},
   "source": [
    "Meanwhile, the following classes are used for hyperparameter tuning.\n",
    "- `ParameterGrid` is a class that allows the iteration over different combinations of parameter values \n",
    "- `GridSearchCV` is a cross-validation class that allows the exhaustive search over all possible combinations of hyperparameter values\n",
    "- `RandomizedSearchCV` is a cross-validation class that allows a random search over some possible combinations of hyperparameter values\n",
    "- `train_test_split` divides the dataset into two subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f9c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c58b7bb",
   "metadata": {},
   "source": [
    "And lastly, these classes computes different scores about how well a model works.\n",
    "- `log_loss` computes the Logistic loss given the true values and the predicted values\n",
    "- `f1_score` computes the balanced F-score by comparing the actual classes and the predicted classes\n",
    "- `accuracy_score` computes the accuracy by determining how many classes were correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6edede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878a641",
   "metadata": {},
   "source": [
    "The warnings module is used to ignore any ConvergenceWarnings that might appear when doing hyperparameter tuning. As these models will not be chosen due to low accuracy scores, the warnings would only clutter the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Load Files\n",
    "The csv files to be loaded here contains the datasets that have already gone through the data cleaning and preprocessing techniques discussed in the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe1ca0f",
   "metadata": {},
   "source": [
    "## Initialize Datasets\n",
    "Before using these datasets, we would need to convert the values in the `comment_text` column into either \"str, unicode or file objects\", according to the documentation of TF-IDF vectorizer and Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7c6cd",
   "metadata": {},
   "source": [
    "Then, we would be declaring our **X_train**, **y_train**, and **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed343812",
   "metadata": {},
   "source": [
    "Afterwards, we would be declaring the different classes that our model would need to predict. This can be found in the **train** data's column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "## Vectorizing Data\n",
    "As explained in the **Feature Engineering** part of the main notebook, three types of vectorizers would be used: (1) Count Vectorizer, (2) TF-IDF Vectorizer, and (3) Average Word2Vec Vectors.\n",
    "\n",
    "Two types of CountVectorizer and TF-IDF Vectorizers were made in consideration of the more complex estimators: one with no **max_features** parameter, and one with a **max_features** parameter that is equal to 5000. Limiting the number of max features would lessen the time and space complexity from training the estimators; this would lessen the burden on our machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18f9b5",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6d1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()                     # creating the Vectorizer with no max features\n",
    "count_train = count_vectorizer.fit_transform(X_train)    # fitting the vectorizer according to the train data, and then\n",
    "                                                         # returning the transformed train data\n",
    "count_test = count_vectorizer.transform(X_test)          # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_5000 = CountVectorizer(max_features = 5000)     # creating the Vectorizer with max features = 5000\n",
    "count_train_5000 = count_vectorizer_5000.fit_transform(X_train)  # fitting the vectorizer according to the train data, and then\n",
    "                                                                 # returning the transformed train data\n",
    "count_test_5000 = count_vectorizer_5000.transform(X_test)        # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec4160",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60850d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()                    # creating the Vectorizer with no max features\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)   # fitting the vectorizer according to the train data, and then\n",
    "                                                        # returning the transformed train data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)         # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_5000 = TfidfVectorizer(max_features = 5000)    # creating the Vectorizer with max features = 5000\n",
    "tfidf_train_5000 = tfidf_vectorizer_5000.fit_transform(X_train) # fitting the vectorizer according to the train data, and then\n",
    "                                                                # returning the transformed train data\n",
    "tfidf_test_5000 = tfidf_vectorizer_5000.transform(X_test)       # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c4764",
   "metadata": {},
   "source": [
    "#### Average Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950da36",
   "metadata": {},
   "source": [
    "Before building a Word2Vec model, the data must be tokenized to produce a list of lists of tokens as indicated in Gensim's documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f71ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    t = TweetTokenizer()\n",
    "\n",
    "    tokens_list = []\n",
    "    for text in data:\n",
    "        tokens_list += [t.tokenize(text)]\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c1d86",
   "metadata": {},
   "source": [
    "The train set is tokenized using NLTK's `TweetTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea16997",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenize(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe399a",
   "metadata": {},
   "source": [
    "The Word2Vec model is trained using this tokenized list, which would transform these words into word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f01854a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd2v_model = Word2Vec(tokens_train, epochs=30, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184bc491",
   "metadata": {},
   "source": [
    "To transform the word vectors into usable features, these vectors are averaged for all words in the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fe9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_word2vec(model, tokens_list):\n",
    "    vectors = []\n",
    "    \n",
    "    for tokens in tokens_list:                    # iterate through each sentence\n",
    "        feat = np.zeros(100)                      # initializes a list that will hold the vectors\n",
    "        count = 0                                 # initializes the word count for a sentence\n",
    "        \n",
    "        for token in tokens:                      # iterate through each word in the sentence\n",
    "            if token in model.wv.index_to_key:    # if the word is in the model's vocabulary...\n",
    "                feat += model.wv[token]           # ...add word vectors to list and...\n",
    "                count += 1                        # ...update the word count\n",
    "        \n",
    "        if count > 1:                             # if sentence contains more than 1 word in the model...\n",
    "            feat /= count                         # ...divide word vectors by word count to get the average\n",
    "            \n",
    "        vectors.append(feat)                      # add the averaged vectors to the list\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db608a01",
   "metadata": {},
   "source": [
    "Using the defined function, the train data can be vectorized using the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d6de79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrd2v_train = vectorize_word2vec(wrd2v_model, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ec1c2",
   "metadata": {},
   "source": [
    "The test data is also vectorized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f63f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = tokenize(X_test)\n",
    "wrd2v_test = vectorize_word2vec(wrd2v_model, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac6bbd",
   "metadata": {},
   "source": [
    "## Training and Tuning Different Models <a class=\"anchor\" id=\"toc\"></a>\n",
    "TODO: i ken fly\n",
    "\n",
    "#### Variable and Function Declarations\n",
    "* [**Helper Functions**](#functs)\n",
    "* [**Hyperparameters**](#params)\n",
    "\n",
    "### Six Single-Label Classifiers\n",
    "* [**Logistic Regression**](#lr)\n",
    "* [**Multinomial Naive Bayes**](#mn)\n",
    "* [**Random Forest Classifier**](#rf)\n",
    "* [**Gradient Boosting Classifier**](#gbc)\n",
    "* [**eXtreme Gradient Boosting Classifier**](#xgb)\n",
    "* [**AdaBoostClassifier Boosting Classifier**](#adb)\n",
    "* [**Stochastic Gradient Descent Classifier**](#sgd)\n",
    "\n",
    "### Multi-Label Classifiers\n",
    "* [**OneVsRest Classifier: Logistic Regression**](#oc_lr)\n",
    "* [**OneVsRest Classifier: Multinomial Naive Bayes**](#oc_mn)\n",
    "* [**MultiOutput Classifier: Logistic Regression**](#mo_lr)\n",
    "* [**MultiOutput Classifier: Multinomial Naive Bayes**](#mo_mn)\n",
    "* [**Binary Relevance: Logistic Regression**](#br_lr)\n",
    "* [**Binary Relevance: Multinomial Naive Bayes**](#br_mn)\n",
    "* [**Classifier Chain: Multinomial Naive Bayes**](#cc_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "### Declaring Helper Functions <a class=\"anchor\" id=\"functs\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "Helper functions that would be repeatedly used throughout the notebook, will be declared and discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335d28c",
   "metadata": {},
   "source": [
    "#### Submission Template Functions\n",
    "The following `to_submission_csv` functions are used to create CSV files with the correct submission template. The first function is used by almost all models, while a modified version is used for the MultiOutput Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a67d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "756102fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv(predictions, filename):\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv_multiclass(predictions, filename):\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e08f7",
   "metadata": {},
   "source": [
    "#### Display Functions\n",
    "The `format_results` function is used to compute for the final test accuracy and to display the final results as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eaf9864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['model', 'vector', 'tuned', 'private', 'public', 'test accuracy']\n",
    "all_results = pd.DataFrame(index=index)\n",
    "\n",
    "def update_results(all_results, results):\n",
    "    for result in results:\n",
    "        # private score accounts for 90% of the test data, while the remaining 10% is the public score\n",
    "        results[result] += [round((results[result][3]*9 + results[result][4]) / 10, 5)]\n",
    "\n",
    "    return pd.concat([pd.DataFrame(results, index=index), all_results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9d7dc",
   "metadata": {},
   "source": [
    "#### Training and Tuning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65432a0a",
   "metadata": {},
   "source": [
    "As the task requires us to give predictions for six classes, the `train_models` function would train multiple classifiers that will give predictions for a given class. The function would fit each classifier using the passed train set, compute for the training accuracies for each class, then predict the classes of the passed test set.\n",
    "\n",
    "The function will return the trained models and their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ecee997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model, X_train, X_test):\n",
    "    \"\"\"Trains six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    test_predictions = np.zeros((len(test), len(classes)))                  # initialize empty list for predictions\n",
    "    models = []                                                             # initialize empty list for models\n",
    "    train_accuracy = []\n",
    "    \n",
    "    \n",
    "    print('Fitting', str(model) + '...')\n",
    "    \n",
    "    for i in range(6):                                                      # loop for each of six classes\n",
    "        \n",
    "        model.fit(X_train, y_train[classes[i]])                             # fit the model\n",
    "        \n",
    "        train_predictions = model.predict(X_train)                          # predict using train data\n",
    "        accuracy = accuracy_score(train_predictions, y_train[classes[i]])   # get training accuracy \n",
    "        print(classes[i] + ':', accuracy)\n",
    "        \n",
    "        test_predictions[:,i] = model.predict_proba(X_test)[:,1]            # predict using test data\n",
    "        \n",
    "        models += [model]\n",
    "        train_accuracy += [accuracy]\n",
    "    \n",
    "    print('\\nOverall training accuracy:', np.mean(train_accuracy))\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54662d22",
   "metadata": {},
   "source": [
    "Similarly, the `tune_and_train_models` function will train multiple classifiers with the addition of hyperparameter tuning to achieve a better training accuracy. Hyperparameter tuning will be done using a `GridSearchCV` for a more comprehensive search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "10da86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_models(model, hyperparameters, X_train, X_test, scoring='accuracy'):\n",
    "    \"\"\"Tunes six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    hyperparameters : estimator object\n",
    "        the hyperparameters used for tuning the model  \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    scoring : \n",
    "        the metric for deciding the best combination of parameters, either 'accuracy' or 'f1'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    test_predictions = np.zeros((len(test), len(classes)))                  # initialize empty list for predictions\n",
    "    models = []                                                             # initialize empty list for models\n",
    "    train_accuracy = []\n",
    "    \n",
    "    print('Tuning', str(model) + '...')\n",
    "    \n",
    "    for i in range(6):                                                              # loop for each of six classes\n",
    "        model_cv = GridSearchCV(model, hyperparameters, \n",
    "                                cv=[(slice(None), slice(None))], scoring=scoring)\n",
    "        model_cv.fit(X_train, y_train[classes[i]])\n",
    "        \n",
    "        train_predictions = model_cv.predict(X_train)                               # predict using train data\n",
    "        accuracy = accuracy_score(train_predictions, y_train[classes[i]])           # get training accuracy \n",
    "        print(classes[i] + ':', accuracy)\n",
    "        \n",
    "        test_predictions[:,i] = model_cv.predict_proba(X_test)[:,1]                 # predict using test data\n",
    "        \n",
    "        models += [model_cv]\n",
    "        train_accuracy += [accuracy]\n",
    "    \n",
    "    print('\\nOverall training', scoring + ':', np.mean(train_accuracy))\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a521b",
   "metadata": {},
   "source": [
    "Multi-label classifiers would follow the same pipeline of training the model, getting the training predictions, and predicting the classes of the test data. As such, the `train_model` and `tune_and_train_model` functions will forgo the loop and proceed to train and/or tune the model using the whole **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7702b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, X_test, dense=False):\n",
    "    \"\"\"Trains a model using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    dense : \n",
    "        a boolean value indicating if the predictions need to be converted to dense\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        a fitted estimator object\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Fitting', str(model) + '...')\n",
    "    \n",
    "    model.fit(X_train, y_train)                                               # fit the model\n",
    "    train_predictions = model.predict(X_train)                                # predict using train data\n",
    "    \n",
    "    if dense:                                           \n",
    "        train_predictions = train_predictions.to_dense()                      # convert predictions to dense\n",
    "        \n",
    "    accuracy = accuracy_score(train_predictions, y_train)                     # get training accuracy \n",
    "    print(accuracy)                                                        \n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)                            # predict using test data\n",
    "    \n",
    "    return model, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea53f9",
   "metadata": {},
   "source": [
    "As with the previous functions, the `tune_and_train_model` function will tune a single multi-label classifier using a `GridSearchCV` to increase the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16431e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_model(model, hyperparameters, X_train, X_test, scoring='accuracy', dense=False):\n",
    "    \"\"\"Tunes a model using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    hyperparameters : estimator object\n",
    "        the hyperparameters used for tuning the model  \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    scoring : \n",
    "        the metric for deciding the best combination of parameters, either 'accuracy' or 'f1'\n",
    "    dense : \n",
    "        a boolean value indicating if the predictions need to be converted to dense\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        a  fitted estimator object\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Tuning', str(model) + '...')\n",
    "\n",
    "    model_cv = GridSearchCV(model, hyperparameters, \n",
    "                            cv=[(slice(None), slice(None))], scoring=scoring)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "\n",
    "    train_predictions = model_cv.predict(X_train)                                # predict using train data\n",
    "    \n",
    "    if dense:                                           \n",
    "        train_predictions = train_predictions.to_dense()                         # convert predictions to dense\n",
    "        \n",
    "    accuracy = accuracy_score(train_predictions, y_train)                        # get training accuracy \n",
    "    print(accuracy)                                                        \n",
    "    \n",
    "    test_predictions = model_cv.predict_proba(X_test)                            # predict using test data\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": [
    "### Declaring Hyperparameter Values <a class=\"anchor\" id=\"params\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "As hyperparameters for each base estimator will remain constant, these will be declared here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e83d3",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameters <a class=\"anchor\" id=\"param_lr\"></a>\n",
    "Tuning Logistic Regression models mostly involve altering the C, which controls the regularization strength, and the maximum number of iterations. \n",
    "\n",
    "For the C value, different powers of the default value (1) were tested to see if a stronger or weaker regularization strength can affect the results.\n",
    "\n",
    "During earlier testing stages, it was determined that the default number of max iterations (100) resulted in a ConvergenceWarning. With this, higher values were considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c75638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [{\n",
    "    'C' : [0.01, 0.1, 1, 10],\n",
    "    'max_iter' : [300, 600, 900, 1200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce74e5",
   "metadata": {},
   "source": [
    "As the OneVsRest Classifier and MultiOutput Classifier require a slightly altered format, this was declared as a different variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "153902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [{\n",
    "    'estimator__C': [0.01, 0.1, 1, 10],           \n",
    "    'estimator__max_iter': [300, 600, 900, 1200], \n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf27334",
   "metadata": {},
   "source": [
    "The Binary Relevance classifier also requires its own separate format, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_multi = [{\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],            \n",
    "    'classifier__max_iter': [300, 600, 900, 1200] \n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95e23d",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Hyperparameters <a class=\"anchor\" id=\"param_mnb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ee4b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [{\n",
    "    'alpha' : [0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f4323",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_mo = [{\n",
    "    'estimator__alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'estimator__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e10be",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_multi = [{\n",
    "    'classifier': [MultinomialNB()],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000],  \n",
    "    'classifier__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf8952",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Hyperparameters <a class=\"anchor\" id=\"param_rf\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "865abbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = [{\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 20, 30],\n",
    "    'min_samples_split' : [2, 4, 6, 10, 15, 20],\n",
    "    'max_leaf_nodes' : [3, 5, 10, 20, 50, 100],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7f119",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier Hyperparameters <a class=\"anchor\" id=\"param_gbc\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ebe92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gbc = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7abec",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier Hyperparameters <a class=\"anchor\" id=\"param_xgb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca0f7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgb = [{\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3753a8",
   "metadata": {},
   "source": [
    "#### Adaboost Classifier Hyperparameters <a class=\"anchor\" id=\"param_adb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c28c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_adb = {\n",
    "    'n_estimators' : [10, 25, 50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fcd8d",
   "metadata": {},
   "source": [
    "#### SGDClassifier Hyperparameters <a class=\"anchor\" id=\"param_sgd\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29d29c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sgd = [{\n",
    "    'loss' : ['log', 'modified_huber'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1c1ed",
   "metadata": {},
   "source": [
    "## Model Experimentation\n",
    "It should be noted that all models used below will have these constant values for parameters, if applicable:\n",
    "* `n_jobs = -1`, which would ensure that all CPU cores will be used for faster processing,\n",
    "* `class_weight='balanced'`, which would <TODO>, and\n",
    "* `random_state=8`, which would ensure that the output can be reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d6f2",
   "metadata": {},
   "source": [
    "### Logistic Regression <a class=\"anchor\" id=\"lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: baket ito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db2b05",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `LogisticRegression()` object is first initialized to be used as the base classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "51162851",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36eb7b",
   "metadata": {},
   "source": [
    "The model is then trained using the count vectorized train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "78aad487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9616847672822756\n",
      "severe_toxic: 0.9756534708687669\n",
      "obscene: 0.9744627783243822\n",
      "threat: 0.9962963195066773\n",
      "insult: 0.9615468976192416\n",
      "identity_hate: 0.9769820330761855\n",
      "\n",
      "Overall training accuracy: 0.9744377111129215\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_models_count, predictions_lr_count = train_models(lr, count_train, count_test)\n",
    "to_submission_csv(predictions_lr_count, 'submission_lr_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908ff9e",
   "metadata": {},
   "source": [
    "The results for count vectors are quite accurate, seeing as the training accuracy rate for each class is at least 0.96.\n",
    "\n",
    "Next, the model will be trained using the TF-IDF vectorized data as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "72d587df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9574233413339517\n",
      "severe_toxic: 0.9794260861936066\n",
      "obscene: 0.9807421147952949\n",
      "threat: 0.9937519975434133\n",
      "insult: 0.9681019734162223\n",
      "identity_hate: 0.9810241209242281\n",
      "\n",
      "Overall training accuracy: 0.9767449390344529\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_models_tfidf, predictions_lr_tfidf = train_models(lr, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_lr_tfidf, 'submission_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c5fa2",
   "metadata": {},
   "source": [
    "Compared to count vectors, the use of TF-IDF vectors yielded higher training accuracy scores for **severe_toxic**, **obscene**, **insult**, and **identity_hate**. Moreover, the execution time is faster by around 9 seconds.\n",
    "\n",
    "Lastly, the Word2Vec vectorized data will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7e9ece5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.8984088587525302\n",
      "severe_toxic: 0.948117139079156\n",
      "obscene: 0.92264258543219\n",
      "threat: 0.9272236183266382\n",
      "insult: 0.9160687092266139\n",
      "identity_hate: 0.9084670773511477\n",
      "\n",
      "Overall training accuracy: 0.9201546646947126\n",
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_models_wrd2v, predictions_lr_wrd2v = train_models(lr, wrd2v_train, wrd2v_test)\n",
    "to_submission_csv(predictions_lr_wrd2v, 'submission_lr_wrd2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848172e5",
   "metadata": {},
   "source": [
    "Word2Vec vectors produced the lowest training accuracies so far, ranging from 0.89 to 0.94 only. Furthermore, training the six models took 3 minutes, which is relatively longer than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085e4eb",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TF-IDF vectors performed the best, followed by Word2Vec vectors, then count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a840402",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"submission_lr_count\": ['Logistic Regression', 'Count Vectors', 'Not Tuned', 0.94845, 0.94248],\n",
    "    \"submission_lr_tfidf\": ['Logistic Regression', 'TF-IDF Vectors', 'Not Tuned', 0.97558, 0.97621], \n",
    "    \"submission_lr_wrd2v\": ['Logistic Regression', 'Word2Vec Vectors', 'Not Tuned', 0.95233, 0.94982]\n",
    "}\n",
    "\n",
    "all_results = update_results(all_results, results)\n",
    "all_results.T.sort_values('test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bace70",
   "metadata": {},
   "source": [
    "TODO: chika abt ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebed0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "A `LogisticRegression()` object with default parameters will serve as the base estimator, which will be tuned using the [`parameters_lr`](#param_lr) hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ea6b02bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9922228976443088\n",
      "severe_toxic: 0.9934887918230756\n",
      "obscene: 0.9942972093926842\n",
      "threat: 0.999448521347864\n",
      "insult: 0.9888012232799193\n",
      "identity_hate: 0.9950554925393712\n",
      "\n",
      "Overall training accuracy: 0.9938856893378705\n",
      "Wall time: 1h 15min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_count_tuned, predictions_lr_count_tuned = tune_and_train_models(lr, parameters_lr, count_train, count_test)\n",
    "to_submission_csv(predictions_lr_count_tuned, 'submission_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363c860",
   "metadata": {},
   "source": [
    "After tuning the models that use count vectors, all training accuracies for each class have noticably increased. As these models are more regularized, this could however mean that the models may have overfitted to the train set. Also, tuning these models took around an hour and 30 minutes, which is considerably long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d9d129ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9798647623941694\n",
      "severe_toxic: 0.989340168326325\n",
      "obscene: 0.9901485858959335\n",
      "threat: 0.998145026351906\n",
      "insult: 0.9829918970238953\n",
      "identity_hate: 0.9930062480024566\n",
      "\n",
      "Overall training accuracy: 0.9889161146657811\n",
      "Wall time: 16min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_tfidf_tuned, predictions_lr_tfidf_tuned = tune_and_train_models(lr, parameters_lr, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287465c",
   "metadata": {},
   "source": [
    "For TF-IDF vectors, the tuning time is significantly faster at around 16 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1935a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.898502860795508\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_wrd2v_tuned, predictions_lr_wrd2v_tuned = tune_and_train_models(lr, parameters_lr, wrd2v_train, wrd2v_test)\n",
    "to_submission_csv(predictions_lr_wrd2v_tuned, 'submission_lr_wrd2v_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd15659",
   "metadata": {},
   "source": [
    "It can be seen above that count vectors had higher training accuracy scores for **toxic**, **severe_toxic**, **obscene**, **threat**, and **identity_hate**, while TODO: kasi irurun ulet to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79b557",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"submission_lr_count_tuned\": ['Logistic Regression', 'Count Vectors', 'Tuned', 0.94845, 0.94248],\n",
    "    \"submission_lr_tfidf_tuned\": ['Logistic Regression', 'TF-IDF Vectors', 'Tuned', 0.97558, 0.97621], \n",
    "    \"submission_lr_wrd2v_tuned\": ['Logistic Regression', 'Word2Vec Vectors', 'Tuned', 0.95233, 0.94982]\n",
    "}\n",
    "\n",
    "all_results = update_results(all_results, results)\n",
    "all_results.T.sort_values('test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5546",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes <a class=\"anchor\" id=\"mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9afeb",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `MultinomialNB()` object with default parameters is initialized to serve as the base classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d909b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae044f97",
   "metadata": {},
   "source": [
    "The model will first be trained using the count vectorized train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d6b0d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MultinomialNB()...\n",
      "toxic: 0.9513696097661856\n",
      "severe_toxic: 0.98641983819115\n",
      "obscene: 0.9670867513520627\n",
      "threat: 0.9955505699657206\n",
      "insult: 0.9646301646289113\n",
      "identity_hate: 0.9877233331871079\n",
      "\n",
      "Overall training accuracy: 0.975463377848523\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn_models_count, predictions_mn_count = train_models(mn, count_train, count_test)\n",
    "to_submission_csv(predictions_mn_count, 'submission_mn_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce2ce7",
   "metadata": {},
   "source": [
    "In comparison to the Logistic Regression model fitted with count vectorized data, the training accuracy is higher by only 0.001. Moreover, the time of execution has vastly improved, as fitting the six MultinomialNB() estimators only took 1.48 seconds.\n",
    "\n",
    "Then, the model will be trained using the TF-IDF vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ba44ba9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MultinomialNB()...\n",
      "toxic: 0.9236828747078103\n",
      "severe_toxic: 0.9899104473870566\n",
      "obscene: 0.9538449968979326\n",
      "threat: 0.996973134216117\n",
      "insult: 0.9535629907689994\n",
      "identity_hate: 0.9911074067343063\n",
      "\n",
      "Overall training accuracy: 0.968180308452037\n",
      "Wall time: 3.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn_models_tfidf, predictions_mn_tfidf = train_models(mn, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_mn_tfidf, 'submission_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13685eb4",
   "metadata": {},
   "source": [
    "The overall training accuracy for TF-IDF Vectors using the MultinomialNB estimator is lower compared to both the Count Vectors MultinonmialNB model and the TF-IDF Vectors using LogisticRegression models at 0.968. However, the training time of 1.32 seconds is the fastest so far.\n",
    "\n",
    "The MultinomialNB models trained with count vectorized data performed better when predicting **toxic**, **obscene**, and **insult** classes, while TF-IDF vectorized data performed better for **severe_toxic**, **threat**, and **identity_hate** classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b7679",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, \n",
    "\n",
    "# TODO: yuck ang baba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaedef",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count</td>\n",
    "    <td class=\"tg-baqh\">0.84551</td>\n",
    "    <td class=\"tg-baqh\">0.85581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.82510</td>\n",
    "    <td class=\"tg-baqh\">0.83586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdb55a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "A `MultinomialNB()` object with default parameters is declared for use as the base estimator, to be tuned by the defined [`parameters_mnb`](#param_mn) hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2ee76844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MultinomialNB()...\n",
      "toxic: 0.9654135149870591\n",
      "severe_toxic: 0.9901736531073942\n",
      "obscene: 0.9763992204097236\n",
      "threat: 0.9970044682304429\n",
      "insult: 0.974074236546741\n",
      "identity_hate: 0.9912515432002056\n",
      "\n",
      "Overall training accuracy: 0.9823861060802611\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn = MultinomialNB()\n",
    "mn_models_count_tuned, predictions_mn_count_tuned = tune_and_train_models(mn, parameters_mnb, count_train, count_test)\n",
    "to_submission_csv(predictions_mn_count_tuned, 'submission_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ecf109d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MultinomialNB()...\n",
      "toxic: 0.975553202022924\n",
      "severe_toxic: 0.9945980159302129\n",
      "obscene: 0.9865577078541841\n",
      "threat: 0.998727839018368\n",
      "insult: 0.9844708625000783\n",
      "identity_hate: 0.9957949752774627\n",
      "\n",
      "Overall training accuracy: 0.9892837671005382\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn = MultinomialNB()\n",
    "mn_models_tfidf_tuned, predictions_mn_tfidf_tuned = tune_and_train_models(mn, parameters_mnb, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3ce89",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90205</td>\n",
    "    <td class=\"tg-baqh\">0.90411</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90610</td>\n",
    "    <td class=\"tg-baqh\">0.90995</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b957",
   "metadata": {},
   "source": [
    "### RandomForestClassifier <a class=\"anchor\" id=\"rf\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f95b7",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `RandomForestClassifier()` object with default parameters is initialized before it is passed to the `train_models()` function. A classifier for each of the six classes for each vectorizer will be trained using this object as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ca166526",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "109a6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n",
      "toxic: 0.999793195505449\n",
      "severe_toxic: 0.9998245295197749\n",
      "obscene: 0.99983079632264\n",
      "threat: 0.9999247983656178\n",
      "insult: 0.9996678594481453\n",
      "identity_hate: 0.9999059979570223\n",
      "\n",
      "Overall training accuracy: 0.9998245295197749\n",
      "Wall time: 42min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_count, predictions_rf_count = train_models(rf, count_train, count_test)\n",
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a44162ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n",
      "toxic: 0.9997618614911231\n",
      "severe_toxic: 0.9997117270682017\n",
      "obscene: 0.9997869287025838\n",
      "threat: 0.999931065168483\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-127-6337c4f8bc50>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                                      \u001b[1;31m# loop for each of six classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_tfidf, predictions_rf_tfidf = train_models(rf, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9bc8682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n",
      "toxic: 0.9996490590395498\n",
      "severe_toxic: 0.9996929266596061\n",
      "obscene: 0.9996678594481453\n",
      "threat: 0.999931065168483\n",
      "insult: 0.9994673217564595\n",
      "identity_hate: 0.9998871975484267\n",
      "\n",
      "Overall training accuracy: 0.9997159049367784\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_wrd2v, predictions_rf_wrd2v = train_models(rf, wrd2v_train, wrd2v_test)\n",
    "to_submission_csv(predictions_rf_wrd2v, 'submission_rf_wrd2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adbfa9",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count</td>\n",
    "    <td class=\"tg-baqh\">0.94071</td>\n",
    "    <td class=\"tg-baqh\">0.94602</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.93731</td>\n",
    "    <td class=\"tg-baqh\">0.93999</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd252b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22f77194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-fbe1e2b19cad>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model, hyperparameters, X_train, X_test, scoring)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                \u001b[1;31m# loop for each combination of hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    594\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[1;31m# create new with correct sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mspmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m             \u001b[0mchanged_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[1;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mtocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         csr_tocsc(self.shape[0], self.shape[1],\n\u001b[0m\u001b[0;32m    183\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)\n",
    "rf_models_count_tuned, predictions_rf_count_tuned = tune_and_train_models(rf, parameters_rf, count_train, count_test)\n",
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9c7b1eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-fbe1e2b19cad>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model, hyperparameters, X_train, X_test, scoring)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                \u001b[1;31m# loop for each combination of hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)\n",
    "rf_models_tfidf_tuned, predictions_rf_tfidf_tuned = tune_and_train_models(rf, parameters_rf, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6a8aa",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.96232</td>\n",
    "    <td class=\"tg-baqh\">0.96285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.95937</td>\n",
    "    <td class=\"tg-baqh\">0.95826</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6d61c",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier <a class=\"anchor\" id=\"gbc\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1686af7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc659fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc_models_count, predictions_gbc_count = train_models(gbc, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc_models_tfidf, predictions_gbc_tfidf = train_models(gbc, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83bea7",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ade6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_count_tuned, predictions_gbc_count_tuned = tune_and_train_models(gbc, parameters_gbc, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_tfidf_tuned, predictions_gbc_tfidf_tuned = tune_and_train_models(gbc, parameters_gbc, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count_tuned, 'submission_gbc_count_tuned')\n",
    "to_submission_csv(predictions_gbc_tfidf_tuned, 'submission_gbc_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f4fd",
   "metadata": {},
   "source": [
    "### XGBClassifier <a class=\"anchor\" id=\"xgb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250de73",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_models_count, predictions_xgb_count = train_models(xgb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2260e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_models_tfidf, predictions_xgb_tfidf = train_models(xgb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count, 'submission_xgb_count')\n",
    "to_submission_csv(predictions_xgb_tfidf, 'submission_xgb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfec96",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>private</th>\n",
    "    <th>public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>submission_xgb_count</td>\n",
    "    <td>0.96468</td>\n",
    "    <td>0.96783</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>submission_xgb_tfidf</td>\n",
    "    <td>0.96502</td>\n",
    "    <td>0.96803</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfee743",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_count_tuned, predictions_xgb_count_tuned = tune_and_train_models(xgb, parameters_xgb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_tfidf_tuned, predictions_xgb_tfidf_tuned = tune_and_train_models(xgb, parameters_xgb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ad09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea054",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier <a class=\"anchor\" id=\"adb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db3139",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0253f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb_models_count, predictions_adb_count = train_models(adb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb_models_tfidf, predictions_adb_tfidf = train_models(adb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85403f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_count_tuned, predictions_adb_count_tuned = tune_and_train_models(adb, parameters_adb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a51c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba60206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_tfidf_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb, parameters_adb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_tuned = GridSearchCV(AdaBoostClassifier(random_state=8), parameters_adb, scoring='accuracy', cv=cv)\n",
    "adb_models_count_tuned, adb_models_tfidf_tuned, \\\n",
    "    predictions_adb_count_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803b2a5",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier <a class=\"anchor\" id=\"sgd\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9981549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b3421",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_models_count, predictions_sgd_count = train_models(sgd, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf693ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_models_tfidf, predictions_sgd_tfidf = train_models(sgd, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count, 'submission_sgd_count')\n",
    "to_submission_csv(predictions_sgd_tfidf, 'submission_sgd_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30717932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count, sgd_models_tfidf, predictions_sgd_count, predictions_sgd_tfidf = train_models(sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10cdff",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count</td>\n",
    "    <td class=\"tg-baqh\">0.68992</td>\n",
    "    <td class=\"tg-baqh\">0.70589</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97214</td>\n",
    "    <td class=\"tg-baqh\">0.97625</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd2aa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count_tuned, predictions_sgd_count_tuned = tune_and_train_models(sgd, parameters_sgd, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f763d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_tfidf_tuned, predictions_sgd_tfidf_tuned = tune_and_train_models(sgd, parameters_sgd, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count_tuned, 'submission_sgd_count_tuned')\n",
    "to_submission_csv(predictions_sgd_tfidf_tuned, 'submission_sgd_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b66f8",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.81387</td>\n",
    "    <td class=\"tg-baqh\">0.81848</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94660</td>\n",
    "    <td class=\"tg-baqh\">0.95230</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Logistic Regression <a class=\"anchor\" id=\"oc_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571180e0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr_model_count, predictions_oc_lr_count = train_model(oc_lr, count_train, count_test)\n",
    "to_submission_csv(predictions_oc_lr_count, 'submission_oc_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr_model_tfidf, predictions_oc_lr_tfidf = train_model(oc_lr, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_oc_lr_tfidf, 'submission_oc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a00c0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c267cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    "oc_lr_model_count_tuned, predictions_oc_lr_count_tuned = tune_and_train_model(oc_lr, parameters_lr_mo, count_train, count_test)\n",
    "to_submission_csv(predictions_oc_lr_count_tuned, 'submission_oc_lr_count_tuned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    "oc_lr_model_tfidf_tuned, predictions_oc_lr_tfidf_tuned = tune_and_train_model(oc_lr, parameters_lr_mo, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_oc_lr_tfidf_tuned, 'submission_oc_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7f230",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"oc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ac935",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48168411",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_mn = OneVsRestClassifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11375a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn_model_count, predictions_oc_mn_count = train_model(oc_mn, count_train, count_test)\n",
    "to_submission_csv(predictions_oc_mn_count, 'submission_oc_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn_model_tfidf, predictions_oc_mn_tfidf = train_model(oc_mn, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_oc_mn_tfidf, 'submission_oc_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de286172",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "625540e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning OneVsRestClassifier(estimator=MultinomialNB())...\n",
      "Overall training f1: 0.7751371196906105\n",
      "Best parameters: {'estimator__alpha': 1e-05, 'estimator__fit_prior': True}\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_mn = OneVsRestClassifier(MultinomialNB())\n",
    "oc_mn_model_count_tuned, predictions_oc_mn_count_tuned = tune_and_train_model(oc_mn, \n",
    "                                                                              parameters_mn_mo, \n",
    "                                                                              count_train, \n",
    "                                                                              count_test, \n",
    "                                                                              scoring='f1')\n",
    "to_submission_csv(predictions_oc_mn_count_tuned, 'submission_oc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb08d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn = OneVsRestClassifier(MultinomialNB())\n",
    "oc_mn_model_tfidf_tuned, predictions_oc_mn_tfidf_tuned = tune_and_train_model(oc_mn, parameters_mn_mo, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_oc_mn_tfidf_tuned, 'submission_oc_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec9910",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression <a class=\"anchor\" id=\"mo_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ea998",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b97d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f42e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr_model_count, predictions_mo_lr_count = train_model(mo_lr, count_train, count_test)\n",
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr_model_tfidf, predictions_mo_lr_tfidf = train_model(mo_lr, tfidf_train, tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6871d",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faba759",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "mo_lr_model_count_tuned, predictions_mo_lr_count_tuned = tune_and_train_model(mo_lr, parameters_lr_mo, count_train, count_test)\n",
    "to_submission_csv_multiclass(predictions_mo_lr_count_tuned, 'submission_mo_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "mo_lr_model_tfidf_tuned, predictions_mo_lr_tfidf_tuned = tune_and_train_model(mo_lr, parameters_lr_mo, tfidf_train, tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf_tuned, 'submission_mo_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b03d3a",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"mo_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4b87",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2282f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn_model_count, predictions_mo_mn_count = train_model(mo_mn, count_train, count_test)\n",
    "to_submission_csv_multiclass(predictions_mo_mn_count, 'submission_mo_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn_model_tfidf, predictions_mo_mn_tfidf = train_model(mo_mn, tfidf_train, tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mo_mn_tfidf, 'submission_mo_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fd6d2",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)\n",
    "mo_mn_model_count_tuned, predictions_mo_mn_count_tuned = tune_and_train_model(mo_mn, parameters_mn_mo, count_train, count_test)\n",
    "to_submission_csv_multiclass(predictions_mo_mn_count_tuned, 'submission_mo_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)\n",
    "mo_mn_model_tfidf_tuned, predictions_mo_mn_tfidf_tuned = tune_and_train_model(mo_mn, parameters_mn_mo, tfidf_train, tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mo_mn_tfidf_tuned, 'submission_mo_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263f499",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression <a class=\"anchor\" id=\"br_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd6c45",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr = BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c899d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr_model_count, predictions_br_lr_count = train_model(br_lr, count_train, count_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr_model_tfidf, predictions_br_lr_tfidf = train_model(br_lr, tfidf_train, tfidf_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cbbec",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75be75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr br_mn= BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "br_lr_model_count_tuned, predictions_br_lr_count_tuned = \\\n",
    "    tune_and_train_model(br_lr, parameters_lr_multi, count_train, count_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_lr_count_tuned, 'submission_br_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ddba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr = BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "br_lr_model_tfidf_tuned, predictions_br_lr_tfidf_tuned = \\\n",
    "    tune_and_train_model(br_lr, parameters_lr_multi, tfidf_train, tfidf_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf_tuned, 'submission_br_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839855c4",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes <a class=\"anchor\" id=\"br_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a0e79",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_mn = BinaryRelevance(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ec3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn_model_count, predictions_br_mn_count = train_model(br_mn, count_train, count_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn_model_tfidf, predictions_br_mn_tfidf = train_model(br_mn, tfidf_train, tfidf_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e95ce6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn = BinaryRelevance(MultinomialNB())\n",
    "br_mn_model_count_tuned, predictions_br_mn_count_tuned = \\\n",
    "    tune_and_train_models(br_mn, parameters_mn_multi, count_train, count_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_mn_count_tuned, 'submission_br_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn = BinaryRelevance(MultinomialNB())\n",
    "br_mn_model_tfidf_tuned, predictions_br_mn_tfidf_tuned = \\\n",
    "    tune_and_train_models(br_mn, parameters_mn_multi, tfidf_train, tfidf_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_br_mn_tfidf_tuned, 'submission_br_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cece5e",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes <a class=\"anchor\" id=\"cc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc05d4a",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mn = ClassifierChain(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn_model_count, predictions_cc_mn_count = train_model(cc_mn, count_train, count_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_cc_lr_count, 'submission_cc_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e42ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn_model_tfidf, predictions_cc_mn_tfidf = train_model(cc_mn, tfidf_train, tfidf_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_cc_lr_tfidf, 'submission_cc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1806f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn = ClassifierChain(MultinomialNB(), random_state=8)\n",
    "cc_mn_model_count_tuned, predictions_cc_mn_count_tuned = \\\n",
    "    tune_and_train_models(cc_mn, parameters_mn_multi, count_train, count_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_cc_mn_count_tuned, 'submission_cc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ed2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn = ClassifierChain(MultinomialNB(), random_state=8)\n",
    "cc_mn_model_tfidf_tuned, predictions_cc_mn_tfidf_tuned = \\\n",
    "    tune_and_train_models(cc_mn, parameters_mn_multi, tfidf_train, tfidf_test, dense=True)\n",
    "to_submission_csv_multiclass(predictions_cc_mn_tfidf_tuned, 'submission_cc_mn_tfidf_tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
