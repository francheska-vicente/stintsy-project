{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "#### Basic Libraries \n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations\n",
    "- `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features \n",
    "- `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce303532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries\n",
    "The following code block can be used to install **scikit-multilearn** without restarting Jupyter Notebook. The `sys` module is used to access the *executable* function of the interpreter, which would run the installation of scikit-multilearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850d2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a154c",
   "metadata": {},
   "source": [
    "The following libraries are multi-label classification modules that would allow the usage of one model that can classify one instance as more than one class.\n",
    "- `ClassifierChain` chains binary classifiers in a way that its predictions are dependent on the earlier classes\n",
    "- `BinaryRelevance` uses binary classifiers to classify the classes independently\n",
    "- `MultiOutputClassifier` fits one classifier per target class \n",
    "- `OneVsRestClassifier` fits one class against the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea567ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7f3",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "- `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees\n",
    "- `GradientBoostingClassifier` is a class under the ensemble module that optimizes arbitrary differentiable loss functions\n",
    "- `AdaBoostClassifier` is a class under the ensemble module that implements AdaBoost-SAMME\n",
    "- `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "- `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "- `SGDClassifier` is a class under the linear models module that implements regularized linear models with stochastic gradient descent (SGD) learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e6642",
   "metadata": {},
   "source": [
    "Meanwhile, the following classes are used for hyperparameter tuning.\n",
    "- `ParameterGrid` is a class that allows the iteration over different combinations of parameter values \n",
    "- `GridSearchCV` is a cross-validation class that allows the exhaustive search over all possible combinations of hyperparameter values\n",
    "- `RandomizedSearchCV` is a cross-validation class that allows a random search over some possible combinations of hyperparameter values\n",
    "- `train_test_split` divides the dataset into two subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f9c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878a641",
   "metadata": {},
   "source": [
    "The warnings module is used to ignore any ConvergenceWarnings that might appear when doing hyperparameter tuning. As these models will not be chosen due to low accuracy scores, the warnings would only clutter the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Load Files\n",
    "The csv files to be loaded here contains the datasets that have already gone through the data cleaning and preprocessing techniques discussed in the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe1ca0f",
   "metadata": {},
   "source": [
    "## Initialize Datasets\n",
    "Before using these datasets, we would need to convert the values in the `comment_text` column into either \"str, unicode or file objects\", according to the documentation of TF-IDF vectorizer and Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7c6cd",
   "metadata": {},
   "source": [
    "Then, we would be declaring our **X_train**, **y_train**, and **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed343812",
   "metadata": {},
   "source": [
    "Afterwards, we would be declaring the different classes that our model would need to predict. This can be found in the **train** data's column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "## Vectorizing Data\n",
    "As explained in the **Feature Engineering** part of the main notebook, three types of vectorizers would be used: (1) Count Vectorizer, (2) TF-IDF Vectorizer, and (3) Average Word2Vec Vectors.\n",
    "\n",
    "Two types of CountVectorizer and TF-IDF Vectorizers were made in consideration of the more complex estimators: one with no **max_features** parameter, and one with a **max_features** parameter that is equal to 5000. Limiting the number of max features would lessen the time and space complexity from training the estimators; this would lessen the burden on our machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18f9b5",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6d1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()                     # creating the Vectorizer with no max features\n",
    "count_train = count_vectorizer.fit_transform(X_train)    # fitting the vectorizer according to the train data, and then\n",
    "                                                         # returning the transformed train data\n",
    "count_test = count_vectorizer.transform(X_test)          # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_5000 = CountVectorizer(max_features = 5000)     # creating the Vectorizer with max features = 5000\n",
    "count_train_5000 = count_vectorizer_5000.fit_transform(X_train)  # fitting the vectorizer according to the train data, and then\n",
    "                                                                 # returning the transformed train data\n",
    "count_test_5000 = count_vectorizer_5000.transform(X_test)        # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec4160",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60850d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()                    # creating the Vectorizer with no max features\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)   # fitting the vectorizer according to the train data, and then\n",
    "                                                        # returning the transformed train data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)         # returning the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_5000 = TfidfVectorizer(max_features = 5000)    # creating the Vectorizer with max features = 5000\n",
    "tfidf_train_5000 = tfidf_vectorizer_5000.fit_transform(X_train) # fitting the vectorizer according to the train data, and then\n",
    "                                                                # returning the transformed train data\n",
    "tfidf_test_5000 = tfidf_vectorizer_5000.transform(X_test)       # returning the transformed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c4764",
   "metadata": {},
   "source": [
    "#### Average Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e37fd0",
   "metadata": {},
   "source": [
    "Before building a Word2Vec model, the data must be tokenized to produce a list of lists of tokens as indicated in Gensim's documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f4ad133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    t = TweetTokenizer()\n",
    "\n",
    "    tokens_list = []\n",
    "    for text in data:\n",
    "        tokens_list += [t.tokenize(text)]\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b49df",
   "metadata": {},
   "source": [
    "The train set is tokenized using NLTK's `TweetTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2cf31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenize(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff0c1d",
   "metadata": {},
   "source": [
    "The Word2Vec model is trained using this tokenized list, which would transform these words into word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f5a829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd2v_model = Word2Vec(tokens_train, epochs=30, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096f80f",
   "metadata": {},
   "source": [
    "To transform the word vectors into usable features, these vectors are averaged for all words in the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fe9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_word2vec(model, tokens_list):\n",
    "    vectors = []\n",
    "    \n",
    "    for tokens in tokens_list:                    # iterate through each sentence\n",
    "        feat = np.zeros(100)                      # initializes a list that will hold the vectors\n",
    "        count = 0                                 # initializes the word count for a sentence\n",
    "        \n",
    "        for token in tokens:                      # iterate through each word in the sentence\n",
    "            if token in model.wv.index_to_key:    # if the word is in the model's vocabulary...\n",
    "                feat += model.wv[token]           # ...add word vectors to list and...\n",
    "                count += 1                        # ...update the word count\n",
    "        \n",
    "        if count > 1:                             # if sentence contains more than 1 word in the model...\n",
    "            feat /= count                         # ...divide word vectors by word count to get the average\n",
    "            \n",
    "        vectors.append(feat)                      # add the averaged vectors to the list\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4aba11",
   "metadata": {},
   "source": [
    "Using the defined function, the train data can be vectorized using the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d6de79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrd2v_train = vectorize_word2vec(wrd2v_model, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfca4f",
   "metadata": {},
   "source": [
    "The test data is also vectorized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f63f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = tokenize(X_test)\n",
    "wrd2v_test = vectorize_word2vec(wrd2v_model, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac6bbd",
   "metadata": {},
   "source": [
    "## Training and Tuning Different Models <a class=\"anchor\" id=\"toc\"></a>\n",
    "TODO: i ken fly\n",
    "\n",
    "#### Variable and Function Declarations\n",
    "* [**Helper Functions**](#functs)\n",
    "* [**Hyperparameters**](#params)\n",
    "\n",
    "### Six Single-Label Classifiers\n",
    "* [**Logistic Regression**](#lr)\n",
    "* [**Multinomial Naive Bayes**](#mn)\n",
    "* [**Random Forest Classifier**](#rf)\n",
    "* [**Gradient Boosting Classifier**](#gbc)\n",
    "* [**eXtreme Gradient Boosting Classifier**](#xgb)\n",
    "* [**AdaBoostClassifier Boosting Classifier**](#adb)\n",
    "* [**Stochastic Gradient Descent Classifier**](#sgd)\n",
    "\n",
    "### Multi-Label Classifiers\n",
    "* [**OneVsRest Classifier: Logistic Regression**](#oc_lr)\n",
    "* [**OneVsRest Classifier: Multinomial Naive Bayes**](#oc_mn)\n",
    "* [**MultiOutput Classifier: Logistic Regression**](#mo_lr)\n",
    "* [**MultiOutput Classifier: Multinomial Naive Bayes**](#mo_mn)\n",
    "* [**Binary Relevance: Logistic Regression**](#br_lr)\n",
    "* [**Binary Relevance: Multinomial Naive Bayes**](#br_mn)\n",
    "* [**Classifier Chain: Multinomial Naive Bayes**](#cc_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "### Declaring Helper Functions <a class=\"anchor\" id=\"functs\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "Helper functions that would be repeatedly used throughout the notebook, will be declared and discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c387d02",
   "metadata": {},
   "source": [
    "#### Submission Template Functions\n",
    "The following `to_submission_csv` functions are used to create CSV files with the correct submission template. The first function is used by almost all models, while a modified version is used for the MultiOutput Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b0e762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43062d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv(predictions, filename):\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv_multiclass(predictions, filename):\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5a971",
   "metadata": {},
   "source": [
    "#### Display Functions\n",
    "The `format_results` function is used to compute for the final test accuracy and to display the final results as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7273e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(results):\n",
    "    for result in results:\n",
    "        # private score accounts for 90% of the test data, while the remaining 10% is the public score\n",
    "        results[result] += [round((results[result][0]*9 + results[result][1]) / 10, 6)]\n",
    "\n",
    "    return pd.DataFrame(results, index=['private', 'public', 'test accuracy']).T.sort_values('test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a8c95",
   "metadata": {},
   "source": [
    "#### Training and Tuning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65432a0a",
   "metadata": {},
   "source": [
    "As the task requires us to give predictions for six classes, the `train_models` function would train multiple classifiers that will give predictions for a given class. The function would fit each classifier using the passed train set, compute for the training accuracies for each class, then predict the classes of the passed test set.\n",
    "\n",
    "The function will return the trained models and their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5ecee997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model, X_train, X_test):\n",
    "    \"\"\"Trains six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    test_predictions = np.zeros((len(test), len(classes)))                  # initialize empty list for predictions\n",
    "    models = []                                                             # initialize empty list for models\n",
    "    train_accuracy = []\n",
    "    \n",
    "    \n",
    "    print('Fitting', str(model) + '...')\n",
    "    \n",
    "    for i in range(6):                                                      # loop for each of six classes\n",
    "        model.fit(X_train, y_train[classes[i]])                             # fit the model\n",
    "        \n",
    "        train_predictions = model.predict(X_train)                          # predict using train data\n",
    "        accuracy = accuracy_score(train_predictions, y_train[classes[i]])   # get training accuracy \n",
    "        print(classes[i] + ':', accuracy)\n",
    "        \n",
    "        test_predictions[:,i] = model.predict_proba(X_test)[:,1]            # predict using test data\n",
    "        \n",
    "        models += [model]\n",
    "        train_accuracy += [accuracy]\n",
    "    \n",
    "    print('Overall training accuracy:', np.mean(train_accuracy))\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54662d22",
   "metadata": {},
   "source": [
    "Similarly, the `tune_and_train_models` function will train multiple classifiers with the addition of hyperparameter tuning to achieve a better training accuracy. Hyperparameter tuning will be manually done using a `ParameterGrid` as using other model selection techniques such as `GridSearchCV` and `RandomizedCV` will be more time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ec21a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_models(model, hyperparameters, X_train, X_test, scoring='accuracy'):\n",
    "    \"\"\"Tunes six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    hyperparameters : estimator object\n",
    "        the hyperparameters used for tuning the model  \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    scoring : \n",
    "        the metric for deciding the best combination of parameters, either 'accuracy' or 'f1'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    test_predictions = np.zeros((len(test), len(classes)))                  # initialize empty list for predictions\n",
    "    models = []                                                             # initialize empty list for models\n",
    "    train_score = []\n",
    "    \n",
    "    print('Tuning', str(model) + '...')\n",
    "    \n",
    "    for i in range(6):                                                          # loop for each of six classes\n",
    "        best_score = 0                                                          # initialize best score per class\n",
    "\n",
    "        for g in ParameterGrid(hyperparameters):                                # loop for each combination of hyperparameters\n",
    "            model.set_params(**g)\n",
    "            model.fit(X_train, y_train[classes[i]])                             # fit the model\n",
    "            train_predictions = model.predict(X_train)                          # predict using train data\n",
    "            \n",
    "            if scoring == 'accuracy':                                           # compute the model's score using\n",
    "                score = accuracy_score(train_predictions, y_train[classes[i]])  # accuracy or...\n",
    "            else: \n",
    "                score = f1_score(train_predictions, y_train[classes[i]])        # ...f1 score\n",
    "            \n",
    "            if score > best_score:                                              # if the current model has the highest score,\n",
    "                best_score = score                                              # update the best score,\n",
    "                best_grid = g                                                   # update the best parameter combination, and\n",
    "                best_model = model                                              # save the best fitted model\n",
    "                \n",
    "        \n",
    "        print(classes[i] + ':', best_score)\n",
    "        print('Best parameters:', best_grid)\n",
    "        \n",
    "        test_predictions[:,i] = best_model.predict_proba(X_test)[:,1]           # predict with the best model using test data\n",
    "        \n",
    "        models += [best_model]\n",
    "        train_score += [best_score]\n",
    "    \n",
    "    print('Overall training', scoring + ':', np.mean(train_score))\n",
    "    \n",
    "    return models, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a521b",
   "metadata": {},
   "source": [
    "Multi-label classifiers would follow the same pipeline of training the model, getting the training predictions, and predicting the classes of the test data. As such, the `train_model` and `tune_and_train_model` functions will forgo the loop and proceed to train and/or tune the model using the whole **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7702b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, X_test, dense=False):\n",
    "    \"\"\"Trains a model using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    dense : \n",
    "        a boolean value indicating if the predictions need to be converted to dense\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        a fitted estimator object\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Fitting', str(model) + '...')\n",
    "    \n",
    "    model.fit(X_train, y_train)                                               # fit the model\n",
    "    train_predictions = model.predict(X_train)                                # predict using train data\n",
    "    \n",
    "    if dense:                                           \n",
    "        train_predictions = train_predictions.to_dense()                      # convert predictions to dense\n",
    "        \n",
    "    accuracy = accuracy_score(train_predictions, y_train)                     # get training accuracy \n",
    "    print(accuracy)                                                        \n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)                            # predict using test data\n",
    "    \n",
    "    return model, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea53f9",
   "metadata": {},
   "source": [
    "As with the previous functions, the `tune_and_train_model` function will tune a single multi-label classifier using a `ParameterGrid` to increase the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "677549cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_model(model, hyperparameters, X_train, X_test, scoring='accuracy', dense=False):\n",
    "    \"\"\"Tunes six models using a given train and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        the type of estimator to be trained \n",
    "    hyperparameters : estimator object\n",
    "        the hyperparameters used for tuning the model  \n",
    "    X_train : \n",
    "        the data used in fitting the model\n",
    "    X_test : \n",
    "        the data to be predicted\n",
    "    scoring : \n",
    "        the metric for deciding the best combination of parameters, either 'accuracy' or 'f1'\n",
    "    dense : \n",
    "        a boolean value indicating if the predictions need to be converted to dense\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models\n",
    "        a list of fitted estimator objects\n",
    "    test_predictions\n",
    "        a list of prediction probabilities by the fitted model\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Tuning', str(model) + '...')\n",
    "    \n",
    "    best_score = 0\n",
    "\n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "        model.set_params(**g)\n",
    "        model.fit(X_train, y_train)                                          # fit the model\n",
    "        train_predictions = model.predict(X_train)                           # predict using train data\n",
    "\n",
    "        if dense:\n",
    "            train_predictions = train_predictions.to_dense()                 # convert predictions to dense\n",
    "        \n",
    "        if scoring == 'accuracy':                                            # compute the model's score using\n",
    "            score = accuracy_score(train_predictions, y_train)               # accuracy or...\n",
    "        else: \n",
    "            score = f1_score(train_predictions, y_train, average='weighted') # ...f1 score\n",
    "\n",
    "        if score > best_score:                                               # if the current model has the highest score,\n",
    "            best_score = score                                               # update the best score,\n",
    "            best_grid = g                                                    # update the best parameter combination, and\n",
    "            best_model = model                                               # save the best fitted model\n",
    "\n",
    "    print(best_score)\n",
    "    print('Best parameters:', best_grid)\n",
    "    test_predictions = best_model.predict_proba(X_test)                      # predict using test data\n",
    "\n",
    "    return model, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": [
    "### Declaring Hyperparameter Values <a class=\"anchor\" id=\"params\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "As hyperparameters for each base estimator will remain constant, these will be declared here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e83d3",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameters <a class=\"anchor\" id=\"param_lr\"></a>\n",
    "Tuning Logistic Regression models mostly involve altering the C, which controls the regularization strength, and the maximum number of iterations. \n",
    "\n",
    "For the C value, different powers of the default value (1) were tested to see if a stronger or weaker regularization strength can affect the results.\n",
    "\n",
    "During earlier testing stages, it was determined that the default number of max iterations (100) resulted in a ConvergenceWarning. With this, higher values were considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c75638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [{\n",
    "    'C' : [0.01, 0.1, 1, 10],\n",
    "    'max_iter' : [300, 600, 900, 1200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce74e5",
   "metadata": {},
   "source": [
    "As the OneVsRest Classifier and MultiOutput Classifier require a slightly altered format, this was declared as a different variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "153902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [{\n",
    "    'estimator__C': [0.01, 0.1, 1, 10],            # [1, 12, 15]\n",
    "    'estimator__max_iter': [300, 600, 900, 1200],  # [600, 1800, 3000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf27334",
   "metadata": {},
   "source": [
    "The Binary Relevance classifier also requires its own separate format, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_multi = [{\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],            # [1, 12, 15]\n",
    "    'classifier__max_iter': [300, 600, 900, 1200]   # [600, 1800, 3000],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95e23d",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Hyperparameters <a class=\"anchor\" id=\"param_mnb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee4b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [{\n",
    "    'alpha' : [0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f4323",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_mo = [{\n",
    "    'estimator__alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000],   # [0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "    'estimator__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e10be",
   "metadata": {},
   "source": [
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_multi = [{\n",
    "    'classifier': [MultinomialNB()],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000],   # [0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "    'classifier__fit_prior': [True, False]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf8952",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Hyperparameters <a class=\"anchor\" id=\"param_rf\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "865abbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = [{\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 20, 30],\n",
    "    'min_samples_split' : [2, 4, 6, 10, 15, 20],\n",
    "    'max_leaf_nodes' : [3, 5, 10, 20, 50, 100],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7f119",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier Hyperparameters <a class=\"anchor\" id=\"param_gbc\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ebe92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gbc = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7abec",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier Hyperparameters <a class=\"anchor\" id=\"param_xgb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca0f7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgb = [{\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3753a8",
   "metadata": {},
   "source": [
    "#### Adaboost Classifier Hyperparameters <a class=\"anchor\" id=\"param_adb\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c28c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_adb = {\n",
    "    'n_estimators' : [10, 25, 50, 100, 250],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fcd8d",
   "metadata": {},
   "source": [
    "#### SGDClassifier Hyperparameters <a class=\"anchor\" id=\"param_sgd\"></a>\n",
    "For Multinomial Naive Bayes hyperparameters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29d29c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sgd = [{\n",
    "    'loss' : ['log', 'modified_huber'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39b3aa",
   "metadata": {},
   "source": [
    "## Model Experimentation\n",
    "It should be noted that all models used below will have these constant values for parameters, if applicable:\n",
    "* `n_jobs = -1`, which would ensure that all CPU cores will be used for faster processing,\n",
    "* `class_weight='balanced'`, which would <TODO>, and\n",
    "* `random_state=8`, which would ensure that the output can be reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d6f2",
   "metadata": {},
   "source": [
    "### Logistic Regression <a class=\"anchor\" id=\"lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: baket ito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db2b05",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `LogisticRegression()` object is first initialized to be used as the base classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "51162851",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891dd80",
   "metadata": {},
   "source": [
    "The model is then trained using the count vectorized train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78aad487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9616847672822756\n",
      "severe_toxic: 0.9756534708687669\n",
      "obscene: 0.9744627783243822\n",
      "threat: 0.9962963195066773\n",
      "insult: 0.9615468976192416\n",
      "identity_hate: 0.9769820330761855\n",
      "Overall accuracy: 0.9744377111129215\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_models_count, predictions_lr_count = train_models(lr, count_train, count_test)\n",
    "to_submission_csv(predictions_lr_count, 'submission_lr_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641c7aa",
   "metadata": {},
   "source": [
    "The results for count vectors are quite accurate, seeing as the training accuracy rate is at least 0.96.\n",
    "\n",
    "Next, the model will be trained using the TF-IDF vectorized data as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72d587df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9574170745310865\n",
      "severe_toxic: 0.9794260861936066\n",
      "obscene: 0.9807421147952949\n",
      "threat: 0.9937519975434133\n",
      "insult: 0.9681019734162223\n",
      "identity_hate: 0.9810303877270933\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_models_tfidf, predictions_lr_tfidf = train_models(lr, tfidf_train, tfidf_test)\n",
    "to_submission_csv(predictions_lr_tfidf, 'submission_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921cd030",
   "metadata": {},
   "source": [
    "Compared to count vectors, the use of TF-IDF vectors yielded higher training accuracy scores for **severe_toxic**, **obscene**, **insult**, and **identity_hate**. Moreover, the execution time is faster by around 9 seconds.\n",
    "\n",
    "Lastly, the Word2Vec vectorized data will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e9ece5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.8984088587525302\n",
      "severe_toxic: 0.948117139079156\n",
      "obscene: 0.92264258543219\n",
      "threat: 0.9272236183266382\n",
      "insult: 0.9160687092266139\n",
      "identity_hate: 0.9084670773511477\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_models_wrd2v, predictions_lr_wrd2v = train_models(lr, wrd2v_train, wrd2v_test)\n",
    "to_submission_csv(predictions_lr_wrd2v, 'submission_lr_wrd2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848172e5",
   "metadata": {},
   "source": [
    "Word2Vec vectors produced the lowest training accuracies so far, ranging from 0.89 to 0.94 only. Furthermore, training the six models took 3 minutes, which is relatively longer than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "823513ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_avrge = (predictions_lr_count + predictions_lr_tfidf + predictions_lr_wrd2v)/3\n",
    "to_submission_csv(predictions_lr_avrge, 'submission_lr_avrge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085e4eb",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TF-IDF vectors performed the best, followed by Word2Vec vectors, then count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "46be77cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_lr_tfidf</th>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.97621</td>\n",
       "      <td>0.975643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_lr_avrge</th>\n",
       "      <td>0.97433</td>\n",
       "      <td>0.97275</td>\n",
       "      <td>0.974172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_lr_wrd2v</th>\n",
       "      <td>0.95233</td>\n",
       "      <td>0.94982</td>\n",
       "      <td>0.952079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_lr_count</th>\n",
       "      <td>0.94845</td>\n",
       "      <td>0.94248</td>\n",
       "      <td>0.947853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     private   public  test accuracy\n",
       "submission_lr_tfidf  0.97558  0.97621       0.975643\n",
       "submission_lr_avrge  0.97433  0.97275       0.974172\n",
       "submission_lr_wrd2v  0.95233  0.94982       0.952079\n",
       "submission_lr_count  0.94845  0.94248       0.947853"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    \"submission_lr_count\": [0.94845, 0.94248],\n",
    "    \"submission_lr_tfidf\": [0.97558, 0.97621], \n",
    "    \"submission_lr_wrd2v\": [0.95233, 0.94982], \n",
    "    \"submission_lr_avrge\": [0.97433, 0.97275]\n",
    "}\n",
    "\n",
    "format_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebed0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "A `LogisticRegression()` object with default parameters will serve as the base estimator, which will be tuned using the [`parameters_lr`](#param_lr) hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea6b02bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9922228976443088\n",
      "Best parameters: {'C': 10, 'max_iter': 1200}\n",
      "severe_toxic: 0.9934887918230756\n",
      "Best parameters: {'C': 10, 'max_iter': 1200}\n",
      "obscene: 0.9942972093926842\n",
      "Best parameters: {'C': 10, 'max_iter': 1200}\n",
      "threat: 0.999448521347864\n",
      "Best parameters: {'C': 10, 'max_iter': 600}\n",
      "insult: 0.9888012232799193\n",
      "Best parameters: {'C': 10, 'max_iter': 1200}\n",
      "identity_hate: 0.9950554925393712\n",
      "Best parameters: {'C': 10, 'max_iter': 1200}\n",
      "Wall time: 54min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_count_tuned, predictions_lr_count_tuned = tune_and_train_models(lr, parameters_lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617533c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2eeaf7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.9798710291970345\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "severe_toxic: 0.989340168326325\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "obscene: 0.9901423190930683\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "threat: 0.998145026351906\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "insult: 0.9829981638267605\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "identity_hate: 0.9930062480024566\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "Wall time: 13min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_tfidf_tuned, predictions_lr_tfidf_tuned = tune_and_train_models(lr, parameters_lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "643fd341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression(class_weight='balanced', n_jobs=-1)...\n",
      "toxic: 0.898502860795508\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "severe_toxic: 0.9481735403049426\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "obscene: 0.9227365874751678\n",
      "Best parameters: {'C': 10, 'max_iter': 300}\n",
      "threat: 0.927248685538099\n",
      "Best parameters: {'C': 1, 'max_iter': 300}\n",
      "insult: 0.9166515218930759\n",
      "Best parameters: {'C': 0.01, 'max_iter': 300}\n",
      "identity_hate: 0.909162692469183\n",
      "Best parameters: {'C': 0.01, 'max_iter': 300}\n",
      "Wall time: 59min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "lr_models_wrd2v_tuned, predictions_lr_wrd2v_tuned = tune_and_train_models(lr, parameters_lr, wrd2v_train, wrd2v_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd15659",
   "metadata": {},
   "source": [
    "It can be seen above that count vectors had higher training accuracy scores for **toxic**, **severe_toxic**, **obscene**, **threat**, and **identity_hate**, while TODO: kasi irurun ulet to\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37b88577",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count_tuned, 'submission_lr_count_tuned')\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79b557",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448f00b",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94016</td>\n",
    "    <td class=\"tg-baqh\">0.94392</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.97135</td>\n",
    "    <td class=\"tg-baqh\">0.97227</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5546",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes <a class=\"anchor\" id=\"mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9afeb",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `MultinomialNB()` object with default parameters is initialized to serve as the base classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d909b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe40bd3",
   "metadata": {},
   "source": [
    "The model will first be trained using the count vectorized train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6b0d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MultinomialNB()...\n",
      "toxic: 0.9513696097661856\n",
      "severe_toxic: 0.98641983819115\n",
      "obscene: 0.9670867513520627\n",
      "threat: 0.9955505699657206\n",
      "insult: 0.9646301646289113\n",
      "identity_hate: 0.9877233331871079\n",
      "Overall accuracy: 0.975463377848523\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn_models_count, predictions_mn_count = train_models(mn, count_train, count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c302321",
   "metadata": {},
   "source": [
    "TODO: comments on ^^\n",
    "\n",
    "Then, the model will be trained using the TF-IDF vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba44ba9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MultinomialNB()...\n",
      "toxic: 0.9236828747078103\n",
      "severe_toxic: 0.9899104473870566\n",
      "obscene: 0.9538449968979326\n",
      "threat: 0.996973134216117\n",
      "insult: 0.9535629907689994\n",
      "identity_hate: 0.9911074067343063\n",
      "Overall accuracy: 0.968180308452037\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn_models_tfidf, predictions_mn_tfidf = train_models(mn, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13685eb4",
   "metadata": {},
   "source": [
    "As seen from the output above, the models trained with count vectorized data performed better when predicting **toxic**, **obscene**, and **insult** classes, while TF-IDF vectorized data performed better for **severe_toxic**, **threat**, and **identity_hate** classes.\n",
    "\n",
    "Next, the test predictions are saved to a csv file before it is uploaded to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8eee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_count, 'submission_mn_count')\n",
    "to_submission_csv(predictions_mn_tfidf, 'submission_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b7679",
   "metadata": {},
   "source": [
    "#### Test Accuracy Score\n",
    "As seen from the scores returned by Kaggle, \n",
    "\n",
    "# TODO: yuck ang baba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaedef",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count</td>\n",
    "    <td class=\"tg-baqh\">0.84551</td>\n",
    "    <td class=\"tg-baqh\">0.85581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.82510</td>\n",
    "    <td class=\"tg-baqh\">0.83586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdb55a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "A `MultinomialNB()` object with default parameters is declared for use as the base estimator, to be tuned by the defined [`parameters_mnb`](#param_mn) hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ee76844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MultinomialNB()...\n",
      "toxic: 0.9661968653452069\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "severe_toxic: 0.9901736531073942\n",
      "Best parameters: {'alpha': 10, 'fit_prior': True}\n",
      "obscene: 0.9771512367535454\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "threat: 0.9970044682304429\n",
      "Best parameters: {'alpha': 1000, 'fit_prior': True}\n",
      "insult: 0.9749202549335405\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "identity_hate: 0.9912515432002056\n",
      "Best parameters: {'alpha': 100, 'fit_prior': True}\n",
      "Overall training accuracy: 0.9827830035950559\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn = MultinomialNB()\n",
    "mn_models_count_tuned, predictions_mn_count_tuned = tune_and_train_models(mn, parameters_mnb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ecf109d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MultinomialNB()...\n",
      "toxic: 0.975828941348992\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "severe_toxic: 0.9947421523961121\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "obscene: 0.9867457119401395\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "threat: 0.9987403726240983\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "insult: 0.9846651333888989\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "identity_hate: 0.9958889773204405\n",
      "Best parameters: {'alpha': 1e-05, 'fit_prior': True}\n",
      "Overall training accuracy: 0.9894352148364468\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mn = MultinomialNB()\n",
    "mn_models_tfidf_tuned, predictions_mn_tfidf_tuned = tune_and_train_models(mn, parameters_mnb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9017ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_count_tuned, 'submission_mn_count_tuned')\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3ce89",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90205</td>\n",
    "    <td class=\"tg-baqh\">0.90411</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mn_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.90610</td>\n",
    "    <td class=\"tg-baqh\">0.90995</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b957",
   "metadata": {},
   "source": [
    "### RandomForestClassifier <a class=\"anchor\" id=\"rf\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f95b7",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "A `RandomForestClassifier()` object with default parameters is initialized before it is passed to the `train_models()` function. A classifier for each of the six classes for each vectorizer will be trained using this object as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca166526",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "109a6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n",
      "toxic: 0.999793195505449\n",
      "severe_toxic: 0.9998245295197749\n",
      "obscene: 0.99983079632264\n",
      "threat: 0.9999247983656178\n",
      "insult: 0.9996678594481453\n",
      "identity_hate: 0.9999059979570223\n",
      "Wall time: 36min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_count, predictions_rf_count = train_models(rf, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a44162ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-d7f27b9bf33d>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                                      \u001b[1;31m# loop for each of six classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_tfidf, predictions_rf_tfidf = train_models(rf, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bc8682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=8)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-d7f27b9bf33d>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                                      \u001b[1;31m# loop for each of six classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# predict using train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_models_wrd2v, predictions_rf_wrd2v = train_models(rf, wrd2v_train, wrd2v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0aa6ad3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_rf_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-b30cf1f0cc92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mto_submission_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_rf_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'submission_rf_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mto_submission_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_rf_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'submission_rf_tfidf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mto_submission_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_rf_wrd2v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'submission_rf_wrd2v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions_rf_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')\n",
    "to_submission_csv(predictions_rf_wrd2v, 'submission_rf_wrd2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adbfa9",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count</td>\n",
    "    <td class=\"tg-baqh\">0.94071</td>\n",
    "    <td class=\"tg-baqh\">0.94602</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.93731</td>\n",
    "    <td class=\"tg-baqh\">0.93999</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd252b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f77194",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)\n",
    "rf_models_count_tuned, predictions_rf_count_tuned = tune_and_train_models(rf, parameters_rf, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=8)\n",
    "rf_models_tfidf_tuned, predictions_rf_tfidf_tuned = tune_and_train_models(rf, parameters_rf, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6a8aa",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.96232</td>\n",
    "    <td class=\"tg-baqh\">0.96285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.95937</td>\n",
    "    <td class=\"tg-baqh\">0.95826</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6d61c",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier <a class=\"anchor\" id=\"gbc\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1686af7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc659fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc_models_count, predictions_gbc_count = train_models(gbc, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc_models_tfidf, predictions_gbc_tfidf = train_models(gbc, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83bea7",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ade6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_count_tuned, predictions_gbc_count_tuned = tune_and_train_models(gbc, parameters_gbc, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier(random_state=8)\n",
    "gbc_models_tfidf_tuned, predictions_gbc_tfidf_tuned = tune_and_train_models(gbc, parameters_gbc, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count_tuned, 'submission_gbc_count_tuned')\n",
    "to_submission_csv(predictions_gbc_tfidf_tuned, 'submission_gbc_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f4fd",
   "metadata": {},
   "source": [
    "### XGBClassifier <a class=\"anchor\" id=\"xgb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>\n",
    "TODO: i ken fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250de73",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_models_count, predictions_xgb_count = train_models(xgb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2260e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_models_tfidf, predictions_xgb_tfidf = train_models(xgb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count, 'submission_xgb_count')\n",
    "to_submission_csv(predictions_xgb_tfidf, 'submission_xgb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfec96",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>private</th>\n",
    "    <th>public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>submission_xgb_count</td>\n",
    "    <td>0.96468</td>\n",
    "    <td>0.96783</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>submission_xgb_tfidf</td>\n",
    "    <td>0.96502</td>\n",
    "    <td>0.96803</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfee743",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_count_tuned, predictions_xgb_count_tuned = tune_and_train_models(xgb, parameters_xgb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", eval_metric='auc', verbosity=0, use_label_encoder=False)\n",
    "xgb_models_tfidf_tuned, predictions_xgb_tfidf_tuned = tune_and_train_models(xgb, parameters_xgb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ad09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea054",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier <a class=\"anchor\" id=\"adb\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db3139",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0253f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb_models_count, predictions_adb_count = train_models(adb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb_models_tfidf, predictions_adb_tfidf = train_models(adb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85403f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_count_tuned, predictions_adb_count_tuned = tune_and_train_models(adb, parameters_adb, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a51c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba60206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adb = AdaBoostClassifier(random_state=8)\n",
    "adb_models_tfidf_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb, parameters_adb, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_tuned = GridSearchCV(AdaBoostClassifier(random_state=8), parameters_adb, scoring='accuracy', cv=cv)\n",
    "adb_models_count_tuned, adb_models_tfidf_tuned, \\\n",
    "    predictions_adb_count_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803b2a5",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier <a class=\"anchor\" id=\"sgd\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9981549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_xgb_count_tuned.csv', 'submission_xgb_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b3421",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_models_count, predictions_sgd_count = train_models(sgd, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf693ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_models_tfidf, predictions_sgd_tfidf = train_models(sgd, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count, 'submission_sgd_count')\n",
    "to_submission_csv(predictions_sgd_tfidf, 'submission_sgd_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30717932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count, sgd_models_tfidf, predictions_sgd_count, predictions_sgd_tfidf = train_models(sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10cdff",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count</td>\n",
    "    <td class=\"tg-baqh\">0.68992</td>\n",
    "    <td class=\"tg-baqh\">0.70589</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97214</td>\n",
    "    <td class=\"tg-baqh\">0.97625</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd2aa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_count_tuned, predictions_sgd_count_tuned = tune_and_train_models(sgd, parameters_sgd, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f763d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', n_jobs=-1, random_state=8)\n",
    "sgd_models_tfidf_tuned, predictions_sgd_tfidf_tuned = tune_and_train_models(sgd, parameters_sgd, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count_tuned, 'submission_sgd_count_tuned')\n",
    "to_submission_csv(predictions_sgd_tfidf_tuned, 'submission_sgd_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b66f8",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.81387</td>\n",
    "    <td class=\"tg-baqh\">0.81848</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_sgd_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.94660</td>\n",
    "    <td class=\"tg-baqh\">0.95230</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Logistic Regression <a class=\"anchor\" id=\"oc_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571180e0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad663474",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr_model_count, predictions_oc_lr_count = train_model(oc_lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr_model_tfidf, predictions_oc_lr_tfidf = train_model(oc_lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_oc_lr_count, 'submission_oc_lr_count')\n",
    "to_submission_csv(predictions_oc_lr_tfidf, 'submission_oc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a00c0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    "oc_lr_model_count_tuned, predictions_oc_lr_count_tuned = tune_and_train_model(oc_lr, parameters_lr_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f938f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    "oc_lr_model_tfidf_tuned, predictions_oc_lr_tfidf_tuned = tune_and_train_model(oc_lr, parameters_lr_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_oc_lr_count_tuned, 'submission_oc_lr_count_tuned')\n",
    "to_submission_csv(predictions_oc_lr_tfidf_tuned, 'submission_oc_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7f230",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"oc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ac935",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48168411",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_mn = OneVsRestClassifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11375a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn_model_count, predictions_oc_mn_count = train_model(oc_mn, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn_model_tfidf, predictions_oc_mn_tfidf = train_model(oc_mn, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_oc_mn_count, 'submission_oc_mn_count')\n",
    "to_submission_csv(predictions_oc_mn_tfidf, 'submission_oc_mn_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de286172",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1c490e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning OneVsRestClassifier(estimator=MultinomialNB())...\n",
      "0.7751371196906105\n",
      "Best parameters: {'estimator__alpha': 1e-05, 'estimator__fit_prior': True}\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oc_mn = OneVsRestClassifier(MultinomialNB())\n",
    "oc_mn_model_count_tuned, predictions_oc_mn_count_tuned = tune_and_train_model(oc_mn, parameters_mn_mo, count_train, count_test, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dda8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_mn = OneVsRestClassifier(MultinomialNB())\n",
    "oc_mn_model_tfidf_tuned, predictions_oc_mn_tfidf_tuned = tune_and_train_model(oc_mn, parameters_mn_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592607c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_oc_mn_count_tuned, 'submission_oc_mn_count_tuned')\n",
    "to_submission_csv(predictions_oc_mn_tfidf_tuned, 'submission_oc_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec9910",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression <a class=\"anchor\" id=\"mo_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ea998",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ff172",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f42e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr_model_count, predictions_mo_lr_count = train_model(mo_lr, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr_model_tfidf, predictions_mo_lr_tfidf = train_model(mo_lr, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab55861",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6871d",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "mo_lr_model_count_tuned, predictions_mo_lr_count_tuned = tune_and_train_models(mo_lr, parameters_lr_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_lr = MultiOutputClassifier(LogisticRegression(n_jobs=-1, class_weight='balanced'), n_jobs=-1)\n",
    "mo_lr_model_tfidf_tuned, predictions_mo_lr_tfidf_tuned = tune_and_train_models(mo_lr, parameters_lr_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count_tuned, 'submission_mo_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf_tuned, 'submission_mo_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b03d3a",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes <a class=\"anchor\" id=\"mo_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4b87",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ee629",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn_model_count, predictions_mo_mn_count = train_model(mo_mn, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn_model_tfidf, predictions_mo_mn_tfidf = train_model(mo_mn, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353eeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_lr_count, 'submission_mo_lr_count')\n",
    "to_submission_csv_multiclass(predictions_mo_lr_tfidf, 'submission_mo_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fd6d2",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)\n",
    "mo_mn_model_count_tuned, predictions_mo_mn_count_tuned = tune_and_train_models(mo_mn, parameters_mn_mo, count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7024349",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mo_mn = MultiOutputClassifier(MultinomialNB(), n_jobs=-1)\n",
    "mo_mn_model_tfidf_tuned, predictions_mo_mn_tfidf_tuned = tune_and_train_models(mo_mn, parameters_mn_mo, tfidf_train, tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60da467",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mo_mn_count_tuned, 'submission_mo_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_mo_mn_tfidf_tuned, 'submission_mo_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263f499",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression <a class=\"anchor\" id=\"br_lr\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd6c45",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9eebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr = BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr_model_count, predictions_br_lr_count = train_model(br_lr, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef478c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr_model_tfidf, predictions_br_lr_tfidf = train_model(br_lr, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cbbec",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr br_mn= BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "br_lr_model_count_tuned, predictions_br_lr_count_tuned = \\\n",
    "    tune_and_train_models(br_lr, parameters_lr_multi, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f672118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_lr = BinaryRelevance(LogisticRegression(n_jobs=-1, class_weight='balanced'))\n",
    "br_lr_model_tfidf_tuned, predictions_br_lr_tfidf_tuned = \\\n",
    "    tune_and_train_models(br_lr, parameters_lr_multi, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80960d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count_tuned, 'submission_br_lr_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf_tuned, 'submission_br_lr_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839855c4",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes <a class=\"anchor\" id=\"br_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a0e79",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_mn = BinaryRelevance(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn_model_count, predictions_br_mn_count = train_model(br_mn, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn_model_tfidf, predictions_br_mn_tfidf = train_model(br_mn, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_lr_count, 'submission_br_lr_count')\n",
    "to_submission_csv_multiclass(predictions_br_lr_tfidf, 'submission_br_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e95ce6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn = BinaryRelevance(MultinomialNB())\n",
    "br_mn_model_count_tuned, predictions_br_mn_count_tuned = \\\n",
    "    tune_and_train_models(br_mn, parameters_mn_multi, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9317055",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_mn = BinaryRelevance(MultinomialNB())\n",
    "br_mn_model_tfidf_tuned, predictions_br_mn_tfidf_tuned = \\\n",
    "    tune_and_train_models(br_mn, parameters_mn_multi, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565699ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_br_mn_count_tuned, 'submission_br_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_br_mn_tfidf_tuned, 'submission_br_mn_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cece5e",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes <a class=\"anchor\" id=\"cc_mn\"></a><a style=\"float:right; font-size:11px\" href=\"#toc\">Back to Models List</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc05d4a",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mn = ClassifierChain(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn_model_count, predictions_cc_mn_count = train_model(cc_mn, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd855db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn_model_tfidf, predictions_cc_mn_tfidf = train_model(cc_mn, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd707690",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_cc_lr_count, 'submission_cc_lr_count')\n",
    "to_submission_csv_multiclass(predictions_cc_lr_tfidf, 'submission_cc_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1806f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn = ClassifierChain(MultinomialNB(), random_state=8)\n",
    "cc_mn_model_count_tuned, predictions_cc_mn_count_tuned = \\\n",
    "    tune_and_train_models(cc_mn, parameters_mn_multi, count_train, count_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_mn = ClassifierChain(MultinomialNB(), random_state=8)\n",
    "cc_mn_model_tfidf_tuned, predictions_cc_mn_tfidf_tuned = \\\n",
    "    tune_and_train_models(cc_mn, parameters_mn_multi, tfidf_train, tfidf_test, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66083052",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_cc_mn_count_tuned, 'submission_cc_mn_count_tuned')\n",
    "to_submission_csv_multiclass(predictions_cc_mn_tfidf_tuned, 'submission_cc_mn_tfidf_tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
