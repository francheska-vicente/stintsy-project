{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "### Import\n",
    "Several libraries are required to perform a thorough analysis of the dataset. Each of these libraries will be imported and described below:\n",
    "\n",
    "#### Basic Libraries \n",
    "Import `numpy` and `pandas`.\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836013db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Datasets and Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Trying different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61100a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    accuracy = np.sum (predictions == actual) / len (predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "967d71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "176302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyper_parameter:\n",
    "    def __init__(self, class_, alpha, fit_prior):\n",
    "        self.class_ = class_\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd42ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc027b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07c13642",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fba0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0bae987",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c613366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b3b66",
   "metadata": {},
   "source": [
    "### Classifier Chain: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07effd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cc = ClassifierChain(\n",
    "    classifier = LogisticRegression(max_iter = 300, C = 10),\n",
    ")\n",
    "\n",
    "lr_cc.fit(count_train, y_train)\n",
    "\n",
    "predictions = lr_cc.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_cc.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'../results/submission_class_lr_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bc68f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [1, 12, 15],\n",
    "        'classifier__max_iter': [600, 1800, 3000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67034465",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cc_tuned = GridSearchCV(ClassifierChain(), parameters_lr, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bef7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lr_cc_tuned.fit(count_train, y_train)\n",
    "print (lr_cc_tuned.best_params_, lr_cc_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_cc_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_cc_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'../results/submission_class_lr_cc_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc = ClassifierChain(\n",
    "    classifier = MultinomialNB(),\n",
    "    max_iter = 300,\n",
    "    alpha = 1.0,\n",
    "    fit_prior = True\n",
    ")\n",
    "\n",
    "mn_cc.fit(count_train, y_train)\n",
    "\n",
    "predictions = mn_cc.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'../results/submission_class_mn_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tuned = GridSearchCV(ClassifierChain(), parameters_mn, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_cc_tuned.fit(count_train, y_train)\n",
    "print (mn_cc_tuned.best_params_, mn_cc_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a93384",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ab6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'../results/submission_class_mn_cc_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf324509",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc574c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'../results/submission_tfidf_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a8714",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5cdd89",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab42516",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24309156",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ea51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(count_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(count_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "sample_submission.to_csv(f'../results/submission_count_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6d970",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [1, 3, 5, 10, 15, 20, 50], \n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, random_state = 42, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70786f3",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb61d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269a8fd",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036227",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'../results/submission_tf_idf_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba88dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043dcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']\n",
    "\n",
    "final_C = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "C_param_range = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, random_state = 42, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in C_param_range:\n",
    "\n",
    "        model = LogisticRegression (C = g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    final_C.append(best_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ec8a5",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']\n",
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_train)\n",
    "\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression (C = final_C [counter])\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'../results/submission_tf_idf_log_reg_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7246",
   "metadata": {},
   "source": [
    "### Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cba4",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'../results/submission_count_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408644e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b87ee1a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
