{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "### Import\n",
    "Several libraries are required to perform a thorough analysis of the dataset. Each of these libraries will be imported and described below:\n",
    "\n",
    "#### Basic Libraries \n",
    "Import `numpy` and `pandas`.\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836013db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Datasets and Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Trying different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fafb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61100a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    accuracy = np.sum (predictions == actual) / len (predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567593f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967d71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160c31b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98318366",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mn_hyper_parameter:\n",
    "    def __init__(self, class_, alpha, fit_prior):\n",
    "        self.class_ = class_\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c247db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_hyperparameter:\n",
    "    def __init__(self, class_, c, max_iter):\n",
    "        self.class_ = class_\n",
    "        self.c = c\n",
    "        self.max_iter = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f9a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0ad45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0caa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ebad703",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [1, 12, 15],\n",
    "        'classifier__max_iter': [600, 1800, 3000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b3b66",
   "metadata": {},
   "source": [
    "### Classifier Chain: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07effd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cc = ClassifierChain(\n",
    "    classifier = LogisticRegression(max_iter = 300, C = 10),\n",
    ")\n",
    "\n",
    "lr_cc.fit(count_train, y_train)\n",
    "\n",
    "predictions = lr_cc.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "predictions = lr_cc.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_class_lr_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bc68f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67034465",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cc_tuned = RandomizedSearchCV(ClassifierChain(), parameters_lr, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bef7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lr_cc_tuned.fit(count_train, y_train)\n",
    "print (lr_cc_tuned.best_params_, lr_cc_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_cc_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_cc_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_class_lr_cc_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc = ClassifierChain(\n",
    "    classifier = MultinomialNB(),\n",
    "    max_iter = 300,\n",
    "    alpha = 1.0,\n",
    "    fit_prior = True\n",
    ")\n",
    "\n",
    "mn_cc.fit(count_train, y_train)\n",
    "\n",
    "predictions = mn_cc.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_class_mn_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tuned = RandomizedSearchCV(ClassifierChain(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_cc_tuned.fit(count_train, y_train)\n",
    "print (mn_cc_tuned.best_params_, mn_cc_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a93384",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ab6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_class_mn_cc_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f016da",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acab8b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d84e29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf417a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           0             0        0       0       0              0\n",
       "4           0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      0             0        0       0       0              0\n",
       "159567      0             0        0       0       0              0\n",
       "159568      0             0        0       0       0              0\n",
       "159569      0             0        0       0       0              0\n",
       "159570      0             0        0       0       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c918d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681a52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lr = BinaryRelevance(classifier = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4721df04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f92a429b6f9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbinary_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0my_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             classifier.fit(self._ensure_input_format(\n\u001b[0m\u001b[0;32m    162\u001b[0m                 X), self._ensure_output_format(y_subset))\n\u001b[0;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1407\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    756\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[0;32m    757\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[1;32m--> 758\u001b[1;33m             opt_res = optimize.minimize(\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                   **options)\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[1;34m(w, X, y)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0myz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "binary_lr.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_lr.predict(count_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = binary_lr.predict(count_test)\n",
    "predictions = predictions.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_lr_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921bad",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf9214d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-03981fa49798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_br_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryRelevance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'parameters_lr' is not defined"
     ]
    }
   ],
   "source": [
    "lr_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_lr, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66df22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lr_br_tuned.fit(count_train, y_train)\n",
    "print (lr_br_tuned.best_params_, lr_br_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8676eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_br_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb442d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_br_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_lr_count_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633710",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d94bf",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4cd9",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f05119",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn = BinaryRelevance(classifier = MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_mn.predict(count_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = binary_mn.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv('results/submission_binary_mn_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89804b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6560507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "849ff4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-41a99b6b9a99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmn_br_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmn_br_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "# train\n",
    "mn_br_tuned.fit(count_train, y_train)\n",
    "print (mn_br_tuned.best_params_, v.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45700c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_br_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_mn_count_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe9a75",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf324509",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc574c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tfidf_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a8714",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cdd89",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d69379",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2508e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab42516",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24309156",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ea51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(count_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(count_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "sample_submission.to_csv(f'results/submission_count_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6d970",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70786f3",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269a8fd",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036227",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba88dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'C' : [1, 12, 15],\n",
    "    'max_iter' :[600, 1800, 3000, 4200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d8f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ec8a5",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7246",
   "metadata": {},
   "source": [
    "### Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cba4",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408644e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c943f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'C' : [1, 12, 15],\n",
    "    'max_iter' :[600, 1800, 3000, 4200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05384cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87ee1a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f612c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg_tuned.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
