{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "### Import\n",
    "Several libraries are required to perform a thorough analysis of the dataset. Each of these libraries will be imported and described below:\n",
    "\n",
    "#### Basic Libraries \n",
    "Import `numpy` and `pandas`.\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fb8d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "836013db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Datasets and Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Trying different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fafb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61100a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    accuracy = np.sum (predictions == actual) / len (predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567593f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "967d71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160c31b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98318366",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "176302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mn_hyper_parameter:\n",
    "    def __init__(self, class_, alpha, fit_prior):\n",
    "        self.class_ = class_\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c247db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_hyperparameter:\n",
    "    def __init__(self, class_, c, max_iter):\n",
    "        self.class_ = class_\n",
    "        self.c = c\n",
    "        self.max_iter = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d951b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under my userna...\n",
       "1         d aww he matches this background colour i am s...\n",
       "2         hey man i am really not trying to edit war it ...\n",
       "3         more i can not make any real suggestions on im...\n",
       "4         you sir are my hero any chance you remember wh...\n",
       "                                ...                        \n",
       "159566    and for the second time of asking when your vi...\n",
       "159567    you should be ashamed of yourself that is a ho...\n",
       "159568    spitzer umm theres no actual article for prost...\n",
       "159569    and it looks like it was actually you who put ...\n",
       "159570    and i really do not think you understand i cam...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "613bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8f9a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0ad45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0caa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ebad703",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [1, 12, 15],\n",
    "        'classifier__max_iter': [600, 1800, 3000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbaaca",
   "metadata": {},
   "source": [
    "### OneVsRestClassifier Classifier: Logistic Regression using Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e08e7337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=3000))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "lr_oc = OneVsRestClassifier(LogisticRegression(max_iter = 3000))\n",
    "lr_oc.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24180595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic            96.740009\n",
      "severe_toxic     99.272424\n",
      "obscene          98.464633\n",
      "threat           99.805729\n",
      "insult           97.465705\n",
      "identity_hate    99.340106\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc.predict(count_train)\n",
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3393e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oc.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5a42f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_oc_lr_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a9a1f",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression using TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mo = MultiOutputClassifier(LogisticRegression(max_iter = 3000))\n",
    "lr_mo.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ededd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_mo.predict(count_train)\n",
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_mo.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ff4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_mo_lr_tfidf.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c8000",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes using Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559daa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_mo = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9795f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_mo.predict(count_train)\n",
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_mo.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99061ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_mo_mn_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21060099",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression using Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ceb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mo = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_mo.predict(count_train)\n",
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa08468",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_mo.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_mo_lr_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7149f3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfbe2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [\n",
    "    {\n",
    "        'estimator__C': [1, 12, 15],\n",
    "        'estimator__max_iter': [600, 1800, 3000],\n",
    "        'estimator__class_weight' : ['balanced', None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cce41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mo_tuned = RandomizedSearchCV(MultiOutputClassifier(LogisticRegression ()), parameters_lr_mo, scoring = 'accuracy', n_jobs = 3, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mo_tuned.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_mo_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3032b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343389d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_mo_tuned.predict(count_test)\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_count_lr_mo_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ad224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_mo_tuned.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 10000)\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc = ClassifierChain(\n",
    "    classifier = MultinomialNB(alpha = 1.0, fit_prior = True),\n",
    ")\n",
    "\n",
    "mn_cc.fit(count_train, y_train)\n",
    "\n",
    "predictions = mn_cc.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_count_mn_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tuned = RandomizedSearchCV(ClassifierChain(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_cc_tuned.fit(count_train, y_train)\n",
    "print (mn_cc_tuned.best_params_, mn_cc_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a93384",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ab6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_count_mn_cc_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46353cfd",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade5aa6",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbcabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7371a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mn_cc = ClassifierChain(\n",
    "    classifier = MultinomialNB(alpha = 1.0, fit_prior = True),\n",
    ")\n",
    "\n",
    "mn_cc.fit(tf_idf_train, y_train)\n",
    "\n",
    "predictions = mn_cc.predict(tf_idf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ee1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_cc.predict(tf_idf_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_tfidf_mn_cc.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a8c8e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ef089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9e5b2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c1539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f016da",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acab8b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf417a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c918d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lr = BinaryRelevance(classifier = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lr.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_lr.predict(count_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = binary_lr.predict(count_test)\n",
    "predictions = predictions.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_lr_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921bad",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9214d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_lr, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66df22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lr_br_tuned.fit(count_train, y_train)\n",
    "print (lr_br_tuned.best_params_, lr_br_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8676eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_br_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb442d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = lr_br_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_lr_count_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633710",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b35262",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46acf7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb884fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn = BinaryRelevance(classifier = MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd28cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_mn.predict(tf_idf_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b995c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = binary_mn.predict(tf_idf_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv('results/submission_binary_mn_tfidf.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e32a6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_br_tuned.fit(tf_idf_train, y_train)\n",
    "print (mn_br_tuned.best_params_, v.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247114a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tuned.predict(tf_idf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886182ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_br_tuned.predict(tf_idf_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_mn_tfidf_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c3b8",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0528ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167d94bf",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4cd9",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features = 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f05119",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn = BinaryRelevance(classifier = MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mn.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = binary_mn.predict(count_train)\n",
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id']\n",
    "counter = 0\n",
    "\n",
    "predictions = binary_mn.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv('results/submission_binary_mn_count.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89804b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tuned = RandomizedSearchCV(BinaryRelevance(), parameters_mn, scoring = 'accuracy', n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ff4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "mn_br_tuned.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mn_br_tuned.best_params_, mn_br_tuned.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tuned.predict(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45700c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "predictions = mn_br_tuned.predict(count_test)\n",
    "predictions = predictions.todense()\n",
    "for i in range (6):\n",
    "    sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "sample_submission.to_csv(f'results/submission_binary_mn_count_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe9a75",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf324509",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc574c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tfidf_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a8714",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cdd89",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d69379",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2508e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab42516",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24309156",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ea51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(count_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(count_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "sample_submission.to_csv(f'results/submission_count_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6d970",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70786f3",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269a8fd",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036227",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba88dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'C' : [1, 12, 15],\n",
    "    'max_iter' :[600, 1800, 3000, 4200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d8f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ec8a5",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7246",
   "metadata": {},
   "source": [
    "### Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cba4",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408644e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c943f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{\n",
    "    'C' : [1, 12, 15],\n",
    "    'max_iter' :[600, 1800, 3000, 4200]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05384cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(hyperparameters):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87ee1a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f612c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg_tuned.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
