{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496f3024",
   "metadata": {},
   "source": [
    "# You're Toxic, I'm Slippin' Under: Toxic Comment Classification Challenge\n",
    "\n",
    "#### STINTSY S13 Group 8\n",
    "- VICENTE, Francheska Josefa\n",
    "- VISTA, Sophia Danielle S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c582a",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first.\n",
    "\n",
    "### Import\n",
    "Several libraries are required to perform a thorough analysis of the dataset. Each of these libraries will be imported and described below:\n",
    "\n",
    "#### Basic Libraries \n",
    "Import `numpy` and `pandas`.\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6255319",
   "metadata": {},
   "source": [
    "#### Natural Language Processing Libraries \n",
    "- `re` is a module that allows the use of regular expressions\n",
    "- `nltk` provides functions for processing text data\n",
    "- `stopwords` is a corpus from NLTK, which includes a compiled list of stopwords\n",
    "- `Counter` is from Python's `collections` module, which is helpful for tokenization\n",
    "- `string` contains functions for string operations\n",
    "- `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features \n",
    "- `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce303532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c181e3",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries\n",
    "The following code block can be used to install **scikit-multilearn** without restarting Jupyter Notebook. The `sys` module is used to access the *executable* function of the interpreter, which would run the installation of scikit-multilearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850d2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a154c",
   "metadata": {},
   "source": [
    "The following libraries are multi-label classification modules that would allow the usage of one model that can classify one instance as more than one class.\n",
    "- `ClassifierChain` chains binary classifiers in a way that its predictions are dependent on the earlier classes\n",
    "- `BinaryRelevance` uses binary classifiers to classify the classes independently\n",
    "- `MultiOutputClassifier` fits one classifier per target class \n",
    "- `OneVsRestClassifier` fits one class against the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea567ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7f3",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "- `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees\n",
    "- `GradientBoostingClassifier` is a class under the ensemble module that optimizes arbitrary differentiable loss functions\n",
    "- `AdaBoostClassifier` is a class under the ensemble module that implements AdaBoost-SAMME\n",
    "- `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "- `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "- `SGDClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e6642",
   "metadata": {},
   "source": [
    "Meanwhile, the following classes are used for hyperparameter tuning.\n",
    "- `ParameterGrid` is a class that allows the iteration over different combinations of parameter values \n",
    "- `GridSearchCV` is a cross-validation class that allows the exhaustive search over all possible combinations of hyperparameter values\n",
    "- `RandomizedSearchCV` is a cross-validation class that allows a random search over some possible combinations of hyperparameter values\n",
    "- `train_test_split` divides the dataset into two subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f9c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688e12a",
   "metadata": {},
   "source": [
    "And lastly, these classes computes different scores about how well a model works.\n",
    "- `log_loss` computes the Logistic loss given the true values and the predicted values\n",
    "- `f1_score` computes the balanced F-score by comparing the actual classes and the predicted classes\n",
    "- `accuracy_score` computes the accuracy by determining how many classes were correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2710dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878a641",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4ba0e",
   "metadata": {},
   "source": [
    "### Datasets and Files\n",
    "From the previous notebook, we would be loading the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8424525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_data/cleaned_train.csv')\n",
    "test = pd.read_csv('cleaned_data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478728",
   "metadata": {},
   "source": [
    "## Trying different Models\n",
    "To determine which model would be best for the task, we would be trying different feature extraction methods, models, and hyperparameters. \n",
    "\n",
    "However, before we can utilize the cleaned data, we would need to convert the values in the `comment_text` column into either  \"str, unicode or file objects\", according to the documentation of TF-IDF vectorizer and Count Vectorixer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d03b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test ['comment_text'] = test ['comment_text'].apply(lambda x: np.str_(x))\n",
    "train ['comment_text'] = train ['comment_text'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7c6cd",
   "metadata": {},
   "source": [
    "Then, we would be declaring our **X_train**, **y_train**, and **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84367b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed343812",
   "metadata": {},
   "source": [
    "Afterwards, we would be declaring the different classes that our model would need to predict. This can be found in the **train** data's column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c232fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069a236",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mn_hyper_parameter:\n",
    "    def __init__(self, class_, alpha, fit_prior):\n",
    "        self.class_ = class_\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c247db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_hyperparameter:\n",
    "    def __init__(self, class_, c, max_iter):\n",
    "        self.class_ = class_\n",
    "        self.c = c\n",
    "        self.max_iter = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fafb6",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61100a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    accuracy = np.sum (predictions == actual) / len (predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1aeb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv(predictions, filename):\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    sample_submission ['id'] = test ['id'] \n",
    "    counter = 0\n",
    "\n",
    "    for i in range (6):\n",
    "        sample_submission[classes [i]] = predictions[:, i : i + 1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a0a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_csv_multiclass (predictions, filename):\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    sample_submission ['id'] = test ['id'] \n",
    "    counter = 0\n",
    "\n",
    "    for i in range (6):\n",
    "        temp = list(zip(*predictions[i]))\n",
    "        sample_submission[classes [i]] = temp[1]\n",
    "\n",
    "    sample_submission.to_csv(f'results/' + filename + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec21a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model):\n",
    "    predictions_count = np.zeros((len(test), len(classes)))\n",
    "    predictions_tfidf = np.zeros((len(test), len(classes)))\n",
    "\n",
    "    for i in range(6):\n",
    "        print('Fitting', classes[i] + '...')\n",
    "\n",
    "        mdl = model\n",
    "        mdl.fit(count_train, y_train[classes[i]])\n",
    "        print('Count Vectors:', compute_accuracy(mdl.predict(count_train), y_train[classes[i]]))\n",
    "        predictions_count[:,i] = mdl.predict_proba(count_test)[:,1]\n",
    "\n",
    "        mdl = model\n",
    "        mdl.fit(tfidf_train, y_train[classes[i]])\n",
    "        print('TF-IDF Vectors:', compute_accuracy(mdl.predict(tfidf_train), y_train[classes[i]]))\n",
    "        predictions_tfidf[:,i] = mdl.predict_proba(tfidf_test)[:,1]\n",
    "    \n",
    "    return predictions_count, predictions_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beed1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_models(model):\n",
    "    predictions_count_tuned = np.zeros((len(test), len(classes)))\n",
    "    predictions_tfidf_tuned = np.zeros((len(test), len(classes)))\n",
    "\n",
    "    for i in range(6):\n",
    "        print('Fitting', classes[i] + '...')\n",
    "\n",
    "        mdl_tuned = model\n",
    "        mdl_tuned.fit(count_train, y_train[classes[i]])\n",
    "        print('Count Vectors:', compute_accuracy(mdl_tuned.predict(count_train), y_train[classes[i]]), mdl_tuned.best_params_)\n",
    "        predictions_count_tuned[:,i] = mdl_tuned.predict_proba(count_test)[:,1]\n",
    "\n",
    "        mdl_tuned = model\n",
    "        mdl_tuned.fit(tfidf_train, y_train[classes[i]])\n",
    "        print('TF-IDF Vectors:', compute_accuracy(mdl_tuned.predict(tfidf_train), y_train[classes[i]]), mdl_tuned.best_params_)\n",
    "        predictions_tfidf_tuned[:,i] = mdl_tuned.predict_proba(tfidf_test)[:,1]\n",
    "    \n",
    "    return predictions_count_tuned, predictions_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98318366",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3df21c9",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cdca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c816521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under my userna...\n",
       "1         d aww he matches this background colour i am s...\n",
       "2         hey man i am really not trying to edit war it ...\n",
       "3         more i can not make any real suggestions on im...\n",
       "4         you sir are my hero any chance you remember wh...\n",
       "                                ...                        \n",
       "159566    and for the second time of asking when your vi...\n",
       "159567    you should be ashamed of yourself that is a ho...\n",
       "159568    spitzer umm theres no actual article for prost...\n",
       "159569    and it looks like it was actually you who put ...\n",
       "159570    and i really do not think you understand i cam...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613bf342",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2367327ac2e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[0;32m    218\u001b[0m                              \"unicode string.\")\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0085708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_5000 = TfidfVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff713513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_5000 = tfidf_vectorizer_5000.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_5000 = tfidf_vectorizer_5000.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0ad45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0caa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ebad703",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "327ed991",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_5000 = CountVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d460312",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train_5000 = count_vectorizer_5000.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "433d031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tes_5000t = count_vectorizer_5000.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce26671",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a58b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_multi = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2442034",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_multi = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [1, 12, 15],\n",
    "        'classifier__max_iter': [600, 1800, 3000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da924612",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mn_mo = [\n",
    "    {\n",
    "        'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'estimator__fit_prior': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "153902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr_mo = [\n",
    "    {\n",
    "        'estimator__C': [1, 12, 15],\n",
    "        'estimator__max_iter': [600, 1800, 3000],\n",
    "        'estimator__class_weight' : ['balanced', None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee4b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [\n",
    "    {\n",
    "        'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "        'fit_prior' : [False, True]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c75638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = [\n",
    "    {\n",
    "        'C' : [1, 12, 15],\n",
    "        'max_iter' :[600, 1800, 3000, 4200]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "865abbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = [\n",
    "    {\n",
    "        'n_estimators' : [500, 1000, 1500],\n",
    "        'min_samples_split' : [2, 10, 20],\n",
    "        'max_leaf_nodes' : [15, 20, 25],\n",
    "        'min_samples_leaf' : [1, 5, 10],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d6f2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bda0dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 97.1943523572579\n",
      "TF-IDF Vectors: 96.23553151888501\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.19596919239711\n",
      "TF-IDF Vectors: 99.12578100030707\n",
      "Fitting obscene...\n",
      "Count Vectors: 98.13750618846782\n",
      "TF-IDF Vectors: 97.95514222509102\n",
      "Fitting threat...\n",
      "Count Vectors: 99.79632890688158\n",
      "TF-IDF Vectors: 99.73366087822976\n",
      "Fitting insult...\n",
      "Count Vectors: 97.40241021238195\n",
      "TF-IDF Vectors: 97.39551672923025\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 99.27681094935797\n",
      "TF-IDF Vectors: 99.24109017302642\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "predictions_lr_count, predictions_lr_tfidf = train_models(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca9c3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_count, 'submission_lr_count')\n",
    "to_submission_csv(predictions_lr_tfidf, 'submission_lr_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c974dc",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count</td>\n",
    "    <td class=\"tg-baqh\">0.93926</td>\n",
    "    <td class=\"tg-baqh\">0.94248</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.97391</td>\n",
    "    <td class=\"tg-baqh\">0.97376</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebed0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40056ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tuned = GridSearchCV(LogisticRegression(n_jobs=-1), parameters_lr, scoring='f1', verbose=2)\n",
    "predictions_lr_count_tuned, predictions_lr_tfidf_tuned = tune_and_train_models(lr_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448f00b",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_lr_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "    <td class=\"tg-baqh\">N/A</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5546",
   "metadata": {},
   "source": [
    "### Naive Bayes: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16aa7cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 95.13696097661855\n",
      "TF-IDF Vectors: 92.36828747078103\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.641983819115\n",
      "TF-IDF Vectors: 98.99104473870565\n",
      "Fitting obscene...\n",
      "Count Vectors: 96.70867513520626\n",
      "TF-IDF Vectors: 95.38449968979326\n",
      "Fitting threat...\n",
      "Count Vectors: 99.55505699657206\n",
      "TF-IDF Vectors: 99.6973134216117\n",
      "Fitting insult...\n",
      "Count Vectors: 96.46301646289113\n",
      "TF-IDF Vectors: 95.35629907689994\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 98.77233331871079\n",
      "TF-IDF Vectors: 99.11074067343063\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "predictions_mnb_count, predictions_mnb_tfidf = train_models(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8eee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_count, 'submission_mnb_count')\n",
    "to_submission_csv(predictions_mnb_tfidf, 'submission_mnb_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaedef",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count</td>\n",
    "    <td class=\"tg-baqh\">0.84551</td>\n",
    "    <td class=\"tg-baqh\">0.85581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf</td>\n",
    "    <td class=\"tg-baqh\">0.82510</td>\n",
    "    <td class=\"tg-baqh\">0.83586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e45539",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c0eefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnb = [{\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'fit_prior' : [False, True]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecf109d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 95.13696097661855 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 97.48262528905627 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 98.72031885492977 {'alpha': 0.001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.42157409554368 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting obscene...\n",
      "Count Vectors: 96.70867513520626 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 98.62067668937338 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting threat...\n",
      "Count Vectors: 99.31315840597603 {'alpha': 0.0001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.87403726240983 {'alpha': 1e-05, 'fit_prior': True}\n",
      "Fitting insult...\n",
      "Count Vectors: 96.46301646289113 {'alpha': 1, 'fit_prior': True}\n",
      "TF-IDF Vectors: 98.40384531023808 {'alpha': 0.001, 'fit_prior': True}\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 98.69337160260949 {'alpha': 0.0001, 'fit_prior': True}\n",
      "TF-IDF Vectors: 99.56759060230243 {'alpha': 0.001, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "mnb_tuned = GridSearchCV(MultinomialNB(), parameters_mnb, scoring='f1')\n",
    "predictions_mnb_count_tuned, predictions_mnb_tfidf_tuned = tune_and_train_models(mnb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9017ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_count_tuned, 'submission_mnb_count_tuned')\n",
    "to_submission_csv(predictions_mnb_tfidf_tuned, 'submission_mnb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3ce89",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.88069</td>\n",
    "    <td class=\"tg-baqh\">0.88388</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_mnb_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.91455</td>\n",
    "    <td class=\"tg-baqh\">0.91739</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b957",
   "metadata": {},
   "source": [
    "### Ensemble Models: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25c706c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 99.97869287025839\n",
      "TF-IDF Vectors: 99.97743950968534\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.98558635341008\n",
      "TF-IDF Vectors: 99.97493278853928\n",
      "Fitting obscene...\n",
      "Count Vectors: 99.98370631255052\n",
      "TF-IDF Vectors: 99.9793195505449\n",
      "Fitting threat...\n",
      "Count Vectors: 99.99435987742133\n",
      "TF-IDF Vectors: 99.99373319713482\n",
      "Fitting insult...\n",
      "Count Vectors: 99.96991934624712\n",
      "TF-IDF Vectors: 99.9655325842415\n",
      "Fitting identity_hate...\n",
      "Count Vectors: 99.9931065168483\n",
      "TF-IDF Vectors: 99.98934643512919\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "predictions_rf_count, predictions_rf_tfidf = train_models(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aa6ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count, 'submission_rf_count')\n",
    "to_submission_csv(predictions_rf_tfidf, 'submission_rf_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058de190",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.96735, 0.96784], 'public': [0.96725, 0.96710]}, \n",
    "    index=['submission_rf_count.csv', 'submission_rf_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd252b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1223467",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 20, 30],\n",
    "    'min_samples_split' : [2, 4, 6, 10, 15, 20],\n",
    "    'max_leaf_nodes' : [3, 5, 10, 20, 50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d81585ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 90.41680505856327 {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 90.4180584191363 {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Fitting severe_toxic...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 99.00044494300343 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 99.00044494300343 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting obscene...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 94.70580493949402 {'n_estimators': 500, 'min_samples_split': 2, 'max_leaf_nodes': 50, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 94.7051782592075 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting threat...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 99.70170018361732 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 99.70044682304429 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting insult...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 95.06363938309592 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 95.06363938309592 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting identity_hate...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Count Vectors: 99.11951419744189 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "TF-IDF Vectors: 99.11951419744189 {'n_estimators': 200, 'min_samples_split': 2, 'max_leaf_nodes': 20, 'max_depth': 20, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "rf_tuned = RandomizedSearchCV(RandomForestClassifier(n_jobs=-1), parameters_rf, scoring='f1', random_state=8, verbose=1)\n",
    "predictions_rf_count_tuned, predictions_rf_tfidf_tuned = tune_and_train_models(rf_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dabb22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6a8aa",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\"></th>\n",
    "    <th class=\"tg-1wig\">private</th>\n",
    "    <th class=\"tg-1wig\">public</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_count_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.96232</td>\n",
    "    <td class=\"tg-baqh\">0.96285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">submission_rf_tfidf_tuned</td>\n",
    "    <td class=\"tg-baqh\">0.95937</td>\n",
    "    <td class=\"tg-baqh\">0.95826</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6d61c",
   "metadata": {},
   "source": [
    "### Ensemble Models: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "predictions_gbc_count, predictions_gbc_tfidf = train_models(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count, 'submission_gbc_count')\n",
    "to_submission_csv(predictions_gbc_tfidf, 'submission_gbc_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.90663, 0.92569], 'public': [0.92024, 0.93239]}, \n",
    "    index=['submission_gbc_count.csv', 'submission_gbc_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83bea7",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gbc = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_tuned = RandomizedSearchCV(GradientBoostingClassifier(), parameters_gbc, scoring='accuracy', random_state=8, verbose=2)\n",
    "predictions_gbc_count_tuned, predictions_gbc_tfidf_tuned = tune_and_train_models(gbc_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_gbc_count_tuned, 'submission_gbc_count_tuned')\n",
    "to_submission_csv(predictions_gbc_tfidf_tuned, 'submission_gbc_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f4fd",
   "metadata": {},
   "source": [
    "### Ensemble Models: XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba086e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(eval_metric='logloss', verbosity=0, use_label_encoder=False)\n",
    "predictions_xgb_count, predictions_xgb_tfidf = train_models(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count, 'submission_xgb_count')\n",
    "to_submission_csv(predictions_xgb_tfidf, 'submission_xgb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgb = [{\n",
    "    'n_estimators' : [50, 100, 250],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 1.2],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc921ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb_tuned = GridSearchCV(xgboost.XGBClassifier(eval_metric='logloss', verbosity=0, use_label_encoder=False), parameters_xgb, scoring='f1')\n",
    "predictions_xgb_count_tuned, predictions_xgb_tfidf_tuned = tune_and_train_models(xgb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea054",
   "metadata": {},
   "source": [
    "### Ensemble Models: AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ad694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier()\n",
    "predictions_adb_count, predictions_adb_tfidf = train_models(adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a51c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93539, 0.93830], 'public': [0.94218, 0.94145]}, \n",
    "    index=['submission_adb_count.csv', 'submission_adb_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d417eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_adb = {\n",
    "    'n_estimators' : [10, 25, 50, 100, 250],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_tuned = GridSearchCV(AdaBoostClassifier(), parameters_adb, scoring='accuracy')\n",
    "predictions_adb_count_tuned, predictions_adb_tfidf_tuned = tune_and_train_models(adb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_xgb_count_tuned, 'submission_xgb_count_tuned')\n",
    "to_submission_csv(predictions_xgb_tfidf_tuned, 'submission_xgb_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803b2a5",
   "metadata": {},
   "source": [
    "### Support Vector Machines: SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30717932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='log', n_jobs=-1)\n",
    "predictions_sgd_count, predictions_sgd_tfidf = train_models(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count, 'submission_sgd_count')\n",
    "to_submission_csv(predictions_sgd_tfidf, 'submission_sgd_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9417b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.92026, 0.95112], 'public': [0.92912, 0.95232]}, \n",
    "    index=['submission_sgd_count.csv', 'submission_sgd_tfidf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd2aa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86d719b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sgd = [{\n",
    "    'loss' : ['log', 'modified_huber'],\n",
    "    'alpha' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e5e602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "Count Vectors: 97.49139881306755 {'alpha': 1e-05, 'loss': 'log'}\n",
      "TF-IDF Vectors: 98.16570680136115 {'alpha': 1e-05, 'loss': 'modified_huber'}\n",
      "Fitting severe_toxic...\n",
      "Count Vectors: 99.08003333939124 {'alpha': 0.01, 'loss': 'log'}\n",
      "TF-IDF Vectors: 99.10760727199805 {'alpha': 1e-05, 'loss': 'log'}\n",
      "Fitting obscene...\n",
      "Count Vectors: 97.64681552412405 {'alpha': 1e-05, 'loss': 'log'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6a19d5243bca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msgd_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_sgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions_sgd_count_tuned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_sgd_tfidf_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtune_and_train_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_tuned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-ddbb18bf0bbc>\u001b[0m in \u001b[0;36mtune_and_train_models\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmdl_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TF-IDF Vectors:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredictions_tfidf_tuned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         \"\"\"\n\u001b[1;32m--> 729\u001b[1;33m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[0;32m    730\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[0m\u001b[0;32m    570\u001b[0m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                  max_iter=max_iter)\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             self._fit_binary(X, y, alpha=alpha, C=C,\n\u001b[0m\u001b[0;32m    527\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    581\u001b[0m                     learning_rate, max_iter):\n\u001b[0;32m    582\u001b[0m         \u001b[1;34m\"\"\"Fit a binary classifier on X and y. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         coef, intercept, n_iter_ = fit_binary(self, 1, X, y, alpha, C,\n\u001b[0m\u001b[0;32m    584\u001b[0m                                               \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m     coef, intercept, average_coef, average_intercept, n_iter_ = _plain_sgd(\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mpenalty_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgd_tuned = GridSearchCV(SGDClassifier(n_jobs=-1), parameters_sgd, scoring='accuracy')\n",
    "predictions_sgd_count_tuned, predictions_sgd_tfidf_tuned = tune_and_train_models(sgd_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_rf_count_tuned, 'submission_rf_count_tuned')\n",
    "to_submission_csv(predictions_rf_tfidf_tuned, 'submission_rf_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1fa56",
   "metadata": {},
   "source": [
    "### Ensemble Models: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4706a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting toxic...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5865            2.41m\n",
      "         2           0.5667            2.30m\n",
      "         3           0.5524            2.20m\n",
      "         4           0.5425            2.14m\n",
      "         5           0.5329            2.10m\n",
      "         6           0.5258            2.10m\n",
      "         7           0.5180            2.10m\n",
      "         8           0.5124            2.10m\n",
      "         9           0.5050            2.10m\n",
      "        10           0.5007            2.09m\n",
      "        11           0.4942            2.06m\n",
      "        12           0.4897            2.03m\n",
      "        13           0.4840            2.02m\n",
      "        14           0.4796            2.00m\n",
      "        15           0.4761            1.99m\n",
      "        16           0.4699            1.97m\n",
      "        17           0.4667            1.93m\n",
      "        18           0.4623            1.90m\n",
      "        19           0.4596            1.87m\n",
      "        20           0.4573            1.85m\n",
      "        21           0.4547            1.83m\n",
      "        22           0.4508            1.80m\n",
      "        23           0.4489            1.77m\n",
      "        24           0.4456            1.75m\n",
      "        25           0.4434            1.72m\n",
      "        26           0.4415            1.69m\n",
      "        27           0.4370            1.67m\n",
      "        28           0.4354            1.64m\n",
      "        29           0.4328            1.62m\n",
      "        30           0.4311            1.59m\n",
      "        31           0.4290            1.57m\n",
      "        32           0.4252            1.55m\n",
      "        33           0.4236            1.52m\n",
      "        34           0.4219            1.50m\n",
      "        35           0.4203            1.47m\n",
      "        36           0.4172            1.45m\n",
      "        37           0.4155            1.43m\n",
      "        38           0.4125            1.41m\n",
      "        39           0.4112            1.39m\n",
      "        40           0.4097            1.37m\n",
      "        41           0.4082            1.35m\n",
      "        42           0.4057            1.32m\n",
      "        43           0.4046            1.30m\n",
      "        44           0.4025            1.28m\n",
      "        45           0.4014            1.25m\n",
      "        46           0.4004            1.23m\n",
      "        47           0.3985            1.20m\n",
      "        48           0.3973            1.18m\n",
      "        49           0.3963            1.16m\n",
      "        50           0.3951            1.13m\n",
      "        51           0.3929            1.11m\n",
      "        52           0.3916            1.09m\n",
      "        53           0.3902            1.06m\n",
      "        54           0.3883            1.04m\n",
      "        55           0.3872            1.02m\n",
      "        56           0.3864           59.79s\n",
      "        57           0.3849           58.48s\n",
      "        58           0.3839           57.07s\n",
      "        59           0.3831           55.72s\n",
      "        60           0.3810           54.38s\n",
      "        61           0.3802           53.08s\n",
      "        62           0.3791           51.86s\n",
      "        63           0.3784           50.51s\n",
      "        64           0.3771           49.25s\n",
      "        65           0.3761           47.99s\n",
      "        66           0.3747           46.62s\n",
      "        67           0.3738           45.33s\n",
      "        68           0.3731           44.00s\n",
      "        69           0.3723           42.73s\n",
      "        70           0.3715           41.50s\n",
      "        71           0.3698           40.36s\n",
      "        72           0.3689           39.02s\n",
      "        73           0.3681           37.66s\n",
      "        74           0.3674           36.36s\n",
      "        75           0.3656           34.99s\n",
      "        76           0.3649           33.59s\n",
      "        77           0.3641           32.20s\n",
      "        78           0.3628           30.83s\n",
      "        79           0.3620           29.40s\n",
      "        80           0.3614           27.99s\n",
      "        81           0.3607           26.59s\n",
      "        82           0.3600           25.17s\n",
      "        83           0.3589           23.78s\n",
      "        84           0.3578           22.39s\n",
      "        85           0.3567           21.01s\n",
      "        86           0.3562           19.60s\n",
      "        87           0.3555           18.20s\n",
      "        88           0.3548           16.78s\n",
      "        89           0.3533           15.38s\n",
      "        90           0.3519           13.97s\n",
      "        91           0.3514           12.57s\n",
      "        92           0.3507           11.17s\n",
      "        93           0.3501            9.77s\n",
      "        94           0.3496            8.38s\n",
      "        95           0.3491            6.98s\n",
      "        96           0.3485            5.58s\n",
      "        97           0.3480            4.19s\n",
      "        98           0.3467            2.79s\n",
      "        99           0.3461            1.40s\n",
      "       100           0.3456            0.00s\n",
      "Count Vectors: 94.33731693102129\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5862            5.50m\n",
      "         2           0.5666            5.32m\n",
      "         3           0.5519            5.17m\n",
      "         4           0.5421            5.07m\n",
      "         5           0.5320            4.98m\n",
      "         6           0.5250            4.92m\n",
      "         7           0.5170            4.89m\n",
      "         8           0.5103            4.87m\n",
      "         9           0.5027            4.82m\n",
      "        10           0.4980            4.81m\n",
      "        11           0.4937            4.77m\n",
      "        12           0.4868            4.71m\n",
      "        13           0.4824            4.65m\n",
      "        14           0.4751            4.60m\n",
      "        15           0.4720            4.53m\n",
      "        16           0.4669            4.48m\n",
      "        17           0.4639            4.45m\n",
      "        18           0.4608            4.41m\n",
      "        19           0.4553            4.37m\n",
      "        20           0.4529            4.32m\n",
      "        21           0.4505            4.27m\n",
      "        22           0.4447            4.24m\n",
      "        23           0.4405            4.21m\n",
      "        24           0.4384            4.15m\n",
      "        25           0.4364            4.09m\n",
      "        26           0.4342            4.04m\n",
      "        27           0.4317            3.99m\n",
      "        28           0.4279            3.93m\n",
      "        29           0.4260            3.87m\n",
      "        30           0.4244            3.81m\n",
      "        31           0.4210            3.75m\n",
      "        32           0.4191            3.69m\n",
      "        33           0.4174            3.63m\n",
      "        34           0.4158            3.57m\n",
      "        35           0.4141            3.51m\n",
      "        36           0.4124            3.46m\n",
      "        37           0.4100            3.40m\n",
      "        38           0.4086            3.34m\n",
      "        39           0.4068            3.28m\n",
      "        40           0.4037            3.22m\n",
      "        41           0.4026            3.17m\n",
      "        42           0.4012            3.11m\n",
      "        43           0.3997            3.06m\n",
      "        44           0.3971            3.00m\n",
      "        45           0.3953            2.94m\n",
      "        46           0.3943            2.89m\n",
      "        47           0.3932            2.83m\n",
      "        48           0.3919            2.78m\n",
      "        49           0.3908            2.73m\n",
      "        50           0.3895            2.67m\n",
      "        51           0.3883            2.62m\n",
      "        52           0.3868            2.56m\n",
      "        53           0.3842            2.51m\n",
      "        54           0.3832            2.45m\n",
      "        55           0.3822            2.40m\n",
      "        56           0.3810            2.34m\n",
      "        57           0.3799            2.29m\n",
      "        58           0.3784            2.24m\n",
      "        59           0.3773            2.18m\n",
      "        60           0.3764            2.13m\n",
      "        61           0.3748            2.07m\n",
      "        62           0.3739            2.02m\n",
      "        63           0.3729            1.97m\n",
      "        64           0.3719            1.92m\n",
      "        65           0.3710            1.86m\n",
      "        66           0.3701            1.81m\n",
      "        67           0.3694            1.76m\n",
      "        68           0.3675            1.70m\n",
      "        69           0.3667            1.65m\n",
      "        70           0.3659            1.59m\n",
      "        71           0.3645            1.54m\n",
      "        72           0.3635            1.49m\n",
      "        73           0.3626            1.43m\n",
      "        74           0.3617            1.38m\n",
      "        75           0.3602            1.33m\n",
      "        76           0.3595            1.27m\n",
      "        77           0.3588            1.22m\n",
      "        78           0.3581            1.17m\n",
      "        79           0.3574            1.11m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        80           0.3567            1.06m\n",
      "        81           0.3558            1.01m\n",
      "        82           0.3552           57.21s\n",
      "        83           0.3539           54.05s\n",
      "        84           0.3532           50.87s\n",
      "        85           0.3525           47.67s\n",
      "        86           0.3515           44.48s\n",
      "        87           0.3508           41.30s\n",
      "        88           0.3501           38.12s\n",
      "        89           0.3496           34.93s\n",
      "        90           0.3489           31.75s\n",
      "        91           0.3483           28.57s\n",
      "        92           0.3477           25.39s\n",
      "        93           0.3469           22.21s\n",
      "        94           0.3458           19.03s\n",
      "        95           0.3450           15.86s\n",
      "        96           0.3444           12.68s\n",
      "        97           0.3438            9.51s\n",
      "        98           0.3429            6.34s\n",
      "        99           0.3424            3.17s\n",
      "       100           0.3417            0.00s\n",
      "TF-IDF Vectors: 94.43382569514512\n",
      "Fitting severe_toxic...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0812            2.26m\n",
      "         2           0.0793            2.12m\n",
      "         3           0.0778            2.05m\n",
      "         4           0.0764            2.02m\n",
      "         5           0.0749            2.00m\n",
      "         6           0.0740            1.99m\n",
      "         7           0.0730            1.97m\n",
      "         8           0.0718            1.94m\n",
      "         9           0.0710            1.92m\n",
      "        10           0.0702            1.91m\n",
      "        11           0.0694            1.88m\n",
      "        12           0.0689            1.87m\n",
      "        13           0.0681            1.85m\n",
      "        14           0.0675            1.83m\n",
      "        15           0.0670            1.81m\n",
      "        16           0.0663            1.78m\n",
      "        17           0.0659            1.76m\n",
      "        18           0.0655            1.74m\n",
      "        19           0.0652            1.72m\n",
      "        20           0.0649            1.70m\n",
      "        21           0.0645            1.68m\n",
      "        22           0.0642            1.65m\n",
      "        23           0.0638            1.63m\n",
      "        24           0.0635            1.61m\n",
      "        25           0.0632            1.59m\n",
      "        26           0.0629            1.57m\n",
      "        27           0.0623            1.54m\n",
      "        28           0.0620            1.52m\n",
      "        29           0.0619            1.50m\n",
      "        30           0.0616            1.47m\n",
      "        31           0.0614            1.45m\n",
      "        32           0.0610            1.43m\n",
      "        33           0.0608            1.41m\n",
      "        34           0.0605            1.39m\n",
      "        35           0.0604            1.37m\n",
      "        36           0.0601            1.35m\n",
      "        37           0.0595            1.33m\n",
      "        38           0.0592            1.30m\n",
      "        39           0.0589            1.28m\n",
      "        40           0.0588            1.26m\n",
      "        41           0.0585            1.24m\n",
      "        42           0.0582            1.22m\n",
      "        43           0.0580            1.19m\n",
      "        44           0.0579            1.17m\n",
      "        45           0.0577            1.15m\n",
      "        46           0.0572            1.12m\n",
      "        47           0.0570            1.10m\n",
      "        48           0.0568            1.07m\n",
      "        49           0.0563            1.05m\n",
      "        50           0.0562            1.03m\n",
      "        51           0.0561            1.01m\n",
      "        52           0.0560           58.96s\n",
      "        53           0.0558           57.59s\n",
      "        54           0.0557           56.25s\n",
      "        55           0.0556           54.88s\n",
      "        56           0.0552           53.54s\n",
      "        57           0.0550           52.22s\n",
      "        58           0.0549           50.97s\n",
      "        59           0.0548           49.67s\n",
      "        60           0.0547           48.33s\n",
      "        61           0.0546           47.06s\n",
      "        62           0.0544           45.73s\n",
      "        63           0.0543           44.49s\n",
      "        64           0.0542           43.20s\n",
      "        65           0.0541           41.93s\n",
      "        66           0.0538           40.60s\n",
      "        67           0.0536           39.31s\n",
      "        68           0.0534           38.01s\n",
      "        69           0.0532           36.74s\n",
      "        70           0.0530           35.46s\n",
      "        71           0.0528           34.20s\n",
      "        72           0.0525           32.95s\n",
      "        73           0.0524           31.73s\n",
      "        74           0.0522           30.53s\n",
      "        75           0.0520           29.29s\n",
      "        76           0.0518           28.06s\n",
      "        77           0.0516           26.83s\n",
      "        78           0.0515           25.64s\n",
      "        79           0.0512           24.42s\n",
      "        80           0.0510           23.22s\n",
      "        81           0.0508           22.01s\n",
      "        82           0.0506           20.81s\n",
      "        83           0.0504           19.62s\n",
      "        84           0.0502           18.43s\n",
      "        85           0.0500           17.28s\n",
      "        86           0.0498           16.10s\n",
      "        87           0.0496           14.92s\n",
      "        88           0.0494           13.76s\n",
      "        89           0.0493           12.59s\n",
      "        90           0.0491           11.44s\n",
      "        91           0.0489           10.30s\n",
      "        92           0.0487            9.15s\n",
      "        93           0.0485            7.99s\n",
      "        94           0.0483            6.84s\n",
      "        95           0.0481            5.69s\n",
      "        96           0.0480            4.55s\n",
      "        97           0.0478            3.41s\n",
      "        98           0.0476            2.27s\n",
      "        99           0.0474            1.13s\n",
      "       100           0.0473            0.00s\n",
      "Count Vectors: 99.21414292070614\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0824            5.27m\n",
      "         2           0.0800            5.12m\n",
      "         3           0.0783            5.04m\n",
      "         4           0.0764            4.97m\n",
      "         5           0.0752            4.90m\n",
      "         6           0.0738            4.86m\n",
      "         7           0.0726            4.81m\n",
      "         8           0.0716            4.76m\n",
      "         9           0.0707            4.70m\n",
      "        10           0.0699            4.67m\n",
      "        11           0.0690            4.62m\n",
      "        12           0.0684            4.62m\n",
      "        13           0.0678            4.58m\n",
      "        14           0.0672            4.54m\n",
      "        15           0.0665            4.51m\n",
      "        16           0.0660            4.47m\n",
      "        17           0.0654            4.48m\n",
      "        18           0.0650            4.46m\n",
      "        19           0.0647            4.42m\n",
      "        20           0.0644            4.44m\n",
      "        21           0.0640            4.40m\n",
      "        22           0.0634            4.37m\n",
      "        23           0.0631            4.31m\n",
      "        24           0.0627            4.24m\n",
      "        25           0.0625            4.18m\n",
      "        26           0.0622            4.11m\n",
      "        27           0.0619            4.05m\n",
      "        28           0.0616            3.98m\n",
      "        29           0.0610            3.92m\n",
      "        30           0.0608            3.86m\n",
      "        31           0.0605            3.79m\n",
      "        32           0.0602            3.73m\n",
      "        33           0.0600            3.67m\n",
      "        34           0.0596            3.61m\n",
      "        35           0.0593            3.55m\n",
      "        36           0.0591            3.50m\n",
      "        37           0.0589            3.45m\n",
      "        38           0.0586            3.39m\n",
      "        39           0.0584            3.34m\n",
      "        40           0.0581            3.29m\n",
      "        41           0.0578            3.25m\n",
      "        42           0.0577            3.20m\n",
      "        43           0.0575            3.14m\n",
      "        44           0.0573            3.08m\n",
      "        45           0.0571            3.03m\n",
      "        46           0.0569            2.97m\n",
      "        47           0.0566            2.91m\n",
      "        48           0.0563            2.86m\n",
      "        49           0.0558            2.80m\n",
      "        50           0.0555            2.74m\n",
      "        51           0.0554            2.69m\n",
      "        52           0.0551            2.63m\n",
      "        53           0.0550            2.57m\n",
      "        54           0.0548            2.52m\n",
      "        55           0.0546            2.46m\n",
      "        56           0.0543            2.41m\n",
      "        57           0.0542            2.36m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        58           0.0540            2.30m\n",
      "        59           0.0538            2.25m\n",
      "        60           0.0536            2.19m\n",
      "        61           0.0535            2.14m\n",
      "        62           0.0532            2.08m\n",
      "        63           0.0529            2.03m\n",
      "        64           0.0527            1.97m\n",
      "        65           0.0527            1.93m\n",
      "        66           0.0525            1.87m\n",
      "        67           0.0523            1.82m\n",
      "        68           0.0522            1.76m\n",
      "        69           0.0519            1.71m\n",
      "        70           0.0519            1.65m\n",
      "        71           0.0517            1.60m\n",
      "        72           0.0517            1.54m\n",
      "        73           0.0515            1.49m\n",
      "        74           0.0514            1.43m\n",
      "        75           0.0513            1.38m\n",
      "        76           0.0510            1.32m\n",
      "        77           0.0508            1.27m\n",
      "        78           0.0506            1.21m\n",
      "        79           0.0505            1.16m\n",
      "        80           0.0504            1.10m\n",
      "        81           0.0503            1.05m\n",
      "        82           0.0502           59.42s\n",
      "        83           0.0501           56.10s\n",
      "        84           0.0500           52.77s\n",
      "        85           0.0498           49.43s\n",
      "        86           0.0497           46.12s\n",
      "        87           0.0496           42.79s\n",
      "        88           0.0496           39.47s\n",
      "        89           0.0495           36.15s\n",
      "        90           0.0495           32.83s\n",
      "        91           0.0494           29.52s\n",
      "        92           0.0493           26.22s\n",
      "        93           0.0491           22.93s\n",
      "        94           0.0489           19.64s\n",
      "        95           0.0488           16.36s\n",
      "        96           0.0487           13.07s\n",
      "        97           0.0487            9.80s\n",
      "        98           0.0485            6.53s\n",
      "        99           0.0484            3.26s\n",
      "       100           0.0482            0.00s\n",
      "TF-IDF Vectors: 99.22730320672302\n",
      "Fitting obscene...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3395            2.26m\n",
      "         2           0.3203            2.15m\n",
      "         3           0.3052            2.09m\n",
      "         4           0.2932            2.08m\n",
      "         5           0.2856            2.04m\n",
      "         6           0.2794            2.01m\n",
      "         7           0.2719            1.98m\n",
      "         8           0.2669            1.96m\n",
      "         9           0.2622            1.93m\n",
      "        10           0.2580            1.91m\n",
      "        11           0.2536            1.89m\n",
      "        12           0.2506            1.87m\n",
      "        13           0.2458            1.85m\n",
      "        14           0.2431            1.83m\n",
      "        15           0.2406            1.81m\n",
      "        16           0.2375            1.78m\n",
      "        17           0.2354            1.76m\n",
      "        18           0.2329            1.75m\n",
      "        19           0.2309            1.72m\n",
      "        20           0.2290            1.71m\n",
      "        21           0.2273            1.68m\n",
      "        22           0.2238            1.67m\n",
      "        23           0.2217            1.65m\n",
      "        24           0.2202            1.63m\n",
      "        25           0.2184            1.61m\n",
      "        26           0.2171            1.59m\n",
      "        27           0.2139            1.57m\n",
      "        28           0.2119            1.55m\n",
      "        29           0.2100            1.52m\n",
      "        30           0.2076            1.51m\n",
      "        31           0.2066            1.48m\n",
      "        32           0.2050            1.46m\n",
      "        33           0.2037            1.44m\n",
      "        34           0.2018            1.42m\n",
      "        35           0.2005            1.40m\n",
      "        36           0.1996            1.38m\n",
      "        37           0.1987            1.36m\n",
      "        38           0.1974            1.34m\n",
      "        39           0.1953            1.32m\n",
      "        40           0.1945            1.30m\n",
      "        41           0.1938            1.27m\n",
      "        42           0.1926            1.25m\n",
      "        43           0.1911            1.23m\n",
      "        44           0.1902            1.21m\n",
      "        45           0.1895            1.19m\n",
      "        46           0.1885            1.17m\n",
      "        47           0.1879            1.14m\n",
      "        48           0.1868            1.12m\n",
      "        49           0.1853            1.10m\n",
      "        50           0.1846            1.08m\n",
      "        51           0.1840            1.06m\n",
      "        52           0.1833            1.04m\n",
      "        53           0.1820            1.02m\n",
      "        54           0.1813           59.68s\n",
      "        55           0.1807           58.34s\n",
      "        56           0.1799           57.07s\n",
      "        57           0.1794           55.76s\n",
      "        58           0.1786           54.42s\n",
      "        59           0.1778           53.12s\n",
      "        60           0.1773           51.84s\n",
      "        61           0.1762           50.52s\n",
      "        62           0.1756           49.23s\n",
      "        63           0.1750           47.92s\n",
      "        64           0.1745           46.60s\n",
      "        65           0.1739           45.30s\n",
      "        66           0.1734           44.05s\n",
      "        67           0.1727           42.74s\n",
      "        68           0.1719           41.45s\n",
      "        69           0.1709           40.16s\n",
      "        70           0.1704           38.90s\n",
      "        71           0.1699           37.58s\n",
      "        72           0.1694           36.29s\n",
      "        73           0.1687           35.02s\n",
      "        74           0.1678           33.73s\n",
      "        75           0.1672           32.45s\n",
      "        76           0.1667           31.16s\n",
      "        77           0.1663           29.85s\n",
      "        78           0.1659           28.55s\n",
      "        79           0.1655           27.26s\n",
      "        80           0.1648           25.96s\n",
      "        81           0.1644           24.66s\n",
      "        82           0.1639           23.37s\n",
      "        83           0.1635           22.06s\n",
      "        84           0.1630           20.76s\n",
      "        85           0.1622           19.48s\n",
      "        86           0.1617           18.19s\n",
      "        87           0.1614           16.88s\n",
      "        88           0.1611           15.59s\n",
      "        89           0.1607           14.29s\n",
      "        90           0.1602           12.99s\n",
      "        91           0.1597           11.70s\n",
      "        92           0.1593           10.41s\n",
      "        93           0.1588            9.10s\n",
      "        94           0.1584            7.80s\n",
      "        95           0.1580            6.50s\n",
      "        96           0.1577            5.20s\n",
      "        97           0.1572            3.90s\n",
      "        98           0.1565            2.60s\n",
      "        99           0.1561            1.30s\n",
      "       100           0.1557            0.00s\n",
      "Count Vectors: 97.60106786320823\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3394            5.25m\n",
      "         2           0.3197            5.12m\n",
      "         3           0.3038            5.04m\n",
      "         4           0.2922            4.97m\n",
      "         5           0.2847            4.92m\n",
      "         6           0.2784            4.86m\n",
      "         7           0.2723            4.81m\n",
      "         8           0.2650            4.76m\n",
      "         9           0.2610            4.70m\n",
      "        10           0.2570            4.65m\n",
      "        11           0.2529            4.60m\n",
      "        12           0.2489            4.55m\n",
      "        13           0.2449            4.50m\n",
      "        14           0.2424            4.45m\n",
      "        15           0.2394            4.39m\n",
      "        16           0.2364            4.35m\n",
      "        17           0.2341            4.30m\n",
      "        18           0.2321            4.25m\n",
      "        19           0.2296            4.19m\n",
      "        20           0.2278            4.14m\n",
      "        21           0.2260            4.09m\n",
      "        22           0.2236            4.04m\n",
      "        23           0.2216            3.99m\n",
      "        24           0.2179            3.94m\n",
      "        25           0.2158            3.89m\n",
      "        26           0.2144            3.84m\n",
      "        27           0.2130            3.78m\n",
      "        28           0.2108            3.73m\n",
      "        29           0.2081            3.68m\n",
      "        30           0.2064            3.63m\n",
      "        31           0.2053            3.58m\n",
      "        32           0.2042            3.53m\n",
      "        33           0.2027            3.48m\n",
      "        34           0.2014            3.43m\n",
      "        35           0.2001            3.38m\n",
      "        36           0.1979            3.33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        37           0.1965            3.28m\n",
      "        38           0.1957            3.23m\n",
      "        39           0.1948            3.17m\n",
      "        40           0.1937            3.12m\n",
      "        41           0.1926            3.07m\n",
      "        42           0.1908            3.02m\n",
      "        43           0.1896            2.97m\n",
      "        44           0.1887            2.91m\n",
      "        45           0.1877            2.86m\n",
      "        46           0.1869            2.81m\n",
      "        47           0.1862            2.76m\n",
      "        48           0.1853            2.71m\n",
      "        49           0.1845            2.65m\n",
      "        50           0.1836            2.60m\n",
      "        51           0.1816            2.55m\n",
      "        52           0.1810            2.50m\n",
      "        53           0.1802            2.45m\n",
      "        54           0.1796            2.40m\n",
      "        55           0.1788            2.35m\n",
      "        56           0.1778            2.29m\n",
      "        57           0.1772            2.24m\n",
      "        58           0.1757            2.19m\n",
      "        59           0.1749            2.14m\n",
      "        60           0.1743            2.09m\n",
      "        61           0.1736            2.03m\n",
      "        62           0.1732            1.98m\n",
      "        63           0.1726            1.93m\n",
      "        64           0.1720            1.88m\n",
      "        65           0.1715            1.83m\n",
      "        66           0.1709            1.77m\n",
      "        67           0.1702            1.72m\n",
      "        68           0.1697            1.67m\n",
      "        69           0.1684            1.62m\n",
      "        70           0.1677            1.56m\n",
      "        71           0.1669            1.51m\n",
      "        72           0.1665            1.46m\n",
      "        73           0.1656            1.41m\n",
      "        74           0.1652            1.36m\n",
      "        75           0.1648            1.30m\n",
      "        76           0.1642            1.25m\n",
      "        77           0.1637            1.20m\n",
      "        78           0.1633            1.15m\n",
      "        79           0.1627            1.10m\n",
      "        80           0.1618            1.04m\n",
      "        81           0.1614           59.44s\n",
      "        82           0.1605           56.31s\n",
      "        83           0.1600           53.18s\n",
      "        84           0.1597           50.06s\n",
      "        85           0.1594           46.93s\n",
      "        86           0.1589           43.79s\n",
      "        87           0.1585           40.66s\n",
      "        88           0.1580           37.53s\n",
      "        89           0.1575           34.40s\n",
      "        90           0.1570           31.27s\n",
      "        91           0.1566           28.15s\n",
      "        92           0.1562           25.02s\n",
      "        93           0.1558           21.89s\n",
      "        94           0.1553           18.76s\n",
      "        95           0.1550           15.63s\n",
      "        96           0.1543           12.51s\n",
      "        97           0.1540            9.38s\n",
      "        98           0.1537            6.25s\n",
      "        99           0.1534            3.13s\n",
      "       100           0.1529            0.00s\n",
      "TF-IDF Vectors: 97.68378966102863\n",
      "Fitting threat...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0493            2.30m\n",
      "         2           0.0384            2.17m\n",
      "         3           0.0367            2.14m\n",
      "         4           0.0356            2.09m\n",
      "         5           5.6724            2.05m\n",
      "         6 325854827083698219568101057963223825814381632814998035103744.0000            2.02m\n",
      "         7 325854827083698219568101057963223825814381632814998035103744.0000            2.01m\n",
      "         8 325854827083698219568101057963223825814381632814998035103744.0000            1.98m\n",
      "         9 325854827083698219568101057963223825814381632814998035103744.0000            1.95m\n",
      "        10 325854827083698219568101057963223825814381632814998035103744.0000            1.92m\n",
      "        11 325854827083698219568101057963223825814381632814998035103744.0000            1.90m\n",
      "        12 325854827083698219568101057963223825814381632814998035103744.0000            1.87m\n",
      "        13 325854827083698219568101057963223825814381632814998035103744.0000            1.85m\n",
      "        14 325854827083698219568101057963223825814381632814998035103744.0000            1.82m\n",
      "        15 325854827083698219568101057963223825814381632814998035103744.0000            1.80m\n",
      "        16 325854827083698219568101057963223825814381632814998035103744.0000            1.78m\n",
      "        17 325854827083698219568101057963223825814381632814998035103744.0000            1.76m\n",
      "        18 325854827083698219568101057963223825814381632814998035103744.0000            1.73m\n",
      "        19 325854827083698219568101057963223825814381632814998035103744.0000            1.71m\n",
      "        20 325854827083698219568101057963223825814381632814998035103744.0000            1.69m\n",
      "        21 325854827083698219568101057963223825814381632814998035103744.0000            1.67m\n",
      "        22 325854827083698219568101057963223825814381632814998035103744.0000            1.65m\n",
      "        23 325854827083698219568101057963223825814381632814998035103744.0000            1.62m\n",
      "        24 325854827083698219568101057963223825814381632814998035103744.0000            1.60m\n",
      "        25 325854827083698219568101057963223825814381632814998035103744.0000            1.58m\n",
      "        26 325854827083698219568101057963223825814381632814998035103744.0000            1.56m\n",
      "        27 325854827083698219568101057963223825814381632814998035103744.0000            1.54m\n",
      "        28 325854827083698219568101057963223825814381632814998035103744.0000            1.52m\n",
      "        29 325854827083698219568101057963223825814381632814998035103744.0000            1.50m\n",
      "        30 325854827083698219568101057963223825814381632814998035103744.0000            1.47m\n",
      "        31 325854827083698219568101057963223825814381632814998035103744.0000            1.45m\n",
      "        32 325854827083698219568101057963223825814381632814998035103744.0000            1.43m\n",
      "        33 325854827083698219568101057963223825814381632814998035103744.0000            1.41m\n",
      "        34 325854827083698219568101057963223825814381632814998035103744.0000            1.39m\n",
      "        35 325854827083698219568101057963223825814381632814998035103744.0000            1.37m\n",
      "        36 325854827083698219568101057963223825814381632814998035103744.0000            1.35m\n",
      "        37 325854827083698219568101057963223825814381632814998035103744.0000            1.33m\n",
      "        38 325854827083698219568101057963223825814381632814998035103744.0000            1.31m\n",
      "        39 325854827083698219568101057963223825814381632814998035103744.0000            1.29m\n",
      "        40 325854827083698219568101057963223825814381632814998035103744.0000            1.26m\n",
      "        41 325854827083698219568101057963223825814381632814998035103744.0000            1.24m\n",
      "        42 325854827083698219568101057963223825814381632814998035103744.0000            1.22m\n",
      "        43 325854827083698219568101057963223825814381632814998035103744.0000            1.20m\n",
      "        44 325854827083698219568101057963223825814381632814998035103744.0000            1.18m\n",
      "        45 325854827083698219568101057963223825814381632814998035103744.0000            1.16m\n",
      "        46 325854827083698219568101057963223825814381632814998035103744.0000            1.14m\n",
      "        47 325854827083698219568101057963223825814381632814998035103744.0000            1.12m\n",
      "        48 325854827083698219568101057963223825814381632814998035103744.0000            1.10m\n",
      "        49 325854827083698219568101057963223825814381632814998035103744.0000            1.07m\n",
      "        50 325854827083698219568101057963223825814381632814998035103744.0000            1.05m\n",
      "        51 325854827083698219568101057963223825814381632814998035103744.0000            1.03m\n",
      "        52 325854827083698219568101057963223825814381632814998035103744.0000            1.01m\n",
      "        53 325854827083698219568101057963223825814381632814998035103744.0000           59.38s\n",
      "        54 325854827083698219568101057963223825814381632814998035103744.0000           58.15s\n",
      "        55 325854827083698219568101057963223825814381632814998035103744.0000           56.94s\n",
      "        56 325854827083698219568101057963223825814381632814998035103744.0000           55.56s\n",
      "        57 325854827083698219568101057963223825814381632814998035103744.0000           54.18s\n",
      "        58 325854827083698219568101057963223825814381632814998035103744.0000           52.85s\n",
      "        59 325854827083698219568101057963223825814381632814998035103744.0000           51.50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        60 325854827083698219568101057963223825814381632814998035103744.0000           50.14s\n",
      "        61 325854827083698219568101057963223825814381632814998035103744.0000           48.80s\n",
      "        62 325854827083698219568101057963223825814381632814998035103744.0000           47.47s\n",
      "        63 325854827083698219568101057963223825814381632814998035103744.0000           46.13s\n",
      "        64 325854827083698219568101057963223825814381632814998035103744.0000           44.81s\n",
      "        65 325854827083698219568101057963223825814381632814998035103744.0000           43.50s\n",
      "        66 325854827083698219568101057963223825814381632814998035103744.0000           42.21s\n",
      "        67 325854827083698219568101057963223825814381632814998035103744.0000           40.91s\n",
      "        68 325854827083698219568101057963223825814381632814998035103744.0000           39.61s\n",
      "        69 325854827083698219568101057963223825814381632814998035103744.0000           38.32s\n",
      "        70 325854827083698219568101057963223825814381632814998035103744.0000           37.03s\n",
      "        71 325854827083698219568101057963223825814381632814998035103744.0000           35.75s\n",
      "        72 325854827083698219568101057963223825814381632814998035103744.0000           34.46s\n",
      "        73 325854827083698219568101057963223825814381632814998035103744.0000           33.20s\n",
      "        74 325854827083698219568101057963223825814381632814998035103744.0000           31.93s\n",
      "        75 325854827083698219568101057963223825814381632814998035103744.0000           30.66s\n",
      "        76 325854827083698219568101057963223825814381632814998035103744.0000           29.40s\n",
      "        77 325854827083698219568101057963223825814381632814998035103744.0000           28.15s\n",
      "        78 325854827083698219568101057963223825814381632814998035103744.0000           26.90s\n",
      "        79 325854827083698219568101057963223825814381632814998035103744.0000           25.65s\n",
      "        80 325854827083698219568101057963223825814381632814998035103744.0000           24.40s\n",
      "        81 325854827083698219568101057963223825814381632814998035103744.0000           23.17s\n",
      "        82 325854827083698219568101057963223825814381632814998035103744.0000           21.94s\n",
      "        83 325854827083698219568101057963223825814381632814998035103744.0000           20.70s\n",
      "        84 325854827083698219568101057963223825814381632814998035103744.0000           19.46s\n",
      "        85 325854827083698219568101057963223825814381632814998035103744.0000           18.23s\n",
      "        86 325854827083698219568101057963223825814381632814998035103744.0000           17.00s\n",
      "        87 325854827083698219568101057963223825814381632814998035103744.0000           15.77s\n",
      "        88 325854827083698219568101057963223825814381632814998035103744.0000           14.55s\n",
      "        89 325854827083698219568101057963223825814381632814998035103744.0000           13.33s\n",
      "        90 325854827083698219568101057963223825814381632814998035103744.0000           12.10s\n",
      "        91 325854827083698219568101057963223825814381632814998035103744.0000           10.88s\n",
      "        92 325854827083698219568101057963223825814381632814998035103744.0000            9.67s\n",
      "        93 325854827083698219568101057963223825814381632814998035103744.0000            8.45s\n",
      "        94 325854827083698219568101057963223825814381632814998035103744.0000            7.24s\n",
      "        95 325854827083698219568101057963223825814381632814998035103744.0000            6.03s\n",
      "        96 325854827083698219568101057963223825814381632814998035103744.0000            4.82s\n",
      "        97 325854827083698219568101057963223825814381632814998035103744.0000            3.61s\n",
      "        98 325854827083698219568101057963223825814381632814998035103744.0000            2.41s\n",
      "        99 325854827083698219568101057963223825814381632814998035103744.0000            1.20s\n",
      "       100 325854827083698219568101057963223825814381632814998035103744.0000            0.00s\n",
      "Count Vectors: 99.74118104166797\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0457            5.45m\n",
      "         2         540.0673            5.30m\n",
      "         3    35116364.1319            5.19m\n",
      "         4    35116359.1794            5.12m\n",
      "         5    35116406.4008            5.05m\n",
      "         6    35116406.4005            4.99m\n",
      "         7    35116406.4002            4.94m\n",
      "         8    35116406.4011            4.88m\n",
      "         9    35116406.3992            4.81m\n",
      "        10    35116406.3989            4.75m\n",
      "        11    35116406.3984            4.69m\n",
      "        12    35116343.4200            4.63m\n",
      "        13    35116343.4199            4.57m\n",
      "        14    35116343.4194            4.50m\n",
      "        15    35116343.4189            4.44m\n",
      "        16    35116343.4199            4.38m\n",
      "        17    35116343.4175            4.32m\n",
      "        18    35116343.4179            4.26m\n",
      "        19    35116343.4168            4.20m\n",
      "        20    35116343.4167            4.15m\n",
      "        21    35116343.4167            4.10m\n",
      "        22    35116343.4159            4.04m\n",
      "        23    35116343.4158            3.99m\n",
      "        24    35116343.4156            3.93m\n",
      "        25    35116343.4156            3.87m\n",
      "        26    35116343.4156            3.82m\n",
      "        27    35116343.4156            3.77m\n",
      "        28    35116343.4154            3.71m\n",
      "        29    35116343.4154            3.66m\n",
      "        30    35116343.4154            3.60m\n",
      "        31    35116343.4085            3.55m\n",
      "        32    35116343.4084            3.50m\n",
      "        33    35116343.4081            3.45m\n",
      "        34    35116343.4078            3.40m\n",
      "        35    35116343.4077            3.35m\n",
      "        36    35116343.4076            3.29m\n",
      "        37    35116343.4075            3.24m\n",
      "        38    35116343.4075            3.19m\n",
      "        39    35116343.4075            3.13m\n",
      "        40    35116343.4075            3.08m\n",
      "        41    35116343.4075            3.03m\n",
      "        42    35116343.4074            2.98m\n",
      "        43    35116343.4074            2.92m\n",
      "        44    35116343.4074            2.87m\n",
      "        45    35116343.4074            2.82m\n",
      "        46    35116343.4074            2.77m\n",
      "        47    35116343.4074            2.72m\n",
      "        48    35116343.4074            2.66m\n",
      "        49    35116343.4074            2.61m\n",
      "        50    35116343.4074            2.56m\n",
      "        51    35116343.4074            2.51m\n",
      "        52    35116343.4074            2.45m\n",
      "        53    35116343.4073            2.40m\n",
      "        54    35116343.4073            2.35m\n",
      "        55    35116343.4073            2.30m\n",
      "        56    35116343.4073            2.25m\n",
      "        57    35116343.4073            2.20m\n",
      "        58    35116343.4073            2.15m\n",
      "        59    35116343.4073            2.09m\n",
      "        60    35116343.4073            2.04m\n",
      "        61    35116343.4073            1.99m\n",
      "        62    35116343.4073            1.94m\n",
      "        63    35116343.4073            1.89m\n",
      "        64    35116343.4073            1.84m\n",
      "        65    35116343.4073            1.79m\n",
      "        66    35116343.4073            1.74m\n",
      "        67    35116343.4073            1.68m\n",
      "        68    35116343.4073            1.63m\n",
      "        69    35116343.4073            1.58m\n",
      "        70    35116343.4072            1.53m\n",
      "        71    35116343.4072            1.48m\n",
      "        72    35116343.4072            1.43m\n",
      "        73    35116343.4072            1.38m\n",
      "        74    35116343.4072            1.33m\n",
      "        75    35116343.4072            1.27m\n",
      "        76    35116343.4072            1.22m\n",
      "        77    35116343.4072            1.17m\n",
      "        78    35116343.4072            1.12m\n",
      "        79    35116343.4072            1.07m\n",
      "        80    35116343.4072            1.02m\n",
      "        81    35116343.4072           58.09s\n",
      "        82    35116343.4072           55.04s\n",
      "        83    35116343.4072           51.98s\n",
      "        84    35116343.4071           48.91s\n",
      "        85    35116343.4071           45.85s\n",
      "        86    35116343.4071           42.80s\n",
      "        87    35116343.4071           39.74s\n",
      "        88    35116343.4071           36.69s\n",
      "        89    35116343.4071           33.63s\n",
      "        90    35116343.4071           30.61s\n",
      "        91    35116343.4071           27.56s\n",
      "        92    35116343.4071           24.48s\n",
      "        93    35116343.4071           21.42s\n",
      "        94    35116343.4071           18.35s\n",
      "        95    35116343.4071           15.29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        96    35116343.4071           12.23s\n",
      "        97    35116343.4071            9.17s\n",
      "        98    35116343.4071            6.11s\n",
      "        99    35116343.4071            3.06s\n",
      "       100    35116343.4071            0.00s\n",
      "TF-IDF Vectors: 99.78066189971862\n",
      "Fitting insult...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3446            2.23m\n",
      "         2           0.3304            2.12m\n",
      "         3           0.3197            2.06m\n",
      "         4           0.3116            2.01m\n",
      "         5           0.3040            2.00m\n",
      "         6           0.2994            1.97m\n",
      "         7           0.2953            1.95m\n",
      "         8           0.2903            1.92m\n",
      "         9           0.2856            1.91m\n",
      "        10           0.2830            1.89m\n",
      "        11           0.2796            1.86m\n",
      "        12           0.2771            1.84m\n",
      "        13           0.2739            1.82m\n",
      "        14           0.2715            1.79m\n",
      "        15           0.2697            1.77m\n",
      "        16           0.2675            1.75m\n",
      "        17           0.2651            1.73m\n",
      "        18           0.2619            1.71m\n",
      "        19           0.2602            1.69m\n",
      "        20           0.2584            1.67m\n",
      "        21           0.2544            1.65m\n",
      "        22           0.2529            1.63m\n",
      "        23           0.2513            1.61m\n",
      "        24           0.2501            1.59m\n",
      "        25           0.2471            1.57m\n",
      "        26           0.2457            1.55m\n",
      "        27           0.2447            1.53m\n",
      "        28           0.2434            1.51m\n",
      "        29           0.2412            1.49m\n",
      "        30           0.2400            1.47m\n",
      "        31           0.2390            1.45m\n",
      "        32           0.2379            1.43m\n",
      "        33           0.2353            1.41m\n",
      "        34           0.2342            1.39m\n",
      "        35           0.2333            1.37m\n",
      "        36           0.2325            1.35m\n",
      "        37           0.2318            1.33m\n",
      "        38           0.2308            1.31m\n",
      "        39           0.2291            1.29m\n",
      "        40           0.2283            1.27m\n",
      "        41           0.2274            1.24m\n",
      "        42           0.2266            1.22m\n",
      "        43           0.2256            1.20m\n",
      "        44           0.2249            1.18m\n",
      "        45           0.2232            1.16m\n",
      "        46           0.2226            1.14m\n",
      "        47           0.2220            1.12m\n",
      "        48           0.2213            1.10m\n",
      "        49           0.2205            1.08m\n",
      "        50           0.2188            1.06m\n",
      "        51           0.2181            1.04m\n",
      "        52           0.2176            1.02m\n",
      "        53           0.2160           59.76s\n",
      "        54           0.2153           58.52s\n",
      "        55           0.2145           57.23s\n",
      "        56           0.2140           55.98s\n",
      "        57           0.2135           54.73s\n",
      "        58           0.2125           53.47s\n",
      "        59           0.2119           52.21s\n",
      "        60           0.2113           50.98s\n",
      "        61           0.2108           49.67s\n",
      "        62           0.2104           48.41s\n",
      "        63           0.2091           47.17s\n",
      "        64           0.2086           45.89s\n",
      "        65           0.2081           44.64s\n",
      "        66           0.2070           43.36s\n",
      "        67           0.2065           42.10s\n",
      "        68           0.2060           40.81s\n",
      "        69           0.2056           39.54s\n",
      "        70           0.2052           38.28s\n",
      "        71           0.2049           36.99s\n",
      "        72           0.2045           35.72s\n",
      "        73           0.2041           34.49s\n",
      "        74           0.2037           33.21s\n",
      "        75           0.2032           31.93s\n",
      "        76           0.2024           30.64s\n",
      "        77           0.2021           29.36s\n",
      "        78           0.2017           28.09s\n",
      "        79           0.2010           26.83s\n",
      "        80           0.2006           25.55s\n",
      "        81           0.2003           24.28s\n",
      "        82           0.1999           22.99s\n",
      "        83           0.1992           21.71s\n",
      "        84           0.1989           20.42s\n",
      "        85           0.1977           19.15s\n",
      "        86           0.1971           17.88s\n",
      "        87           0.1967           16.60s\n",
      "        88           0.1963           15.32s\n",
      "        89           0.1960           14.04s\n",
      "        90           0.1957           12.77s\n",
      "        91           0.1954           11.49s\n",
      "        92           0.1951           10.22s\n",
      "        93           0.1948            8.93s\n",
      "        94           0.1938            7.66s\n",
      "        95           0.1934            6.38s\n",
      "        96           0.1931            5.11s\n",
      "        97           0.1927            3.83s\n",
      "        98           0.1924            2.55s\n",
      "        99           0.1920            1.28s\n",
      "       100           0.1912            0.00s\n",
      "Count Vectors: 96.8609584448302\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3442            5.15m\n",
      "         2           0.3299            5.01m\n",
      "         3           0.3188            4.94m\n",
      "         4           0.3104            4.88m\n",
      "         5           0.3028            4.85m\n",
      "         6           0.2982            4.79m\n",
      "         7           0.2925            4.74m\n",
      "         8           0.2876            4.68m\n",
      "         9           0.2837            4.64m\n",
      "        10           0.2805            4.59m\n",
      "        11           0.2769            4.54m\n",
      "        12           0.2746            4.48m\n",
      "        13           0.2723            4.44m\n",
      "        14           0.2701            4.38m\n",
      "        15           0.2676            4.33m\n",
      "        16           0.2655            4.28m\n",
      "        17           0.2633            4.23m\n",
      "        18           0.2609            4.18m\n",
      "        19           0.2576            4.13m\n",
      "        20           0.2559            4.08m\n",
      "        21           0.2546            4.02m\n",
      "        22           0.2529            3.98m\n",
      "        23           0.2490            3.92m\n",
      "        24           0.2476            3.87m\n",
      "        25           0.2462            3.82m\n",
      "        26           0.2430            3.77m\n",
      "        27           0.2416            3.72m\n",
      "        28           0.2405            3.67m\n",
      "        29           0.2395            3.62m\n",
      "        30           0.2385            3.57m\n",
      "        31           0.2371            3.52m\n",
      "        32           0.2341            3.46m\n",
      "        33           0.2330            3.42m\n",
      "        34           0.2320            3.36m\n",
      "        35           0.2299            3.31m\n",
      "        36           0.2291            3.26m\n",
      "        37           0.2281            3.21m\n",
      "        38           0.2271            3.16m\n",
      "        39           0.2261            3.11m\n",
      "        40           0.2239            3.06m\n",
      "        41           0.2229            3.01m\n",
      "        42           0.2215            2.96m\n",
      "        43           0.2208            2.91m\n",
      "        44           0.2201            2.86m\n",
      "        45           0.2192            2.81m\n",
      "        46           0.2185            2.76m\n",
      "        47           0.2177            2.71m\n",
      "        48           0.2170            2.66m\n",
      "        49           0.2164            2.61m\n",
      "        50           0.2147            2.56m\n",
      "        51           0.2139            2.51m\n",
      "        52           0.2132            2.45m\n",
      "        53           0.2126            2.40m\n",
      "        54           0.2121            2.35m\n",
      "        55           0.2114            2.30m\n",
      "        56           0.2108            2.25m\n",
      "        57           0.2101            2.20m\n",
      "        58           0.2092            2.15m\n",
      "        59           0.2078            2.10m\n",
      "        60           0.2072            2.04m\n",
      "        61           0.2067            1.99m\n",
      "        62           0.2060            1.94m\n",
      "        63           0.2053            1.89m\n",
      "        64           0.2048            1.84m\n",
      "        65           0.2044            1.79m\n",
      "        66           0.2033            1.74m\n",
      "        67           0.2028            1.69m\n",
      "        68           0.2024            1.64m\n",
      "        69           0.2020            1.59m\n",
      "        70           0.2016            1.53m\n",
      "        71           0.2011            1.48m\n",
      "        72           0.2007            1.43m\n",
      "        73           0.2003            1.38m\n",
      "        74           0.1999            1.33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        75           0.1994            1.28m\n",
      "        76           0.1989            1.23m\n",
      "        77           0.1979            1.18m\n",
      "        78           0.1974            1.13m\n",
      "        79           0.1970            1.07m\n",
      "        80           0.1967            1.02m\n",
      "        81           0.1964           58.33s\n",
      "        82           0.1960           55.27s\n",
      "        83           0.1957           52.19s\n",
      "        84           0.1949           49.12s\n",
      "        85           0.1945           46.05s\n",
      "        86           0.1941           42.98s\n",
      "        87           0.1937           39.90s\n",
      "        88           0.1926           36.83s\n",
      "        89           0.1922           33.76s\n",
      "        90           0.1918           30.69s\n",
      "        91           0.1915           27.62s\n",
      "        92           0.1910           24.55s\n",
      "        93           0.1901           21.48s\n",
      "        94           0.1898           18.41s\n",
      "        95           0.1894           15.35s\n",
      "        96           0.1891           12.28s\n",
      "        97           0.1888            9.21s\n",
      "        98           0.1885            6.14s\n",
      "        99           0.1877            3.07s\n",
      "       100           0.1873            0.00s\n",
      "TF-IDF Vectors: 96.96498737239223\n",
      "Fitting identity_hate...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0813            2.25m\n",
      "         2           0.0772            2.12m\n",
      "         3           0.0757            2.08m\n",
      "         4           0.0738            2.03m\n",
      "         5           0.0726            2.01m\n",
      "         6           0.0719            1.98m\n",
      "         7           0.0712            1.95m\n",
      "         8           0.0700            1.92m\n",
      "         9           0.0692            1.91m\n",
      "        10           0.0680            1.89m\n",
      "        11           0.0672            1.88m\n",
      "        12           0.0666            1.85m\n",
      "        13           0.0659            1.83m\n",
      "        14           0.0651            1.82m\n",
      "        15           0.0645            1.80m\n",
      "        16           0.0638            1.78m\n",
      "        17           0.0635            1.76m\n",
      "        18           0.0628            1.74m\n",
      "        19           0.0623            1.72m\n",
      "        20           0.0622            1.69m\n",
      "        21           0.0618            1.67m\n",
      "        22           0.0612            1.65m\n",
      "        23           0.0603            1.63m\n",
      "        24           0.0596            1.61m\n",
      "        25           0.0592            1.58m\n",
      "        26           0.0587            1.56m\n",
      "        27           0.0584            1.54m\n",
      "        28           0.0583            1.51m\n",
      "        29           0.0580            1.50m\n",
      "        30           0.0578            1.47m\n",
      "        31           0.0574            1.45m\n",
      "        32           0.0569            1.42m\n",
      "        33           0.0567            1.40m\n",
      "        34           0.0566            1.38m\n",
      "        35           0.0565            1.36m\n",
      "        36           0.0562            1.34m\n",
      "        37           0.0559            1.32m\n",
      "        38           0.0559            1.29m\n",
      "        39           0.0556            1.27m\n",
      "        40           0.0553            1.25m\n",
      "        41           0.0549            1.23m\n",
      "        42           0.0547            1.21m\n",
      "        43           0.0546            1.19m\n",
      "        44           0.0545            1.17m\n",
      "        45           0.0543            1.15m\n",
      "        46           0.0539            1.13m\n",
      "        47           0.0535            1.11m\n",
      "        48           0.0535            1.08m\n",
      "        49           0.0531            1.06m\n",
      "        50           0.0528            1.04m\n",
      "        51           0.0526            1.02m\n",
      "        52           0.0524           59.71s\n",
      "        53           0.0522           58.33s\n",
      "        54           0.0520           56.98s\n",
      "        55           0.0518           55.62s\n",
      "        56           0.0517           54.40s\n",
      "        57           0.0515           53.10s\n",
      "        58           0.0513           51.81s\n",
      "        59           0.0511           50.48s\n",
      "        60           0.0508           49.17s\n",
      "        61           0.0506           47.84s\n",
      "        62           0.0504           46.66s\n",
      "        63           0.0502           45.38s\n",
      "        64           0.0500           44.08s\n",
      "        65           0.0498           42.80s\n",
      "        66           0.0496           41.52s\n",
      "        67           0.0494           40.24s\n",
      "        68           0.0492           38.97s\n",
      "        69           0.0490           37.69s\n",
      "        70           0.0488           36.42s\n",
      "        71           0.0486           35.16s\n",
      "        72           0.0483           33.91s\n",
      "        73           0.0481           32.66s\n",
      "        74           0.0479           31.41s\n",
      "        75           0.0478           30.21s\n",
      "        76           0.0476           28.97s\n",
      "        77           0.0474           27.72s\n",
      "        78           0.0472           26.54s\n",
      "        79           0.0470           25.32s\n",
      "        80           0.0468           24.08s\n",
      "        81           0.0466           22.85s\n",
      "        82           0.0464           21.62s\n",
      "        83           0.0462           20.41s\n",
      "        84           0.0460           19.19s\n",
      "        85           0.0458           18.01s\n",
      "        86           0.0456           16.79s\n",
      "        87           0.0454           15.59s\n",
      "        88           0.0452           14.37s\n",
      "        89           0.0450           13.16s\n",
      "        90           0.0448           11.96s\n",
      "        91           0.0446           10.76s\n",
      "        92           0.0444            9.55s\n",
      "        93           0.0443            8.35s\n",
      "        94           0.0442            7.15s\n",
      "        95           0.0440            5.94s\n",
      "        96           0.0438            4.75s\n",
      "        97           0.0436            3.56s\n",
      "        98           0.0435            2.37s\n",
      "        99           0.0433            1.18s\n",
      "       100           0.0431            0.00s\n",
      "Count Vectors: 99.41781401382457\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0813            5.28m\n",
      "         2           0.0764            5.09m\n",
      "         3           0.0734            5.01m\n",
      "         4           0.0716            4.92m\n",
      "         5           0.0700            4.86m\n",
      "         6           0.0684            4.81m\n",
      "         7           0.0673            4.75m\n",
      "         8           0.0666            4.69m\n",
      "         9           0.0658            4.64m\n",
      "        10           0.0648            4.59m\n",
      "        11           0.0638            4.53m\n",
      "        12           0.0628            4.49m\n",
      "        13           0.0624            4.44m\n",
      "        14           0.0617            4.38m\n",
      "        15           0.0610            4.33m\n",
      "        16           0.0602            4.27m\n",
      "        17           0.0600            4.23m\n",
      "        18           0.0594            4.17m\n",
      "        19           0.0591            4.12m\n",
      "        20           0.0586            4.08m\n",
      "        21           0.0584            4.02m\n",
      "        22           0.0578            3.97m\n",
      "        23           0.0576            3.92m\n",
      "        24           0.0568            3.87m\n",
      "        25           0.0565            3.82m\n",
      "        26           0.0560            3.76m\n",
      "        27           0.0557            3.71m\n",
      "        28           0.0555            3.66m\n",
      "        29           0.0552            3.60m\n",
      "        30           0.0550            3.55m\n",
      "        31           0.0546            3.50m\n",
      "        32           0.0544            3.45m\n",
      "        33           0.0542            3.40m\n",
      "        34           0.0539            3.35m\n",
      "        35           0.0536            3.30m\n",
      "        36           0.0534            3.24m\n",
      "        37           0.0531            3.19m\n",
      "        38           0.0526            3.14m\n",
      "        39           0.0525            3.10m\n",
      "        40           0.0523            3.04m\n",
      "        41           0.0519            2.99m\n",
      "        42           0.0516            2.94m\n",
      "        43           0.0514            2.89m\n",
      "        44           0.0513            2.84m\n",
      "        45           0.0511            2.79m\n",
      "        46           0.0508            2.74m\n",
      "        47           0.0505            2.69m\n",
      "        48           0.0505            2.64m\n",
      "        49           0.0503            2.58m\n",
      "        50           0.0498            2.53m\n",
      "        51           0.0498            2.48m\n",
      "        52           0.0494            2.43m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        53           0.0492            2.38m\n",
      "        54           0.0491            2.33m\n",
      "        55           0.0490            2.28m\n",
      "        56           0.0486            2.23m\n",
      "        57           0.0484            2.18m\n",
      "        58           0.0481            2.13m\n",
      "        59           0.0479            2.08m\n",
      "        60           0.0474            2.03m\n",
      "        61           0.0473            1.98m\n",
      "        62           0.0473            1.92m\n",
      "        63           0.0470            1.87m\n",
      "        64           0.0465            1.82m\n",
      "        65           0.0462            1.77m\n",
      "        66           0.0460            1.72m\n",
      "        67           0.0458            1.67m\n",
      "        68           0.0456            1.62m\n",
      "        69           0.0454            1.57m\n",
      "        70           0.0452            1.51m\n",
      "        71           0.0449            1.46m\n",
      "        72           0.0447            1.41m\n",
      "        73           0.0445            1.36m\n",
      "        74           0.0444            1.31m\n",
      "        75           0.0442            1.26m\n",
      "        76           0.0439            1.21m\n",
      "        77           0.0437            1.16m\n",
      "        78           0.0435            1.11m\n",
      "        79           0.0433            1.06m\n",
      "        80           0.0430            1.01m\n",
      "        81           0.0430           57.35s\n",
      "        82           0.0429           54.34s\n",
      "        83           0.0426           51.29s\n",
      "        84           0.0424           48.26s\n",
      "        85           0.0422           45.22s\n",
      "        86           0.0420           42.19s\n",
      "        87           0.0417           39.16s\n",
      "        88           0.0415           36.13s\n",
      "        89           0.0413           33.11s\n",
      "        90           0.0411           30.08s\n",
      "        91           0.0410           27.08s\n",
      "        92           0.0409           24.08s\n",
      "        93           0.0406           21.06s\n",
      "        94           0.0404           18.04s\n",
      "        95           0.0402           15.03s\n",
      "        96           0.0400           12.02s\n",
      "        97           0.0397            9.01s\n",
      "        98           0.0395            6.01s\n",
      "        99           0.0394            3.00s\n",
      "       100           0.0393            0.00s\n",
      "TF-IDF Vectors: 99.5149494582349\n"
     ]
    }
   ],
   "source": [
    "predictions_gbc_count = np.zeros((len(test), len(classes)))\n",
    "predictions_gbc_tfidf = np.zeros((len(test), len(classes)))\n",
    "\n",
    "for i in range(6):\n",
    "    print('Fitting', classes[i] + '...')\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(verbose=2)\n",
    "    \n",
    "    gbc.fit(count_train, y_train[classes[i]])\n",
    "    print('Count Vectors:', compute_accuracy(gbc.predict(count_train), y_train[classes[i]]))\n",
    "    predictions_gbc_count[:,i] = gbc.predict_proba(count_test)[:,1]\n",
    "    \n",
    "    gbc.fit(tfidf_train, y_train[classes[i]])\n",
    "    print('TF-IDF Vectors:', compute_accuracy(gbc.predict(tfidf_train), y_train[classes[i]]))\n",
    "    predictions_gbc_tfidf[:,i] = gbc.predict_proba(tfidf_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "729bf683",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_sgd_count_tuned, 'submission_sgd_count_tuned')\n",
    "to_submission_csv(predictions_sgd_tfidf_tuned, 'submission_sgd_tfidf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_adb_count, 'submission_adb_count')\n",
    "to_submission_csv(predictions_adb_tfidf, 'submission_adb_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54ec5673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_adb_count.csv</th>\n",
       "      <td>0.93539</td>\n",
       "      <td>0.94218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_adb_tfidf.csv</th>\n",
       "      <td>0.93830</td>\n",
       "      <td>0.94145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          private   public\n",
       "submission_adb_count.csv  0.93539  0.94218\n",
       "submission_adb_tfidf.csv  0.93830  0.94145"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.79902, 0.95247], 'public': [0.81682, 0.95784]}, \n",
    "    index=['predictions_sgd_count_tuned.csv', 'predictions_sgd_tfidf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8f56",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571180e0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf32cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 max_iter=3000))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_count = OneVsRestClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_oc_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37058cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 max_iter=3000))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_tf = OneVsRestClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_oc_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4795ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            95.739201\n",
      "severe_toxic     97.941355\n",
      "obscene          98.078598\n",
      "threat           99.375200\n",
      "insult           96.812077\n",
      "identity_hate    98.102412\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = lr_oc_count.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef14df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_oc_tf = lr_oc_tf.predict_proba(tfidf_test)\n",
    "predictions_lr_oc_count = lr_oc_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ac23fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_lr_oc_tf, 'submission_oc_lr_tf')\n",
    "to_submission_csv(predictions_lr_oc_count, 'submission_oc_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e68800ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_lr_tf.csv</th>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.97621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_oc_lr_count.csv  0.94036  0.94400\n",
       "submission_oc_lr_tf.csv     0.97558  0.97621"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97558], 'public': [0.94400, 0.97621]}, \n",
    "    index=['submission_oc_lr_count.csv', 'submission_oc_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414831b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5198b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a84f7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(LogisticRegression ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d557e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_oc_tf_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_oc_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58ae1c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            98.477167\n",
      "severe_toxic     99.529363\n",
      "obscene          99.205369\n",
      "threat           99.895344\n",
      "insult           98.869469\n",
      "identity_hate    99.662219\n",
      "dtype: float64 {'estimator__C': 12, 'estimator__class_weight': None, 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_oc_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), lr_oc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86997d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_oc_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned, 'submission_oc_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647d7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "lr_oc_count_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_oc_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oc_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), lr_oc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_oc_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv(predictions_lr_count_tuned, 'submission_oc_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0206f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97558], 'public': [0.94410, 0.97621]}, \n",
    "    index=['submission_oc_lr_count_tuned.csv', 'submission_oc_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ea0d0",
   "metadata": {},
   "source": [
    "### OneVsRest Classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dffb0b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf7e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_count = OneVsRestClassifier(MultinomialNB())\n",
    "mn_oc_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfda2b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_tf = OneVsRestClassifier(MultinomialNB())\n",
    "mn_oc_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c466f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = mn_oc_count.predict(count_train)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26cad537",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_oc_tf = mn_oc_tf.predict_proba(tfidf_test)\n",
    "predictions_mn_oc_count = mn_oc_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_oc_tf, 'submission_oc_mn_tf')\n",
    "to_submission_csv(predictions_mn_oc_count, 'submission_oc_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e241161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_tf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_oc_mn_count.csv  0.84551  0.85581\n",
       "submission_oc_mn_tf.csv     0.82510  0.83586"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_oc_mn_count.csv', 'submission_oc_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113669a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2efd1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff8b5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(MultinomialNB ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a077218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_tf_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'accuracy')\n",
    "mn_oc_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "230d91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            93.609114\n",
      "severe_toxic     98.989791\n",
      "obscene          96.043141\n",
      "threat           99.691673\n",
      "insult           95.876444\n",
      "identity_hate    99.106354\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), mn_oc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2903154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_oc_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned, 'submission_oc_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f2e1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=OneVsRestClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_oc_count_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'accuracy')\n",
    "mn_oc_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c226e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64 {'estimator__alpha': 1.0, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_oc_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), mn_oc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "909b082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_oc_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv(predictions_mn_count_tuned, 'submission_oc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c88e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_count_tuned.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_oc_mn_tf_tuned.csv</th>\n",
       "      <td>0.85045</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_oc_mn_count_tuned.csv  0.84551  0.85581\n",
       "submission_oc_mn_tf_tuned.csv     0.85045  0.86105"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.85045], 'public': [0.85581, 0.86105]}, \n",
    "    index=['submission_oc_mn_count_tuned.csv', 'submission_oc_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a9a1f",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160feff",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "41b713eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           0             0        0       0       0              0\n",
       "4           0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      0             0        0       0       0              0\n",
       "159567      0             0        0       0       0              0\n",
       "159568      0             0        0       0       0              0\n",
       "159569      0             0        0       0       0              0\n",
       "159570      0             0        0       0       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']\n",
    "y_train = train.loc [ : , 'toxic' : ]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e768790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7564c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   max_iter=3000))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_tf = MultiOutputClassifier(LogisticRegression(class_weight = 'balanced', max_iter = 3000))\n",
    "lr_mo_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ededd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64\n",
      "Count Vectors:  toxic            97.955142\n",
      "severe_toxic     98.672064\n",
      "obscene          98.804294\n",
      "threat           99.741808\n",
      "insult           97.874927\n",
      "identity_hate    98.947177\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = lr_mo_count.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d96e87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_mo_tf = lr_mo_tf.predict_proba(tfidf_test)\n",
    "predictions_lr_mo_count = lr_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c7ff4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_lr_mo_tf, 'submission_mo_lr_tf')\n",
    "to_submission_csv_multiclass(predictions_lr_mo_count, 'submission_mo_lr_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c4518fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count.csv</th>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.94400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_lr_count.csv  0.94036  0.94400\n",
       "submission_mo_lr_tf.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.94036, 0.97063], 'public': [0.94400, 0.97183]}, \n",
    "    index=['submission_mo_lr_count.csv', 'submission_mo_lr_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5096",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7c83146",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8bafa6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(LogisticRegression ())\n",
    "lr_mo_tf_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2d001476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            94.403118\n",
      "severe_toxic     97.335982\n",
      "obscene          97.324702\n",
      "threat           99.067500\n",
      "insult           95.850750\n",
      "identity_hate    97.123537\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: ', compute_accuracy(predictions, y_train), lr_mo_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "31b6e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_mo_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_lr_tfidf_tuned, 'submission_mo_lr_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d297b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': [1, 12, 15],\n",
       "                          'estimator__class_weight': ['balanced', None],\n",
       "                          'estimator__max_iter': [600, 1800, 3000]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mo_count_tuned = GridSearchCV(estimator, parameters_lr_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_mo_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "10449db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            97.936342\n",
      "severe_toxic     98.640730\n",
      "obscene          98.735359\n",
      "threat           99.741808\n",
      "insult           97.858633\n",
      "identity_hate    98.945924\n",
      "dtype: float64 {'estimator__C': 1, 'estimator__class_weight': 'balanced', 'estimator__max_iter': 600}\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_mo_count_tuned.predict(count_train)\n",
    "print('Count Vectors: ', compute_accuracy(predictions, y_train), lr_mo_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "221b93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_mo_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_lr_count_tuned, 'submission_mo_lr_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d17e95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_count_tuned.csv</th>\n",
       "      <td>0.93996</td>\n",
       "      <td>0.94410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_lr_tf_tuned.csv</th>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_lr_count_tuned.csv  0.93996  0.94410\n",
       "submission_mo_lr_tf_tuned.csv     0.97063  0.97183"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.93996, 0.97063], 'public': [0.94410, 0.97183]}, \n",
    "    index=['submission_mo_lr_count_tuned.csv', 'submission_mo_lr_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c8000",
   "metadata": {},
   "source": [
    "### MultiOutput Classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51860474",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "559daa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_count = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo_count.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6f95889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_tf = MultiOutputClassifier(MultinomialNB())\n",
    "mn_mo_tf.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a9795f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            92.368287\n",
      "severe_toxic     98.991045\n",
      "obscene          95.384500\n",
      "threat           99.697313\n",
      "insult           95.356299\n",
      "identity_hate    99.110741\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            95.136961\n",
      "severe_toxic     98.641984\n",
      "obscene          96.708675\n",
      "threat           99.555057\n",
      "insult           96.463016\n",
      "identity_hate    98.772333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_tf.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions, y_train))\n",
    "\n",
    "predictions = mn_mo_count.predict(count_train)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c1a6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mnb_mo_tf = mn_mo_tf.predict_proba(tfidf_test)\n",
    "predictions_mnb_mo_count = mn_mo_count.predict_proba(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e99061ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv_multiclass(predictions_mnb_mo_tf, 'submission_mo_mn_tf')\n",
    "to_submission_csv_multiclass(predictions_mnb_mo_count, 'submission_mo_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bddaaa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_count.csv</th>\n",
       "      <td>0.84551</td>\n",
       "      <td>0.85581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_tf.csv</th>\n",
       "      <td>0.82510</td>\n",
       "      <td>0.83586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_mo_mn_count.csv  0.84551  0.85581\n",
       "submission_mo_mn_tf.csv     0.82510  0.83586"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.84551, 0.82510], 'public': [0.85581, 0.83586]}, \n",
    "    index=['submission_mo_mn_count.csv', 'submission_mo_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d7b5b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1717b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ea0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultiOutputClassifier(MultinomialNB ())\n",
    "mn_mo_tf_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_mo_tf_tuned.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b36dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors:  toxic            93.609114\n",
      "severe_toxic     98.989791\n",
      "obscene          96.043141\n",
      "threat           99.691673\n",
      "insult           95.876444\n",
      "identity_hate    99.106354\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_tf_tuned.predict(tfidf_train)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions, y_train), mn_mo_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe5702db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_mo_tf_tuned.predict_proba(tfidf_test)\n",
    "to_submission_csv_multiclass(predictions_mn_tfidf_tuned, 'submission_mo_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19a946ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=MultinomialNB()),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator__alpha': [0.5, 0.6, 0.7, 0.8, 1.0],\n",
       "                          'estimator__fit_prior': [True, False]}],\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_mo_count_tuned = GridSearchCV(estimator, parameters_mn_mo, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_mo_count_tuned.fit(count_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58c687c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors:  toxic            95.165162\n",
      "severe_toxic     98.426406\n",
      "obscene          96.575192\n",
      "threat           99.472335\n",
      "insult           96.317627\n",
      "identity_hate    98.473407\n",
      "dtype: float64 {'estimator__alpha': 0.5, 'estimator__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "predictions = mn_mo_count_tuned.predict(count_train)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions, y_train), mn_mo_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33e6339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_mo_count_tuned.predict_proba(count_test)\n",
    "to_submission_csv_multiclass(predictions_mn_count_tuned, 'submission_mo_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed6b150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_count_tuned.csv</th>\n",
       "      <td>0.87456</td>\n",
       "      <td>0.88221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_mo_mn_tf_tuned.csv</th>\n",
       "      <td>0.85045</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  private   public\n",
       "submission_mo_mn_count_tuned.csv  0.87456  0.88221\n",
       "submission_mo_mn_tf_tuned.csv     0.85045  0.86105"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.87456, 0.85045], 'public': [0.88221, 0.86105]}, \n",
    "    index=['submission_mo_mn_count_tuned.csv', 'submission_mo_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf14d",
   "metadata": {},
   "source": [
    "### Classifier Chain: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5054ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6b9bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_tf = ClassifierChain(classifier = MultinomialNB(alpha = 1.0, fit_prior = True))\n",
    "mn_cc_count = ClassifierChain(classifier = MultinomialNB(alpha = 1.0, fit_prior = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26ee28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_cc_tf.fit(tfidf_train_5000, y_train)\n",
    "mn_cc_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d20afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectors: \n",
      " toxic            95.029799\n",
      "severe_toxic     98.715932\n",
      "obscene          97.173672\n",
      "threat           99.046819\n",
      "insult           96.766330\n",
      "identity_hate    95.881457\n",
      "dtype: float64\n",
      "Count Vectors: \n",
      " toxic            94.139913\n",
      "severe_toxic     97.492025\n",
      "obscene          94.467666\n",
      "threat           95.961672\n",
      "insult           94.012070\n",
      "identity_hate    93.246893\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions_mn_cc_tf = mn_cc_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions_mn_cc_tf.todense(), y_train))\n",
    "\n",
    "predictions_mn_cc_count = mn_cc_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions_mn_cc_count.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ec577f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_cc_tf = mn_cc_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_mn_cc_count = mn_cc_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3408d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mn_cc_tf.todense(), 'submission_tfidf_mn_cc')\n",
    "to_submission_csv(predictions_mn_cc_count.todense(), 'submission_count_mn_cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaa47c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>submission_count_mn_cc.csv</th>\n",
       "      <td>0.92866</td>\n",
       "      <td>0.92896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_tfidf_mn_cc.csv</th>\n",
       "      <td>0.94711</td>\n",
       "      <td>0.94614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            private   public\n",
       "submission_count_mn_cc.csv  0.92866  0.92896\n",
       "submission_tfidf_mn_cc.csv  0.94711  0.94614"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0.92866, 0.94711], 'public': [0.92896, 0.94614]}, \n",
    "    index=['submission_count_mn_cc.csv', 'submission_tfidf_mn_cc.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c2f29",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b3cf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "estimator = ClassifierChain(MultinomialNB ())\n",
    "mn_cc_tf_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_cc_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_cc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_cc_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned.todense(), 'submission_cc_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_cc_count_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_cc_count_tuned.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_cc_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_cc_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_cc_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_mn_count_tuned.todense(), 'submission_cc_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_cc_mn_count_tuned.csv', 'submission_cc_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f016da",
   "metadata": {},
   "source": [
    "### Binary Relevance: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acab8b",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4437362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr_tf = BinaryRelevance(classifier = LogisticRegression())\n",
    "br_lr_count = BinaryRelevance(classifier = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721df04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "br_lr_tf.fit(tfidf_train_5000, y_train)\n",
    "br_lr_count.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_br_lr_tf = br_lr_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions_br_lr_tf.todense(), y_train))\n",
    "\n",
    "predictions_br_lr_count = br_lr_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions_br_lr_count.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_br_lr_tf = br_lr_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_br_lr_count = br_lr_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6451a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_br_lr_tf.todense(), 'submission_tfidf_lr_br')\n",
    "to_submission_csv(predictions_br_lr_count.todense(), 'submission_count_lr_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_count_lr_br.csv', 'submission_tfidf_lr_br.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921bad",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22772ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_lr_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BinaryRelevance(LogisticRegression ())\n",
    "lr_cc_tf_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_cc_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_cc_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions.todense(), y_train), lr_cc_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_tfidf_tuned = lr_cc_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_lr_tfidf_tuned.todense(), 'submission_lr_cc_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea099b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_br_count_tuned = GridSearchCV(estimator, parameters_lr_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "lr_br_count_tuned.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_br_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train), lr_br_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ede017",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr_count_tuned = lr_br_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_lr_count_tuned.todense(), 'submission_lr_cc_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db979687",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_count_lr_br.csv', 'submission_tfidf_lr_br.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633710",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b35262",
   "metadata": {},
   "source": [
    "### Binary Relevance: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46acf7",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_count = MultiOutputClassifier(MultinomialNB())\n",
    "mn_br_count.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_tf = MultiOutputClassifier(MultinomialNB())\n",
    "mn_br_tf.fit(count_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tf.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n' , compute_accuracy(predictions.todense(), y_train))\n",
    "\n",
    "predictions = mn_br_count.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mnb_br_tf = mn_br_tf.predict_proba(tfidf_test_5000)\n",
    "predictions_mnb_br_count = mn_br_count.predict_proba(count_test_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3351f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_csv(predictions_mnb_br_tf.todense(), 'submission_br_mn_tf')\n",
    "to_submission_csv(predictions_mnb_br_count.todense(), 'submission_br_mn_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_br_mn_count.csv', 'submission_br_mn_tf.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e32a6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = np.zeros((len(test), len(classes)))\n",
    "predictions_mn_tfidf_tuned = np.zeros((len(test), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ClassifierChain(MultinomialNB ())\n",
    "mn_br_tf_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_br_tf_tuned.fit(tfidf_train_5000, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7526d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_tf_tuned.predict(tfidf_train_5000)\n",
    "print('TF-IDF Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_br_tf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_tfidf_tuned = mn_br_tf_tuned.predict_proba(tfidf_test_5000)\n",
    "to_submission_csv(predictions_mn_tfidf_tuned.todense(), 'submission_br_mn_tf_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_br_count_tuned = GridSearchCV(estimator, parameters_mn_multi, n_jobs = -1, verbose = 10, scoring = 'f1')\n",
    "mn_br_count_tuned.fit(count_train_5000, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac99605",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mn_br_count_tuned.predict(count_train_5000)\n",
    "print('Count Vectors: \\n', compute_accuracy(predictions.todense(), y_train), mn_br_count_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mn_count_tuned = mn_br_count_tuned.predict_proba(count_test_5000)\n",
    "to_submission_csv(predictions_mn_count_tuned.todense(), 'submission_br_mn_count_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97146af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={'private': [0, 0], 'public': [0, 0]}, \n",
    "    index=['submission_br_mn_count_tuned.csv', 'submission_br_mn_tf_tuned.csv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c3b8",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0528ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf324509",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(tfidf_train, y_train)\n",
    "    predictions = model.predict(tfidf_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc574c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tfidf_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a8714",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_mnb):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cdd89",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d69379",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2508e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab42516",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24309156",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ea51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    y_train = train[class_]\n",
    "    model = MultinomialNB ()\n",
    "    model.fit(count_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(count_train)\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "sample_submission.to_csv(f'results/submission_count_nb.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6d970",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = MultinomialNB ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_mnb):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = mn_hyper_parameter (class_, best_grid['alpha'], best_grid['fit_prior'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70786f3",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    \n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = MultinomialNB (alpha = temp.alpha, fit_prior = temp.fit_prior)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    \n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_mn_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269a8fd",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036227",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression (n_jobs=-1)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict_proba(tf_idf_test)[:,1]\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_logreg_1.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba88dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d8f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = tf_idf_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = tf_idf_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_lr):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ec8a5",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    predictions = model.predict(tf_idf_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(tf_idf_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_tf_idf_log_reg_tuned.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7246",
   "metadata": {},
   "source": [
    "### Logistic Regression using Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cba4",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    model = LogisticRegression ()\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    predictions = arr_model [counter].predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408644e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05384cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyperparameters = []\n",
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    best_score = 0\n",
    "    \n",
    "    model = LogisticRegression ()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split (X, y_train, test_size = 0.25, stratify = y_train)\n",
    "    \n",
    "    X_train_sparse_matrix = count_vectorizer.fit_transform(X_train)\n",
    "    X_validation_sparse_matrix = count_vectorizer.transform(X_val)\n",
    "    \n",
    "    for g in ParameterGrid(parameters_lr):\n",
    "\n",
    "        model.set_params(**g)\n",
    "\n",
    "        model.fit(X_train_sparse_matrix, y_train)\n",
    "        predictions = model.predict (X_train_sparse_matrix)\n",
    "        train_acc = compute_accuracy (predictions, y_train)\n",
    "\n",
    "        predictions = model.predict (X_validation_sparse_matrix)\n",
    "        val_acc = compute_accuracy (predictions, y_val)\n",
    "\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_grid = g\n",
    "    \n",
    "    print(\"Best accuracy: \", best_score, \"%\")\n",
    "    print(\"Best grid: \", best_grid)\n",
    "    temp = lr_hyperparameter (class_, best_grid['C'], best_grid['max_iter'])\n",
    "    final_hyperparameters.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87ee1a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train ['comment_text']\n",
    "X_test = test ['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f612c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.columns [2:]\n",
    "arr_model = []\n",
    "counter = 0\n",
    "for class_ in classes:\n",
    "    print(\"Class: \", class_)\n",
    "    y_train = train[class_]\n",
    "    temp = final_hyperparameters [counter]\n",
    "    model = LogisticRegression (C = temp.c, max_iter = temp.max_iter)\n",
    "\n",
    "    model.fit(count_train, y_train)\n",
    "    predictions = model.predict(count_train)\n",
    "    print(compute_accuracy(predictions, y_train))\n",
    "    arr_model.append(model)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission ['id'] = test ['id'] \n",
    "counter = 0\n",
    "\n",
    "for class_ in classes:\n",
    "    predictions = arr_model [counter].predict(count_test)\n",
    "    sample_submission [class_] = predictions\n",
    "    counter = counter + 1\n",
    "    \n",
    "sample_submission.to_csv(f'results/submission_count_log_reg_tuned.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
